% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/paws.sagemaker_operations.R
\name{create_transform_job}
\alias{create_transform_job}
\title{Starts a transform job}
\usage{
create_transform_job(TransformJobName, ModelName,
  MaxConcurrentTransforms = NULL, MaxPayloadInMB = NULL,
  BatchStrategy = NULL, Environment = NULL, TransformInput,
  TransformOutput, TransformResources, Tags = NULL)
}
\arguments{
\item{TransformJobName}{[required] The name of the transform job. The name must be unique within an AWS Region in an AWS account.}

\item{ModelName}{[required] The name of the model that you want to use for the transform job. \code{ModelName} must be the name of an existing Amazon SageMaker model within an AWS Region in an AWS account.}

\item{MaxConcurrentTransforms}{The maximum number of parallel requests that can be sent to an algorithm container on an instance. This is good for algorithms that implement multiple workers on larger instances . The default value is \code{1}. To allow Amazon SageMaker to determine the appropriate number for \code{MaxConcurrentTransforms}, do not set the value in the API.}

\item{MaxPayloadInMB}{The maximum payload size allowed, in MB. A payload is the data portion of a record (without metadata). The value in \code{MaxPayloadInMB} must be greater or equal to the size of a single record. You can approximate the size of a record by dividing the size of your dataset by the number of records. Then multiply this value by the number of records you want in a mini-batch. We recommend to enter a slightly larger value than this to ensure the records fit within the maximum payload size. The default value is \code{6} MB.

For cases where the payload might be arbitrarily large and is transmitted using HTTP chunked encoding, set the value to \code{0}. This feature only works in supported algorithms. Currently, Amazon SageMaker built-in algorithms do not support this feature.}

\item{BatchStrategy}{Determines the number of records to include in a mini-batch. If you want to include only one record in a mini-batch, specify \code{SingleRecord}.. If you want mini-batches to contain a maximum of the number of records specified in the \code{MaxPayloadInMB} parameter, specify \code{MultiRecord}.

If you set \code{SplitType} to \code{Line} and \code{BatchStrategy} to \code{MultiRecord}, a batch transform automatically splits your input data into the specified payload size. There's no need to split the dataset into smaller files or to use larger payload sizes unless the records in your dataset are very large.}

\item{Environment}{The environment variables to set in the Docker container. We support up to 16 key and values entries in the map.}

\item{TransformInput}{[required] Describes the input source and the way the transform job consumes it.}

\item{TransformOutput}{[required] Describes the results of the transform job.}

\item{TransformResources}{[required] Describes the resources, including ML instance types and ML instance count, to use for the transform job.}

\item{Tags}{(Optional) An array of key-value pairs. For more information, see \href{http://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/cost-alloc-tags.html#allocation-what}{Using Cost Allocation Tags} in the \emph{AWS Billing and Cost Management User Guide}.}
}
\description{
Starts a transform job. A transform job uses a trained model to get inferences on a dataset and saves these results to an Amazon S3 location that you specify.
}
\details{
To perform batch transformations, you create a transform job and use the data that you have readily available.

In the request body, you provide the following:
\itemize{
\item \code{TransformJobName} - Identifies the transform job. The name must be unique within an AWS Region in an AWS account.
\item \code{ModelName} - Identifies the model to use. \code{ModelName} must be the name of an existing Amazon SageMaker model in the same AWS Region and AWS account. For information on creating a model, see CreateModel.
\item \code{TransformInput} - Describes the dataset to be transformed and the Amazon S3 location where it is stored.
\item \code{TransformOutput} - Identifies the Amazon S3 location where you want Amazon SageMaker to save the results from the transform job.
\item \code{TransformResources} - Identifies the ML compute instances for the transform job.
}

For more information about how batch transformation works Amazon SageMaker, see \href{http://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html}{How It Works}.
}
\section{Accepted Parameters}{
\preformatted{create_transform_job(
  TransformJobName = "string",
  ModelName = "string",
  MaxConcurrentTransforms = 123,
  MaxPayloadInMB = 123,
  BatchStrategy = "MultiRecord"|"SingleRecord",
  Environment = list(
    "string"
  ),
  TransformInput = list(
    DataSource = list(
      S3DataSource = list(
        S3DataType = "ManifestFile"|"S3Prefix"|"AugmentedManifestFile",
        S3Uri = "string"
      )
    ),
    ContentType = "string",
    CompressionType = "None"|"Gzip",
    SplitType = "None"|"Line"|"RecordIO"|"TFRecord"
  ),
  TransformOutput = list(
    S3OutputPath = "string",
    Accept = "string",
    AssembleWith = "None"|"Line",
    KmsKeyId = "string"
  ),
  TransformResources = list(
    InstanceType = "ml.m4.xlarge"|"ml.m4.2xlarge"|"ml.m4.4xlarge"|"ml.m4.10xlarge"|"ml.m4.16xlarge"|"ml.c4.xlarge"|"ml.c4.2xlarge"|"ml.c4.4xlarge"|"ml.c4.8xlarge"|"ml.p2.xlarge"|"ml.p2.8xlarge"|"ml.p2.16xlarge"|"ml.p3.2xlarge"|"ml.p3.8xlarge"|"ml.p3.16xlarge"|"ml.c5.xlarge"|"ml.c5.2xlarge"|"ml.c5.4xlarge"|"ml.c5.9xlarge"|"ml.c5.18xlarge"|"ml.m5.large"|"ml.m5.xlarge"|"ml.m5.2xlarge"|"ml.m5.4xlarge"|"ml.m5.12xlarge"|"ml.m5.24xlarge",
    InstanceCount = 123,
    VolumeKmsKeyId = "string"
  ),
  Tags = list(
    list(
      Key = "string",
      Value = "string"
    )
  )
)
}
}

