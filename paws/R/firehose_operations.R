# This file is generated by make.paws. Please do not edit here.
#' @importFrom paws.common get_config new_operation new_request send_request
#' @include firehose_service.R
NULL

#' Creates a Firehose delivery stream
#'
#' @description
#' Creates a Firehose delivery stream.
#' 
#' By default, you can create up to 50 delivery streams per Amazon Web
#' Services Region.
#' 
#' This is an asynchronous operation that immediately returns. The initial
#' status of the delivery stream is `CREATING`. After the delivery stream
#' is created, its status is `ACTIVE` and it now accepts data. If the
#' delivery stream creation fails, the status transitions to
#' `CREATING_FAILED`. Attempts to send data to a delivery stream that is
#' not in the `ACTIVE` state cause an exception. To check the state of a
#' delivery stream, use
#' [`describe_delivery_stream`][firehose_describe_delivery_stream].
#' 
#' If the status of a delivery stream is `CREATING_FAILED`, this status
#' doesn't change, and you can't invoke
#' [`create_delivery_stream`][firehose_create_delivery_stream] again on it.
#' However, you can invoke the
#' [`delete_delivery_stream`][firehose_delete_delivery_stream] operation to
#' delete it.
#' 
#' A Firehose delivery stream can be configured to receive records directly
#' from providers using [`put_record`][firehose_put_record] or
#' [`put_record_batch`][firehose_put_record_batch], or it can be configured
#' to use an existing Kinesis stream as its source. To specify a Kinesis
#' data stream as input, set the `DeliveryStreamType` parameter to
#' `KinesisStreamAsSource`, and provide the Kinesis stream Amazon Resource
#' Name (ARN) and role ARN in the `KinesisStreamSourceConfiguration`
#' parameter.
#' 
#' To create a delivery stream with server-side encryption (SSE) enabled,
#' include DeliveryStreamEncryptionConfigurationInput in your request. This
#' is optional. You can also invoke
#' [`start_delivery_stream_encryption`][firehose_start_delivery_stream_encryption]
#' to turn on SSE for an existing delivery stream that doesn't have SSE
#' enabled.
#' 
#' A delivery stream is configured with a single destination, such as
#' Amazon Simple Storage Service (Amazon S3), Amazon Redshift, Amazon
#' OpenSearch Service, Amazon OpenSearch Serverless, Splunk, and any custom
#' HTTP endpoint or HTTP endpoints owned by or supported by third-party
#' service providers, including Datadog, Dynatrace, LogicMonitor, MongoDB,
#' New Relic, and Sumo Logic. You must specify only one of the following
#' destination configuration parameters:
#' `ExtendedS3DestinationConfiguration`, `S3DestinationConfiguration`,
#' `ElasticsearchDestinationConfiguration`,
#' `RedshiftDestinationConfiguration`, or `SplunkDestinationConfiguration`.
#' 
#' When you specify `S3DestinationConfiguration`, you can also provide the
#' following optional values: BufferingHints, `EncryptionConfiguration`,
#' and `CompressionFormat`. By default, if no `BufferingHints` value is
#' provided, Firehose buffers data up to 5 MB or for 5 minutes, whichever
#' condition is satisfied first. `BufferingHints` is a hint, so there are
#' some cases where the service cannot adhere to these conditions strictly.
#' For example, record boundaries might be such that the size is a little
#' over or under the configured buffering size. By default, no encryption
#' is performed. We strongly recommend that you enable encryption to ensure
#' secure data storage in Amazon S3.
#' 
#' A few notes about Amazon Redshift as a destination:
#' 
#' - An Amazon Redshift destination requires an S3 bucket as intermediate
#'   location. Firehose first delivers data to Amazon S3 and then uses
#'   `COPY` syntax to load data into an Amazon Redshift table. This is
#'   specified in the `RedshiftDestinationConfiguration.S3Configuration`
#'   parameter.
#' 
#' - The compression formats `SNAPPY` or `ZIP` cannot be specified in
#'   `RedshiftDestinationConfiguration.S3Configuration` because the Amazon
#'   Redshift `COPY` operation that reads from the S3 bucket doesn't
#'   support these compression formats.
#' 
#' - We strongly recommend that you use the user name and password you
#'   provide exclusively with Firehose, and that the permissions for the
#'   account are restricted for Amazon Redshift `INSERT` permissions.
#' 
#' Firehose assumes the IAM role that is configured as part of the
#' destination. The role should allow the Firehose principal to assume the
#' role, and the role should have permissions that allow the service to
#' deliver the data. For more information, see [Grant Firehose Access to an
#' Amazon S3
#' Destination](https://docs.aws.amazon.com/firehose/latest/dev/controlling-access.html#using-iam-s3)
#' in the *Amazon Firehose Developer Guide*.
#'
#' @usage
#' firehose_create_delivery_stream(DeliveryStreamName, DeliveryStreamType,
#'   KinesisStreamSourceConfiguration,
#'   DeliveryStreamEncryptionConfigurationInput, S3DestinationConfiguration,
#'   ExtendedS3DestinationConfiguration, RedshiftDestinationConfiguration,
#'   ElasticsearchDestinationConfiguration,
#'   AmazonopensearchserviceDestinationConfiguration,
#'   SplunkDestinationConfiguration, HttpEndpointDestinationConfiguration,
#'   Tags, AmazonOpenSearchServerlessDestinationConfiguration,
#'   MSKSourceConfiguration, SnowflakeDestinationConfiguration,
#'   IcebergDestinationConfiguration)
#'
#' @param DeliveryStreamName &#91;required&#93; The name of the delivery stream. This name must be unique per Amazon Web
#' Services account in the same Amazon Web Services Region. If the delivery
#' streams are in different accounts or different Regions, you can have
#' multiple delivery streams with the same name.
#' @param DeliveryStreamType The delivery stream type. This parameter can be one of the following
#' values:
#' 
#' - `DirectPut`: Provider applications access the delivery stream
#'   directly.
#' 
#' - `KinesisStreamAsSource`: The delivery stream uses a Kinesis data
#'   stream as a source.
#' @param KinesisStreamSourceConfiguration When a Kinesis data stream is used as the source for the delivery
#' stream, a KinesisStreamSourceConfiguration containing the Kinesis data
#' stream Amazon Resource Name (ARN) and the role ARN for the source
#' stream.
#' @param DeliveryStreamEncryptionConfigurationInput Used to specify the type and Amazon Resource Name (ARN) of the KMS key
#' needed for Server-Side Encryption (SSE).
#' @param S3DestinationConfiguration \[Deprecated\] The destination in Amazon S3. You can specify only one
#' destination.
#' @param ExtendedS3DestinationConfiguration The destination in Amazon S3. You can specify only one destination.
#' @param RedshiftDestinationConfiguration The destination in Amazon Redshift. You can specify only one
#' destination.
#' @param ElasticsearchDestinationConfiguration The destination in Amazon ES. You can specify only one destination.
#' @param AmazonopensearchserviceDestinationConfiguration The destination in Amazon OpenSearch Service. You can specify only one
#' destination.
#' @param SplunkDestinationConfiguration The destination in Splunk. You can specify only one destination.
#' @param HttpEndpointDestinationConfiguration Enables configuring Kinesis Firehose to deliver data to any HTTP
#' endpoint destination. You can specify only one destination.
#' @param Tags A set of tags to assign to the delivery stream. A tag is a key-value
#' pair that you can define and assign to Amazon Web Services resources.
#' Tags are metadata. For example, you can add friendly names and
#' descriptions or other types of information that can help you distinguish
#' the delivery stream. For more information about tags, see [Using Cost
#' Allocation
#' Tags](https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/cost-alloc-tags.html)
#' in the Amazon Web Services Billing and Cost Management User Guide.
#' 
#' You can specify up to 50 tags when creating a delivery stream.
#' 
#' If you specify tags in the
#' [`create_delivery_stream`][firehose_create_delivery_stream] action,
#' Amazon Data Firehose performs an additional authorization on the
#' `firehose:TagDeliveryStream` action to verify if users have permissions
#' to create tags. If you do not provide this permission, requests to
#' create new Firehose delivery streams with IAM resource tags will fail
#' with an `AccessDeniedException` such as following.
#' 
#' **AccessDeniedException**
#' 
#' User: arn:aws:sts::x:assumed-role/x/x is not authorized to perform:
#' firehose:TagDeliveryStream on resource:
#' arn:aws:firehose:us-east-1:x:deliverystream/x with an explicit deny in
#' an identity-based policy.
#' 
#' For an example IAM policy, see [Tag
#' example.](https://docs.aws.amazon.com/firehose/latest/APIReference/API_CreateDeliveryStream.html#API_CreateDeliveryStream_Examples)
#' @param AmazonOpenSearchServerlessDestinationConfiguration The destination in the Serverless offering for Amazon OpenSearch
#' Service. You can specify only one destination.
#' @param MSKSourceConfiguration 
#' @param SnowflakeDestinationConfiguration Configure Snowflake destination
#' @param IcebergDestinationConfiguration Configure Apache Iceberg Tables destination.
#' 
#' Amazon Data Firehose is in preview release and is subject to change.
#'
#' @return
#' A list with the following syntax:
#' ```
#' list(
#'   DeliveryStreamARN = "string"
#' )
#' ```
#'
#' @section Request syntax:
#' ```
#' svc$create_delivery_stream(
#'   DeliveryStreamName = "string",
#'   DeliveryStreamType = "DirectPut"|"KinesisStreamAsSource"|"MSKAsSource",
#'   KinesisStreamSourceConfiguration = list(
#'     KinesisStreamARN = "string",
#'     RoleARN = "string"
#'   ),
#'   DeliveryStreamEncryptionConfigurationInput = list(
#'     KeyARN = "string",
#'     KeyType = "AWS_OWNED_CMK"|"CUSTOMER_MANAGED_CMK"
#'   ),
#'   S3DestinationConfiguration = list(
#'     RoleARN = "string",
#'     BucketARN = "string",
#'     Prefix = "string",
#'     ErrorOutputPrefix = "string",
#'     BufferingHints = list(
#'       SizeInMBs = 123,
#'       IntervalInSeconds = 123
#'     ),
#'     CompressionFormat = "UNCOMPRESSED"|"GZIP"|"ZIP"|"Snappy"|"HADOOP_SNAPPY",
#'     EncryptionConfiguration = list(
#'       NoEncryptionConfig = "NoEncryption",
#'       KMSEncryptionConfig = list(
#'         AWSKMSKeyARN = "string"
#'       )
#'     ),
#'     CloudWatchLoggingOptions = list(
#'       Enabled = TRUE|FALSE,
#'       LogGroupName = "string",
#'       LogStreamName = "string"
#'     )
#'   ),
#'   ExtendedS3DestinationConfiguration = list(
#'     RoleARN = "string",
#'     BucketARN = "string",
#'     Prefix = "string",
#'     ErrorOutputPrefix = "string",
#'     BufferingHints = list(
#'       SizeInMBs = 123,
#'       IntervalInSeconds = 123
#'     ),
#'     CompressionFormat = "UNCOMPRESSED"|"GZIP"|"ZIP"|"Snappy"|"HADOOP_SNAPPY",
#'     EncryptionConfiguration = list(
#'       NoEncryptionConfig = "NoEncryption",
#'       KMSEncryptionConfig = list(
#'         AWSKMSKeyARN = "string"
#'       )
#'     ),
#'     CloudWatchLoggingOptions = list(
#'       Enabled = TRUE|FALSE,
#'       LogGroupName = "string",
#'       LogStreamName = "string"
#'     ),
#'     ProcessingConfiguration = list(
#'       Enabled = TRUE|FALSE,
#'       Processors = list(
#'         list(
#'           Type = "RecordDeAggregation"|"Decompression"|"CloudWatchLogProcessing"|"Lambda"|"MetadataExtraction"|"AppendDelimiterToRecord",
#'           Parameters = list(
#'             list(
#'               ParameterName = "LambdaArn"|"NumberOfRetries"|"MetadataExtractionQuery"|"JsonParsingEngine"|"RoleArn"|"BufferSizeInMBs"|"BufferIntervalInSeconds"|"SubRecordType"|"Delimiter"|"CompressionFormat"|"DataMessageExtraction",
#'               ParameterValue = "string"
#'             )
#'           )
#'         )
#'       )
#'     ),
#'     S3BackupMode = "Disabled"|"Enabled",
#'     S3BackupConfiguration = list(
#'       RoleARN = "string",
#'       BucketARN = "string",
#'       Prefix = "string",
#'       ErrorOutputPrefix = "string",
#'       BufferingHints = list(
#'         SizeInMBs = 123,
#'         IntervalInSeconds = 123
#'       ),
#'       CompressionFormat = "UNCOMPRESSED"|"GZIP"|"ZIP"|"Snappy"|"HADOOP_SNAPPY",
#'       EncryptionConfiguration = list(
#'         NoEncryptionConfig = "NoEncryption",
#'         KMSEncryptionConfig = list(
#'           AWSKMSKeyARN = "string"
#'         )
#'       ),
#'       CloudWatchLoggingOptions = list(
#'         Enabled = TRUE|FALSE,
#'         LogGroupName = "string",
#'         LogStreamName = "string"
#'       )
#'     ),
#'     DataFormatConversionConfiguration = list(
#'       SchemaConfiguration = list(
#'         RoleARN = "string",
#'         CatalogId = "string",
#'         DatabaseName = "string",
#'         TableName = "string",
#'         Region = "string",
#'         VersionId = "string"
#'       ),
#'       InputFormatConfiguration = list(
#'         Deserializer = list(
#'           OpenXJsonSerDe = list(
#'             ConvertDotsInJsonKeysToUnderscores = TRUE|FALSE,
#'             CaseInsensitive = TRUE|FALSE,
#'             ColumnToJsonKeyMappings = list(
#'               "string"
#'             )
#'           ),
#'           HiveJsonSerDe = list(
#'             TimestampFormats = list(
#'               "string"
#'             )
#'           )
#'         )
#'       ),
#'       OutputFormatConfiguration = list(
#'         Serializer = list(
#'           ParquetSerDe = list(
#'             BlockSizeBytes = 123,
#'             PageSizeBytes = 123,
#'             Compression = "UNCOMPRESSED"|"GZIP"|"SNAPPY",
#'             EnableDictionaryCompression = TRUE|FALSE,
#'             MaxPaddingBytes = 123,
#'             WriterVersion = "V1"|"V2"
#'           ),
#'           OrcSerDe = list(
#'             StripeSizeBytes = 123,
#'             BlockSizeBytes = 123,
#'             RowIndexStride = 123,
#'             EnablePadding = TRUE|FALSE,
#'             PaddingTolerance = 123.0,
#'             Compression = "NONE"|"ZLIB"|"SNAPPY",
#'             BloomFilterColumns = list(
#'               "string"
#'             ),
#'             BloomFilterFalsePositiveProbability = 123.0,
#'             DictionaryKeyThreshold = 123.0,
#'             FormatVersion = "V0_11"|"V0_12"
#'           )
#'         )
#'       ),
#'       Enabled = TRUE|FALSE
#'     ),
#'     DynamicPartitioningConfiguration = list(
#'       RetryOptions = list(
#'         DurationInSeconds = 123
#'       ),
#'       Enabled = TRUE|FALSE
#'     ),
#'     FileExtension = "string",
#'     CustomTimeZone = "string"
#'   ),
#'   RedshiftDestinationConfiguration = list(
#'     RoleARN = "string",
#'     ClusterJDBCURL = "string",
#'     CopyCommand = list(
#'       DataTableName = "string",
#'       DataTableColumns = "string",
#'       CopyOptions = "string"
#'     ),
#'     Username = "string",
#'     Password = "string",
#'     RetryOptions = list(
#'       DurationInSeconds = 123
#'     ),
#'     S3Configuration = list(
#'       RoleARN = "string",
#'       BucketARN = "string",
#'       Prefix = "string",
#'       ErrorOutputPrefix = "string",
#'       BufferingHints = list(
#'         SizeInMBs = 123,
#'         IntervalInSeconds = 123
#'       ),
#'       CompressionFormat = "UNCOMPRESSED"|"GZIP"|"ZIP"|"Snappy"|"HADOOP_SNAPPY",
#'       EncryptionConfiguration = list(
#'         NoEncryptionConfig = "NoEncryption",
#'         KMSEncryptionConfig = list(
#'           AWSKMSKeyARN = "string"
#'         )
#'       ),
#'       CloudWatchLoggingOptions = list(
#'         Enabled = TRUE|FALSE,
#'         LogGroupName = "string",
#'         LogStreamName = "string"
#'       )
#'     ),
#'     ProcessingConfiguration = list(
#'       Enabled = TRUE|FALSE,
#'       Processors = list(
#'         list(
#'           Type = "RecordDeAggregation"|"Decompression"|"CloudWatchLogProcessing"|"Lambda"|"MetadataExtraction"|"AppendDelimiterToRecord",
#'           Parameters = list(
#'             list(
#'               ParameterName = "LambdaArn"|"NumberOfRetries"|"MetadataExtractionQuery"|"JsonParsingEngine"|"RoleArn"|"BufferSizeInMBs"|"BufferIntervalInSeconds"|"SubRecordType"|"Delimiter"|"CompressionFormat"|"DataMessageExtraction",
#'               ParameterValue = "string"
#'             )
#'           )
#'         )
#'       )
#'     ),
#'     S3BackupMode = "Disabled"|"Enabled",
#'     S3BackupConfiguration = list(
#'       RoleARN = "string",
#'       BucketARN = "string",
#'       Prefix = "string",
#'       ErrorOutputPrefix = "string",
#'       BufferingHints = list(
#'         SizeInMBs = 123,
#'         IntervalInSeconds = 123
#'       ),
#'       CompressionFormat = "UNCOMPRESSED"|"GZIP"|"ZIP"|"Snappy"|"HADOOP_SNAPPY",
#'       EncryptionConfiguration = list(
#'         NoEncryptionConfig = "NoEncryption",
#'         KMSEncryptionConfig = list(
#'           AWSKMSKeyARN = "string"
#'         )
#'       ),
#'       CloudWatchLoggingOptions = list(
#'         Enabled = TRUE|FALSE,
#'         LogGroupName = "string",
#'         LogStreamName = "string"
#'       )
#'     ),
#'     CloudWatchLoggingOptions = list(
#'       Enabled = TRUE|FALSE,
#'       LogGroupName = "string",
#'       LogStreamName = "string"
#'     ),
#'     SecretsManagerConfiguration = list(
#'       SecretARN = "string",
#'       RoleARN = "string",
#'       Enabled = TRUE|FALSE
#'     )
#'   ),
#'   ElasticsearchDestinationConfiguration = list(
#'     RoleARN = "string",
#'     DomainARN = "string",
#'     ClusterEndpoint = "string",
#'     IndexName = "string",
#'     TypeName = "string",
#'     IndexRotationPeriod = "NoRotation"|"OneHour"|"OneDay"|"OneWeek"|"OneMonth",
#'     BufferingHints = list(
#'       IntervalInSeconds = 123,
#'       SizeInMBs = 123
#'     ),
#'     RetryOptions = list(
#'       DurationInSeconds = 123
#'     ),
#'     S3BackupMode = "FailedDocumentsOnly"|"AllDocuments",
#'     S3Configuration = list(
#'       RoleARN = "string",
#'       BucketARN = "string",
#'       Prefix = "string",
#'       ErrorOutputPrefix = "string",
#'       BufferingHints = list(
#'         SizeInMBs = 123,
#'         IntervalInSeconds = 123
#'       ),
#'       CompressionFormat = "UNCOMPRESSED"|"GZIP"|"ZIP"|"Snappy"|"HADOOP_SNAPPY",
#'       EncryptionConfiguration = list(
#'         NoEncryptionConfig = "NoEncryption",
#'         KMSEncryptionConfig = list(
#'           AWSKMSKeyARN = "string"
#'         )
#'       ),
#'       CloudWatchLoggingOptions = list(
#'         Enabled = TRUE|FALSE,
#'         LogGroupName = "string",
#'         LogStreamName = "string"
#'       )
#'     ),
#'     ProcessingConfiguration = list(
#'       Enabled = TRUE|FALSE,
#'       Processors = list(
#'         list(
#'           Type = "RecordDeAggregation"|"Decompression"|"CloudWatchLogProcessing"|"Lambda"|"MetadataExtraction"|"AppendDelimiterToRecord",
#'           Parameters = list(
#'             list(
#'               ParameterName = "LambdaArn"|"NumberOfRetries"|"MetadataExtractionQuery"|"JsonParsingEngine"|"RoleArn"|"BufferSizeInMBs"|"BufferIntervalInSeconds"|"SubRecordType"|"Delimiter"|"CompressionFormat"|"DataMessageExtraction",
#'               ParameterValue = "string"
#'             )
#'           )
#'         )
#'       )
#'     ),
#'     CloudWatchLoggingOptions = list(
#'       Enabled = TRUE|FALSE,
#'       LogGroupName = "string",
#'       LogStreamName = "string"
#'     ),
#'     VpcConfiguration = list(
#'       SubnetIds = list(
#'         "string"
#'       ),
#'       RoleARN = "string",
#'       SecurityGroupIds = list(
#'         "string"
#'       )
#'     ),
#'     DocumentIdOptions = list(
#'       DefaultDocumentIdFormat = "FIREHOSE_DEFAULT"|"NO_DOCUMENT_ID"
#'     )
#'   ),
#'   AmazonopensearchserviceDestinationConfiguration = list(
#'     RoleARN = "string",
#'     DomainARN = "string",
#'     ClusterEndpoint = "string",
#'     IndexName = "string",
#'     TypeName = "string",
#'     IndexRotationPeriod = "NoRotation"|"OneHour"|"OneDay"|"OneWeek"|"OneMonth",
#'     BufferingHints = list(
#'       IntervalInSeconds = 123,
#'       SizeInMBs = 123
#'     ),
#'     RetryOptions = list(
#'       DurationInSeconds = 123
#'     ),
#'     S3BackupMode = "FailedDocumentsOnly"|"AllDocuments",
#'     S3Configuration = list(
#'       RoleARN = "string",
#'       BucketARN = "string",
#'       Prefix = "string",
#'       ErrorOutputPrefix = "string",
#'       BufferingHints = list(
#'         SizeInMBs = 123,
#'         IntervalInSeconds = 123
#'       ),
#'       CompressionFormat = "UNCOMPRESSED"|"GZIP"|"ZIP"|"Snappy"|"HADOOP_SNAPPY",
#'       EncryptionConfiguration = list(
#'         NoEncryptionConfig = "NoEncryption",
#'         KMSEncryptionConfig = list(
#'           AWSKMSKeyARN = "string"
#'         )
#'       ),
#'       CloudWatchLoggingOptions = list(
#'         Enabled = TRUE|FALSE,
#'         LogGroupName = "string",
#'         LogStreamName = "string"
#'       )
#'     ),
#'     ProcessingConfiguration = list(
#'       Enabled = TRUE|FALSE,
#'       Processors = list(
#'         list(
#'           Type = "RecordDeAggregation"|"Decompression"|"CloudWatchLogProcessing"|"Lambda"|"MetadataExtraction"|"AppendDelimiterToRecord",
#'           Parameters = list(
#'             list(
#'               ParameterName = "LambdaArn"|"NumberOfRetries"|"MetadataExtractionQuery"|"JsonParsingEngine"|"RoleArn"|"BufferSizeInMBs"|"BufferIntervalInSeconds"|"SubRecordType"|"Delimiter"|"CompressionFormat"|"DataMessageExtraction",
#'               ParameterValue = "string"
#'             )
#'           )
#'         )
#'       )
#'     ),
#'     CloudWatchLoggingOptions = list(
#'       Enabled = TRUE|FALSE,
#'       LogGroupName = "string",
#'       LogStreamName = "string"
#'     ),
#'     VpcConfiguration = list(
#'       SubnetIds = list(
#'         "string"
#'       ),
#'       RoleARN = "string",
#'       SecurityGroupIds = list(
#'         "string"
#'       )
#'     ),
#'     DocumentIdOptions = list(
#'       DefaultDocumentIdFormat = "FIREHOSE_DEFAULT"|"NO_DOCUMENT_ID"
#'     )
#'   ),
#'   SplunkDestinationConfiguration = list(
#'     HECEndpoint = "string",
#'     HECEndpointType = "Raw"|"Event",
#'     HECToken = "string",
#'     HECAcknowledgmentTimeoutInSeconds = 123,
#'     RetryOptions = list(
#'       DurationInSeconds = 123
#'     ),
#'     S3BackupMode = "FailedEventsOnly"|"AllEvents",
#'     S3Configuration = list(
#'       RoleARN = "string",
#'       BucketARN = "string",
#'       Prefix = "string",
#'       ErrorOutputPrefix = "string",
#'       BufferingHints = list(
#'         SizeInMBs = 123,
#'         IntervalInSeconds = 123
#'       ),
#'       CompressionFormat = "UNCOMPRESSED"|"GZIP"|"ZIP"|"Snappy"|"HADOOP_SNAPPY",
#'       EncryptionConfiguration = list(
#'         NoEncryptionConfig = "NoEncryption",
#'         KMSEncryptionConfig = list(
#'           AWSKMSKeyARN = "string"
#'         )
#'       ),
#'       CloudWatchLoggingOptions = list(
#'         Enabled = TRUE|FALSE,
#'         LogGroupName = "string",
#'         LogStreamName = "string"
#'       )
#'     ),
#'     ProcessingConfiguration = list(
#'       Enabled = TRUE|FALSE,
#'       Processors = list(
#'         list(
#'           Type = "RecordDeAggregation"|"Decompression"|"CloudWatchLogProcessing"|"Lambda"|"MetadataExtraction"|"AppendDelimiterToRecord",
#'           Parameters = list(
#'             list(
#'               ParameterName = "LambdaArn"|"NumberOfRetries"|"MetadataExtractionQuery"|"JsonParsingEngine"|"RoleArn"|"BufferSizeInMBs"|"BufferIntervalInSeconds"|"SubRecordType"|"Delimiter"|"CompressionFormat"|"DataMessageExtraction",
#'               ParameterValue = "string"
#'             )
#'           )
#'         )
#'       )
#'     ),
#'     CloudWatchLoggingOptions = list(
#'       Enabled = TRUE|FALSE,
#'       LogGroupName = "string",
#'       LogStreamName = "string"
#'     ),
#'     BufferingHints = list(
#'       IntervalInSeconds = 123,
#'       SizeInMBs = 123
#'     ),
#'     SecretsManagerConfiguration = list(
#'       SecretARN = "string",
#'       RoleARN = "string",
#'       Enabled = TRUE|FALSE
#'     )
#'   ),
#'   HttpEndpointDestinationConfiguration = list(
#'     EndpointConfiguration = list(
#'       Url = "string",
#'       Name = "string",
#'       AccessKey = "string"
#'     ),
#'     BufferingHints = list(
#'       SizeInMBs = 123,
#'       IntervalInSeconds = 123
#'     ),
#'     CloudWatchLoggingOptions = list(
#'       Enabled = TRUE|FALSE,
#'       LogGroupName = "string",
#'       LogStreamName = "string"
#'     ),
#'     RequestConfiguration = list(
#'       ContentEncoding = "NONE"|"GZIP",
#'       CommonAttributes = list(
#'         list(
#'           AttributeName = "string",
#'           AttributeValue = "string"
#'         )
#'       )
#'     ),
#'     ProcessingConfiguration = list(
#'       Enabled = TRUE|FALSE,
#'       Processors = list(
#'         list(
#'           Type = "RecordDeAggregation"|"Decompression"|"CloudWatchLogProcessing"|"Lambda"|"MetadataExtraction"|"AppendDelimiterToRecord",
#'           Parameters = list(
#'             list(
#'               ParameterName = "LambdaArn"|"NumberOfRetries"|"MetadataExtractionQuery"|"JsonParsingEngine"|"RoleArn"|"BufferSizeInMBs"|"BufferIntervalInSeconds"|"SubRecordType"|"Delimiter"|"CompressionFormat"|"DataMessageExtraction",
#'               ParameterValue = "string"
#'             )
#'           )
#'         )
#'       )
#'     ),
#'     RoleARN = "string",
#'     RetryOptions = list(
#'       DurationInSeconds = 123
#'     ),
#'     S3BackupMode = "FailedDataOnly"|"AllData",
#'     S3Configuration = list(
#'       RoleARN = "string",
#'       BucketARN = "string",
#'       Prefix = "string",
#'       ErrorOutputPrefix = "string",
#'       BufferingHints = list(
#'         SizeInMBs = 123,
#'         IntervalInSeconds = 123
#'       ),
#'       CompressionFormat = "UNCOMPRESSED"|"GZIP"|"ZIP"|"Snappy"|"HADOOP_SNAPPY",
#'       EncryptionConfiguration = list(
#'         NoEncryptionConfig = "NoEncryption",
#'         KMSEncryptionConfig = list(
#'           AWSKMSKeyARN = "string"
#'         )
#'       ),
#'       CloudWatchLoggingOptions = list(
#'         Enabled = TRUE|FALSE,
#'         LogGroupName = "string",
#'         LogStreamName = "string"
#'       )
#'     ),
#'     SecretsManagerConfiguration = list(
#'       SecretARN = "string",
#'       RoleARN = "string",
#'       Enabled = TRUE|FALSE
#'     )
#'   ),
#'   Tags = list(
#'     list(
#'       Key = "string",
#'       Value = "string"
#'     )
#'   ),
#'   AmazonOpenSearchServerlessDestinationConfiguration = list(
#'     RoleARN = "string",
#'     CollectionEndpoint = "string",
#'     IndexName = "string",
#'     BufferingHints = list(
#'       IntervalInSeconds = 123,
#'       SizeInMBs = 123
#'     ),
#'     RetryOptions = list(
#'       DurationInSeconds = 123
#'     ),
#'     S3BackupMode = "FailedDocumentsOnly"|"AllDocuments",
#'     S3Configuration = list(
#'       RoleARN = "string",
#'       BucketARN = "string",
#'       Prefix = "string",
#'       ErrorOutputPrefix = "string",
#'       BufferingHints = list(
#'         SizeInMBs = 123,
#'         IntervalInSeconds = 123
#'       ),
#'       CompressionFormat = "UNCOMPRESSED"|"GZIP"|"ZIP"|"Snappy"|"HADOOP_SNAPPY",
#'       EncryptionConfiguration = list(
#'         NoEncryptionConfig = "NoEncryption",
#'         KMSEncryptionConfig = list(
#'           AWSKMSKeyARN = "string"
#'         )
#'       ),
#'       CloudWatchLoggingOptions = list(
#'         Enabled = TRUE|FALSE,
#'         LogGroupName = "string",
#'         LogStreamName = "string"
#'       )
#'     ),
#'     ProcessingConfiguration = list(
#'       Enabled = TRUE|FALSE,
#'       Processors = list(
#'         list(
#'           Type = "RecordDeAggregation"|"Decompression"|"CloudWatchLogProcessing"|"Lambda"|"MetadataExtraction"|"AppendDelimiterToRecord",
#'           Parameters = list(
#'             list(
#'               ParameterName = "LambdaArn"|"NumberOfRetries"|"MetadataExtractionQuery"|"JsonParsingEngine"|"RoleArn"|"BufferSizeInMBs"|"BufferIntervalInSeconds"|"SubRecordType"|"Delimiter"|"CompressionFormat"|"DataMessageExtraction",
#'               ParameterValue = "string"
#'             )
#'           )
#'         )
#'       )
#'     ),
#'     CloudWatchLoggingOptions = list(
#'       Enabled = TRUE|FALSE,
#'       LogGroupName = "string",
#'       LogStreamName = "string"
#'     ),
#'     VpcConfiguration = list(
#'       SubnetIds = list(
#'         "string"
#'       ),
#'       RoleARN = "string",
#'       SecurityGroupIds = list(
#'         "string"
#'       )
#'     )
#'   ),
#'   MSKSourceConfiguration = list(
#'     MSKClusterARN = "string",
#'     TopicName = "string",
#'     AuthenticationConfiguration = list(
#'       RoleARN = "string",
#'       Connectivity = "PUBLIC"|"PRIVATE"
#'     ),
#'     ReadFromTimestamp = as.POSIXct(
#'       "2015-01-01"
#'     )
#'   ),
#'   SnowflakeDestinationConfiguration = list(
#'     AccountUrl = "string",
#'     PrivateKey = "string",
#'     KeyPassphrase = "string",
#'     User = "string",
#'     Database = "string",
#'     Schema = "string",
#'     Table = "string",
#'     SnowflakeRoleConfiguration = list(
#'       Enabled = TRUE|FALSE,
#'       SnowflakeRole = "string"
#'     ),
#'     DataLoadingOption = "JSON_MAPPING"|"VARIANT_CONTENT_MAPPING"|"VARIANT_CONTENT_AND_METADATA_MAPPING",
#'     MetaDataColumnName = "string",
#'     ContentColumnName = "string",
#'     SnowflakeVpcConfiguration = list(
#'       PrivateLinkVpceId = "string"
#'     ),
#'     CloudWatchLoggingOptions = list(
#'       Enabled = TRUE|FALSE,
#'       LogGroupName = "string",
#'       LogStreamName = "string"
#'     ),
#'     ProcessingConfiguration = list(
#'       Enabled = TRUE|FALSE,
#'       Processors = list(
#'         list(
#'           Type = "RecordDeAggregation"|"Decompression"|"CloudWatchLogProcessing"|"Lambda"|"MetadataExtraction"|"AppendDelimiterToRecord",
#'           Parameters = list(
#'             list(
#'               ParameterName = "LambdaArn"|"NumberOfRetries"|"MetadataExtractionQuery"|"JsonParsingEngine"|"RoleArn"|"BufferSizeInMBs"|"BufferIntervalInSeconds"|"SubRecordType"|"Delimiter"|"CompressionFormat"|"DataMessageExtraction",
#'               ParameterValue = "string"
#'             )
#'           )
#'         )
#'       )
#'     ),
#'     RoleARN = "string",
#'     RetryOptions = list(
#'       DurationInSeconds = 123
#'     ),
#'     S3BackupMode = "FailedDataOnly"|"AllData",
#'     S3Configuration = list(
#'       RoleARN = "string",
#'       BucketARN = "string",
#'       Prefix = "string",
#'       ErrorOutputPrefix = "string",
#'       BufferingHints = list(
#'         SizeInMBs = 123,
#'         IntervalInSeconds = 123
#'       ),
#'       CompressionFormat = "UNCOMPRESSED"|"GZIP"|"ZIP"|"Snappy"|"HADOOP_SNAPPY",
#'       EncryptionConfiguration = list(
#'         NoEncryptionConfig = "NoEncryption",
#'         KMSEncryptionConfig = list(
#'           AWSKMSKeyARN = "string"
#'         )
#'       ),
#'       CloudWatchLoggingOptions = list(
#'         Enabled = TRUE|FALSE,
#'         LogGroupName = "string",
#'         LogStreamName = "string"
#'       )
#'     ),
#'     SecretsManagerConfiguration = list(
#'       SecretARN = "string",
#'       RoleARN = "string",
#'       Enabled = TRUE|FALSE
#'     ),
#'     BufferingHints = list(
#'       SizeInMBs = 123,
#'       IntervalInSeconds = 123
#'     )
#'   ),
#'   IcebergDestinationConfiguration = list(
#'     DestinationTableConfigurationList = list(
#'       list(
#'         DestinationTableName = "string",
#'         DestinationDatabaseName = "string",
#'         UniqueKeys = list(
#'           "string"
#'         ),
#'         S3ErrorOutputPrefix = "string"
#'       )
#'     ),
#'     BufferingHints = list(
#'       SizeInMBs = 123,
#'       IntervalInSeconds = 123
#'     ),
#'     CloudWatchLoggingOptions = list(
#'       Enabled = TRUE|FALSE,
#'       LogGroupName = "string",
#'       LogStreamName = "string"
#'     ),
#'     ProcessingConfiguration = list(
#'       Enabled = TRUE|FALSE,
#'       Processors = list(
#'         list(
#'           Type = "RecordDeAggregation"|"Decompression"|"CloudWatchLogProcessing"|"Lambda"|"MetadataExtraction"|"AppendDelimiterToRecord",
#'           Parameters = list(
#'             list(
#'               ParameterName = "LambdaArn"|"NumberOfRetries"|"MetadataExtractionQuery"|"JsonParsingEngine"|"RoleArn"|"BufferSizeInMBs"|"BufferIntervalInSeconds"|"SubRecordType"|"Delimiter"|"CompressionFormat"|"DataMessageExtraction",
#'               ParameterValue = "string"
#'             )
#'           )
#'         )
#'       )
#'     ),
#'     S3BackupMode = "FailedDataOnly"|"AllData",
#'     RetryOptions = list(
#'       DurationInSeconds = 123
#'     ),
#'     RoleARN = "string",
#'     CatalogConfiguration = list(
#'       CatalogARN = "string"
#'     ),
#'     S3Configuration = list(
#'       RoleARN = "string",
#'       BucketARN = "string",
#'       Prefix = "string",
#'       ErrorOutputPrefix = "string",
#'       BufferingHints = list(
#'         SizeInMBs = 123,
#'         IntervalInSeconds = 123
#'       ),
#'       CompressionFormat = "UNCOMPRESSED"|"GZIP"|"ZIP"|"Snappy"|"HADOOP_SNAPPY",
#'       EncryptionConfiguration = list(
#'         NoEncryptionConfig = "NoEncryption",
#'         KMSEncryptionConfig = list(
#'           AWSKMSKeyARN = "string"
#'         )
#'       ),
#'       CloudWatchLoggingOptions = list(
#'         Enabled = TRUE|FALSE,
#'         LogGroupName = "string",
#'         LogStreamName = "string"
#'       )
#'     )
#'   )
#' )
#' ```
#'
#' @keywords internal
#'
#' @rdname firehose_create_delivery_stream
#'
#' @aliases firehose_create_delivery_stream
firehose_create_delivery_stream <- function(DeliveryStreamName, DeliveryStreamType = NULL, KinesisStreamSourceConfiguration = NULL, DeliveryStreamEncryptionConfigurationInput = NULL, S3DestinationConfiguration = NULL, ExtendedS3DestinationConfiguration = NULL, RedshiftDestinationConfiguration = NULL, ElasticsearchDestinationConfiguration = NULL, AmazonopensearchserviceDestinationConfiguration = NULL, SplunkDestinationConfiguration = NULL, HttpEndpointDestinationConfiguration = NULL, Tags = NULL, AmazonOpenSearchServerlessDestinationConfiguration = NULL, MSKSourceConfiguration = NULL, SnowflakeDestinationConfiguration = NULL, IcebergDestinationConfiguration = NULL) {
  op <- new_operation(
    name = "CreateDeliveryStream",
    http_method = "POST",
    http_path = "/",
    host_prefix = "",
    paginator = list(),
    stream_api = FALSE
  )
  input <- .firehose$create_delivery_stream_input(DeliveryStreamName = DeliveryStreamName, DeliveryStreamType = DeliveryStreamType, KinesisStreamSourceConfiguration = KinesisStreamSourceConfiguration, DeliveryStreamEncryptionConfigurationInput = DeliveryStreamEncryptionConfigurationInput, S3DestinationConfiguration = S3DestinationConfiguration, ExtendedS3DestinationConfiguration = ExtendedS3DestinationConfiguration, RedshiftDestinationConfiguration = RedshiftDestinationConfiguration, ElasticsearchDestinationConfiguration = ElasticsearchDestinationConfiguration, AmazonopensearchserviceDestinationConfiguration = AmazonopensearchserviceDestinationConfiguration, SplunkDestinationConfiguration = SplunkDestinationConfiguration, HttpEndpointDestinationConfiguration = HttpEndpointDestinationConfiguration, Tags = Tags, AmazonOpenSearchServerlessDestinationConfiguration = AmazonOpenSearchServerlessDestinationConfiguration, MSKSourceConfiguration = MSKSourceConfiguration, SnowflakeDestinationConfiguration = SnowflakeDestinationConfiguration, IcebergDestinationConfiguration = IcebergDestinationConfiguration)
  output <- .firehose$create_delivery_stream_output()
  config <- get_config()
  svc <- .firehose$service(config, op)
  request <- new_request(svc, op, input, output)
  response <- send_request(request)
  return(response)
}
.firehose$operations$create_delivery_stream <- firehose_create_delivery_stream

#' Deletes a delivery stream and its data
#'
#' @description
#' Deletes a delivery stream and its data.
#' 
#' You can delete a delivery stream only if it is in one of the following
#' states: `ACTIVE`, `DELETING`, `CREATING_FAILED`, or `DELETING_FAILED`.
#' You can't delete a delivery stream that is in the `CREATING` state. To
#' check the state of a delivery stream, use
#' [`describe_delivery_stream`][firehose_describe_delivery_stream].
#' 
#' DeleteDeliveryStream is an asynchronous API. When an API request to
#' DeleteDeliveryStream succeeds, the delivery stream is marked for
#' deletion, and it goes into the `DELETING` state.While the delivery
#' stream is in the `DELETING` state, the service might continue to accept
#' records, but it doesn't make any guarantees with respect to delivering
#' the data. Therefore, as a best practice, first stop any applications
#' that are sending records before you delete a delivery stream.
#' 
#' Removal of a delivery stream that is in the `DELETING` state is a low
#' priority operation for the service. A stream may remain in the
#' `DELETING` state for several minutes. Therefore, as a best practice,
#' applications should not wait for streams in the `DELETING` state to be
#' removed.
#'
#' @usage
#' firehose_delete_delivery_stream(DeliveryStreamName, AllowForceDelete)
#'
#' @param DeliveryStreamName &#91;required&#93; The name of the delivery stream.
#' @param AllowForceDelete Set this to true if you want to delete the delivery stream even if
#' Firehose is unable to retire the grant for the CMK. Firehose might be
#' unable to retire the grant due to a customer error, such as when the CMK
#' or the grant are in an invalid state. If you force deletion, you can
#' then use the
#' [RevokeGrant](https://docs.aws.amazon.com/kms/latest/APIReference/API_RevokeGrant.html)
#' operation to revoke the grant you gave to Firehose. If a failure to
#' retire the grant happens due to an Amazon Web Services KMS issue,
#' Firehose keeps retrying the delete operation.
#' 
#' The default value is false.
#'
#' @return
#' An empty list.
#'
#' @section Request syntax:
#' ```
#' svc$delete_delivery_stream(
#'   DeliveryStreamName = "string",
#'   AllowForceDelete = TRUE|FALSE
#' )
#' ```
#'
#' @keywords internal
#'
#' @rdname firehose_delete_delivery_stream
#'
#' @aliases firehose_delete_delivery_stream
firehose_delete_delivery_stream <- function(DeliveryStreamName, AllowForceDelete = NULL) {
  op <- new_operation(
    name = "DeleteDeliveryStream",
    http_method = "POST",
    http_path = "/",
    host_prefix = "",
    paginator = list(),
    stream_api = FALSE
  )
  input <- .firehose$delete_delivery_stream_input(DeliveryStreamName = DeliveryStreamName, AllowForceDelete = AllowForceDelete)
  output <- .firehose$delete_delivery_stream_output()
  config <- get_config()
  svc <- .firehose$service(config, op)
  request <- new_request(svc, op, input, output)
  response <- send_request(request)
  return(response)
}
.firehose$operations$delete_delivery_stream <- firehose_delete_delivery_stream

#' Describes the specified delivery stream and its status
#'
#' @description
#' Describes the specified delivery stream and its status. For example,
#' after your delivery stream is created, call
#' [`describe_delivery_stream`][firehose_describe_delivery_stream] to see
#' whether the delivery stream is `ACTIVE` and therefore ready for data to
#' be sent to it.
#' 
#' If the status of a delivery stream is `CREATING_FAILED`, this status
#' doesn't change, and you can't invoke
#' [`create_delivery_stream`][firehose_create_delivery_stream] again on it.
#' However, you can invoke the
#' [`delete_delivery_stream`][firehose_delete_delivery_stream] operation to
#' delete it. If the status is `DELETING_FAILED`, you can force deletion by
#' invoking [`delete_delivery_stream`][firehose_delete_delivery_stream]
#' again but with DeleteDeliveryStreamInput$AllowForceDelete set to true.
#'
#' @usage
#' firehose_describe_delivery_stream(DeliveryStreamName, Limit,
#'   ExclusiveStartDestinationId)
#'
#' @param DeliveryStreamName &#91;required&#93; The name of the delivery stream.
#' @param Limit The limit on the number of destinations to return. You can have one
#' destination per delivery stream.
#' @param ExclusiveStartDestinationId The ID of the destination to start returning the destination
#' information. Firehose supports one destination per delivery stream.
#'
#' @return
#' A list with the following syntax:
#' ```
#' list(
#'   DeliveryStreamDescription = list(
#'     DeliveryStreamName = "string",
#'     DeliveryStreamARN = "string",
#'     DeliveryStreamStatus = "CREATING"|"CREATING_FAILED"|"DELETING"|"DELETING_FAILED"|"ACTIVE",
#'     FailureDescription = list(
#'       Type = "RETIRE_KMS_GRANT_FAILED"|"CREATE_KMS_GRANT_FAILED"|"KMS_ACCESS_DENIED"|"DISABLED_KMS_KEY"|"INVALID_KMS_KEY"|"KMS_KEY_NOT_FOUND"|"KMS_OPT_IN_REQUIRED"|"CREATE_ENI_FAILED"|"DELETE_ENI_FAILED"|"SUBNET_NOT_FOUND"|"SECURITY_GROUP_NOT_FOUND"|"ENI_ACCESS_DENIED"|"SUBNET_ACCESS_DENIED"|"SECURITY_GROUP_ACCESS_DENIED"|"UNKNOWN_ERROR",
#'       Details = "string"
#'     ),
#'     DeliveryStreamEncryptionConfiguration = list(
#'       KeyARN = "string",
#'       KeyType = "AWS_OWNED_CMK"|"CUSTOMER_MANAGED_CMK",
#'       Status = "ENABLED"|"ENABLING"|"ENABLING_FAILED"|"DISABLED"|"DISABLING"|"DISABLING_FAILED",
#'       FailureDescription = list(
#'         Type = "RETIRE_KMS_GRANT_FAILED"|"CREATE_KMS_GRANT_FAILED"|"KMS_ACCESS_DENIED"|"DISABLED_KMS_KEY"|"INVALID_KMS_KEY"|"KMS_KEY_NOT_FOUND"|"KMS_OPT_IN_REQUIRED"|"CREATE_ENI_FAILED"|"DELETE_ENI_FAILED"|"SUBNET_NOT_FOUND"|"SECURITY_GROUP_NOT_FOUND"|"ENI_ACCESS_DENIED"|"SUBNET_ACCESS_DENIED"|"SECURITY_GROUP_ACCESS_DENIED"|"UNKNOWN_ERROR",
#'         Details = "string"
#'       )
#'     ),
#'     DeliveryStreamType = "DirectPut"|"KinesisStreamAsSource"|"MSKAsSource",
#'     VersionId = "string",
#'     CreateTimestamp = as.POSIXct(
#'       "2015-01-01"
#'     ),
#'     LastUpdateTimestamp = as.POSIXct(
#'       "2015-01-01"
#'     ),
#'     Source = list(
#'       KinesisStreamSourceDescription = list(
#'         KinesisStreamARN = "string",
#'         RoleARN = "string",
#'         DeliveryStartTimestamp = as.POSIXct(
#'           "2015-01-01"
#'         )
#'       ),
#'       MSKSourceDescription = list(
#'         MSKClusterARN = "string",
#'         TopicName = "string",
#'         AuthenticationConfiguration = list(
#'           RoleARN = "string",
#'           Connectivity = "PUBLIC"|"PRIVATE"
#'         ),
#'         DeliveryStartTimestamp = as.POSIXct(
#'           "2015-01-01"
#'         ),
#'         ReadFromTimestamp = as.POSIXct(
#'           "2015-01-01"
#'         )
#'       )
#'     ),
#'     Destinations = list(
#'       list(
#'         DestinationId = "string",
#'         S3DestinationDescription = list(
#'           RoleARN = "string",
#'           BucketARN = "string",
#'           Prefix = "string",
#'           ErrorOutputPrefix = "string",
#'           BufferingHints = list(
#'             SizeInMBs = 123,
#'             IntervalInSeconds = 123
#'           ),
#'           CompressionFormat = "UNCOMPRESSED"|"GZIP"|"ZIP"|"Snappy"|"HADOOP_SNAPPY",
#'           EncryptionConfiguration = list(
#'             NoEncryptionConfig = "NoEncryption",
#'             KMSEncryptionConfig = list(
#'               AWSKMSKeyARN = "string"
#'             )
#'           ),
#'           CloudWatchLoggingOptions = list(
#'             Enabled = TRUE|FALSE,
#'             LogGroupName = "string",
#'             LogStreamName = "string"
#'           )
#'         ),
#'         ExtendedS3DestinationDescription = list(
#'           RoleARN = "string",
#'           BucketARN = "string",
#'           Prefix = "string",
#'           ErrorOutputPrefix = "string",
#'           BufferingHints = list(
#'             SizeInMBs = 123,
#'             IntervalInSeconds = 123
#'           ),
#'           CompressionFormat = "UNCOMPRESSED"|"GZIP"|"ZIP"|"Snappy"|"HADOOP_SNAPPY",
#'           EncryptionConfiguration = list(
#'             NoEncryptionConfig = "NoEncryption",
#'             KMSEncryptionConfig = list(
#'               AWSKMSKeyARN = "string"
#'             )
#'           ),
#'           CloudWatchLoggingOptions = list(
#'             Enabled = TRUE|FALSE,
#'             LogGroupName = "string",
#'             LogStreamName = "string"
#'           ),
#'           ProcessingConfiguration = list(
#'             Enabled = TRUE|FALSE,
#'             Processors = list(
#'               list(
#'                 Type = "RecordDeAggregation"|"Decompression"|"CloudWatchLogProcessing"|"Lambda"|"MetadataExtraction"|"AppendDelimiterToRecord",
#'                 Parameters = list(
#'                   list(
#'                     ParameterName = "LambdaArn"|"NumberOfRetries"|"MetadataExtractionQuery"|"JsonParsingEngine"|"RoleArn"|"BufferSizeInMBs"|"BufferIntervalInSeconds"|"SubRecordType"|"Delimiter"|"CompressionFormat"|"DataMessageExtraction",
#'                     ParameterValue = "string"
#'                   )
#'                 )
#'               )
#'             )
#'           ),
#'           S3BackupMode = "Disabled"|"Enabled",
#'           S3BackupDescription = list(
#'             RoleARN = "string",
#'             BucketARN = "string",
#'             Prefix = "string",
#'             ErrorOutputPrefix = "string",
#'             BufferingHints = list(
#'               SizeInMBs = 123,
#'               IntervalInSeconds = 123
#'             ),
#'             CompressionFormat = "UNCOMPRESSED"|"GZIP"|"ZIP"|"Snappy"|"HADOOP_SNAPPY",
#'             EncryptionConfiguration = list(
#'               NoEncryptionConfig = "NoEncryption",
#'               KMSEncryptionConfig = list(
#'                 AWSKMSKeyARN = "string"
#'               )
#'             ),
#'             CloudWatchLoggingOptions = list(
#'               Enabled = TRUE|FALSE,
#'               LogGroupName = "string",
#'               LogStreamName = "string"
#'             )
#'           ),
#'           DataFormatConversionConfiguration = list(
#'             SchemaConfiguration = list(
#'               RoleARN = "string",
#'               CatalogId = "string",
#'               DatabaseName = "string",
#'               TableName = "string",
#'               Region = "string",
#'               VersionId = "string"
#'             ),
#'             InputFormatConfiguration = list(
#'               Deserializer = list(
#'                 OpenXJsonSerDe = list(
#'                   ConvertDotsInJsonKeysToUnderscores = TRUE|FALSE,
#'                   CaseInsensitive = TRUE|FALSE,
#'                   ColumnToJsonKeyMappings = list(
#'                     "string"
#'                   )
#'                 ),
#'                 HiveJsonSerDe = list(
#'                   TimestampFormats = list(
#'                     "string"
#'                   )
#'                 )
#'               )
#'             ),
#'             OutputFormatConfiguration = list(
#'               Serializer = list(
#'                 ParquetSerDe = list(
#'                   BlockSizeBytes = 123,
#'                   PageSizeBytes = 123,
#'                   Compression = "UNCOMPRESSED"|"GZIP"|"SNAPPY",
#'                   EnableDictionaryCompression = TRUE|FALSE,
#'                   MaxPaddingBytes = 123,
#'                   WriterVersion = "V1"|"V2"
#'                 ),
#'                 OrcSerDe = list(
#'                   StripeSizeBytes = 123,
#'                   BlockSizeBytes = 123,
#'                   RowIndexStride = 123,
#'                   EnablePadding = TRUE|FALSE,
#'                   PaddingTolerance = 123.0,
#'                   Compression = "NONE"|"ZLIB"|"SNAPPY",
#'                   BloomFilterColumns = list(
#'                     "string"
#'                   ),
#'                   BloomFilterFalsePositiveProbability = 123.0,
#'                   DictionaryKeyThreshold = 123.0,
#'                   FormatVersion = "V0_11"|"V0_12"
#'                 )
#'               )
#'             ),
#'             Enabled = TRUE|FALSE
#'           ),
#'           DynamicPartitioningConfiguration = list(
#'             RetryOptions = list(
#'               DurationInSeconds = 123
#'             ),
#'             Enabled = TRUE|FALSE
#'           ),
#'           FileExtension = "string",
#'           CustomTimeZone = "string"
#'         ),
#'         RedshiftDestinationDescription = list(
#'           RoleARN = "string",
#'           ClusterJDBCURL = "string",
#'           CopyCommand = list(
#'             DataTableName = "string",
#'             DataTableColumns = "string",
#'             CopyOptions = "string"
#'           ),
#'           Username = "string",
#'           RetryOptions = list(
#'             DurationInSeconds = 123
#'           ),
#'           S3DestinationDescription = list(
#'             RoleARN = "string",
#'             BucketARN = "string",
#'             Prefix = "string",
#'             ErrorOutputPrefix = "string",
#'             BufferingHints = list(
#'               SizeInMBs = 123,
#'               IntervalInSeconds = 123
#'             ),
#'             CompressionFormat = "UNCOMPRESSED"|"GZIP"|"ZIP"|"Snappy"|"HADOOP_SNAPPY",
#'             EncryptionConfiguration = list(
#'               NoEncryptionConfig = "NoEncryption",
#'               KMSEncryptionConfig = list(
#'                 AWSKMSKeyARN = "string"
#'               )
#'             ),
#'             CloudWatchLoggingOptions = list(
#'               Enabled = TRUE|FALSE,
#'               LogGroupName = "string",
#'               LogStreamName = "string"
#'             )
#'           ),
#'           ProcessingConfiguration = list(
#'             Enabled = TRUE|FALSE,
#'             Processors = list(
#'               list(
#'                 Type = "RecordDeAggregation"|"Decompression"|"CloudWatchLogProcessing"|"Lambda"|"MetadataExtraction"|"AppendDelimiterToRecord",
#'                 Parameters = list(
#'                   list(
#'                     ParameterName = "LambdaArn"|"NumberOfRetries"|"MetadataExtractionQuery"|"JsonParsingEngine"|"RoleArn"|"BufferSizeInMBs"|"BufferIntervalInSeconds"|"SubRecordType"|"Delimiter"|"CompressionFormat"|"DataMessageExtraction",
#'                     ParameterValue = "string"
#'                   )
#'                 )
#'               )
#'             )
#'           ),
#'           S3BackupMode = "Disabled"|"Enabled",
#'           S3BackupDescription = list(
#'             RoleARN = "string",
#'             BucketARN = "string",
#'             Prefix = "string",
#'             ErrorOutputPrefix = "string",
#'             BufferingHints = list(
#'               SizeInMBs = 123,
#'               IntervalInSeconds = 123
#'             ),
#'             CompressionFormat = "UNCOMPRESSED"|"GZIP"|"ZIP"|"Snappy"|"HADOOP_SNAPPY",
#'             EncryptionConfiguration = list(
#'               NoEncryptionConfig = "NoEncryption",
#'               KMSEncryptionConfig = list(
#'                 AWSKMSKeyARN = "string"
#'               )
#'             ),
#'             CloudWatchLoggingOptions = list(
#'               Enabled = TRUE|FALSE,
#'               LogGroupName = "string",
#'               LogStreamName = "string"
#'             )
#'           ),
#'           CloudWatchLoggingOptions = list(
#'             Enabled = TRUE|FALSE,
#'             LogGroupName = "string",
#'             LogStreamName = "string"
#'           ),
#'           SecretsManagerConfiguration = list(
#'             SecretARN = "string",
#'             RoleARN = "string",
#'             Enabled = TRUE|FALSE
#'           )
#'         ),
#'         ElasticsearchDestinationDescription = list(
#'           RoleARN = "string",
#'           DomainARN = "string",
#'           ClusterEndpoint = "string",
#'           IndexName = "string",
#'           TypeName = "string",
#'           IndexRotationPeriod = "NoRotation"|"OneHour"|"OneDay"|"OneWeek"|"OneMonth",
#'           BufferingHints = list(
#'             IntervalInSeconds = 123,
#'             SizeInMBs = 123
#'           ),
#'           RetryOptions = list(
#'             DurationInSeconds = 123
#'           ),
#'           S3BackupMode = "FailedDocumentsOnly"|"AllDocuments",
#'           S3DestinationDescription = list(
#'             RoleARN = "string",
#'             BucketARN = "string",
#'             Prefix = "string",
#'             ErrorOutputPrefix = "string",
#'             BufferingHints = list(
#'               SizeInMBs = 123,
#'               IntervalInSeconds = 123
#'             ),
#'             CompressionFormat = "UNCOMPRESSED"|"GZIP"|"ZIP"|"Snappy"|"HADOOP_SNAPPY",
#'             EncryptionConfiguration = list(
#'               NoEncryptionConfig = "NoEncryption",
#'               KMSEncryptionConfig = list(
#'                 AWSKMSKeyARN = "string"
#'               )
#'             ),
#'             CloudWatchLoggingOptions = list(
#'               Enabled = TRUE|FALSE,
#'               LogGroupName = "string",
#'               LogStreamName = "string"
#'             )
#'           ),
#'           ProcessingConfiguration = list(
#'             Enabled = TRUE|FALSE,
#'             Processors = list(
#'               list(
#'                 Type = "RecordDeAggregation"|"Decompression"|"CloudWatchLogProcessing"|"Lambda"|"MetadataExtraction"|"AppendDelimiterToRecord",
#'                 Parameters = list(
#'                   list(
#'                     ParameterName = "LambdaArn"|"NumberOfRetries"|"MetadataExtractionQuery"|"JsonParsingEngine"|"RoleArn"|"BufferSizeInMBs"|"BufferIntervalInSeconds"|"SubRecordType"|"Delimiter"|"CompressionFormat"|"DataMessageExtraction",
#'                     ParameterValue = "string"
#'                   )
#'                 )
#'               )
#'             )
#'           ),
#'           CloudWatchLoggingOptions = list(
#'             Enabled = TRUE|FALSE,
#'             LogGroupName = "string",
#'             LogStreamName = "string"
#'           ),
#'           VpcConfigurationDescription = list(
#'             SubnetIds = list(
#'               "string"
#'             ),
#'             RoleARN = "string",
#'             SecurityGroupIds = list(
#'               "string"
#'             ),
#'             VpcId = "string"
#'           ),
#'           DocumentIdOptions = list(
#'             DefaultDocumentIdFormat = "FIREHOSE_DEFAULT"|"NO_DOCUMENT_ID"
#'           )
#'         ),
#'         AmazonopensearchserviceDestinationDescription = list(
#'           RoleARN = "string",
#'           DomainARN = "string",
#'           ClusterEndpoint = "string",
#'           IndexName = "string",
#'           TypeName = "string",
#'           IndexRotationPeriod = "NoRotation"|"OneHour"|"OneDay"|"OneWeek"|"OneMonth",
#'           BufferingHints = list(
#'             IntervalInSeconds = 123,
#'             SizeInMBs = 123
#'           ),
#'           RetryOptions = list(
#'             DurationInSeconds = 123
#'           ),
#'           S3BackupMode = "FailedDocumentsOnly"|"AllDocuments",
#'           S3DestinationDescription = list(
#'             RoleARN = "string",
#'             BucketARN = "string",
#'             Prefix = "string",
#'             ErrorOutputPrefix = "string",
#'             BufferingHints = list(
#'               SizeInMBs = 123,
#'               IntervalInSeconds = 123
#'             ),
#'             CompressionFormat = "UNCOMPRESSED"|"GZIP"|"ZIP"|"Snappy"|"HADOOP_SNAPPY",
#'             EncryptionConfiguration = list(
#'               NoEncryptionConfig = "NoEncryption",
#'               KMSEncryptionConfig = list(
#'                 AWSKMSKeyARN = "string"
#'               )
#'             ),
#'             CloudWatchLoggingOptions = list(
#'               Enabled = TRUE|FALSE,
#'               LogGroupName = "string",
#'               LogStreamName = "string"
#'             )
#'           ),
#'           ProcessingConfiguration = list(
#'             Enabled = TRUE|FALSE,
#'             Processors = list(
#'               list(
#'                 Type = "RecordDeAggregation"|"Decompression"|"CloudWatchLogProcessing"|"Lambda"|"MetadataExtraction"|"AppendDelimiterToRecord",
#'                 Parameters = list(
#'                   list(
#'                     ParameterName = "LambdaArn"|"NumberOfRetries"|"MetadataExtractionQuery"|"JsonParsingEngine"|"RoleArn"|"BufferSizeInMBs"|"BufferIntervalInSeconds"|"SubRecordType"|"Delimiter"|"CompressionFormat"|"DataMessageExtraction",
#'                     ParameterValue = "string"
#'                   )
#'                 )
#'               )
#'             )
#'           ),
#'           CloudWatchLoggingOptions = list(
#'             Enabled = TRUE|FALSE,
#'             LogGroupName = "string",
#'             LogStreamName = "string"
#'           ),
#'           VpcConfigurationDescription = list(
#'             SubnetIds = list(
#'               "string"
#'             ),
#'             RoleARN = "string",
#'             SecurityGroupIds = list(
#'               "string"
#'             ),
#'             VpcId = "string"
#'           ),
#'           DocumentIdOptions = list(
#'             DefaultDocumentIdFormat = "FIREHOSE_DEFAULT"|"NO_DOCUMENT_ID"
#'           )
#'         ),
#'         SplunkDestinationDescription = list(
#'           HECEndpoint = "string",
#'           HECEndpointType = "Raw"|"Event",
#'           HECToken = "string",
#'           HECAcknowledgmentTimeoutInSeconds = 123,
#'           RetryOptions = list(
#'             DurationInSeconds = 123
#'           ),
#'           S3BackupMode = "FailedEventsOnly"|"AllEvents",
#'           S3DestinationDescription = list(
#'             RoleARN = "string",
#'             BucketARN = "string",
#'             Prefix = "string",
#'             ErrorOutputPrefix = "string",
#'             BufferingHints = list(
#'               SizeInMBs = 123,
#'               IntervalInSeconds = 123
#'             ),
#'             CompressionFormat = "UNCOMPRESSED"|"GZIP"|"ZIP"|"Snappy"|"HADOOP_SNAPPY",
#'             EncryptionConfiguration = list(
#'               NoEncryptionConfig = "NoEncryption",
#'               KMSEncryptionConfig = list(
#'                 AWSKMSKeyARN = "string"
#'               )
#'             ),
#'             CloudWatchLoggingOptions = list(
#'               Enabled = TRUE|FALSE,
#'               LogGroupName = "string",
#'               LogStreamName = "string"
#'             )
#'           ),
#'           ProcessingConfiguration = list(
#'             Enabled = TRUE|FALSE,
#'             Processors = list(
#'               list(
#'                 Type = "RecordDeAggregation"|"Decompression"|"CloudWatchLogProcessing"|"Lambda"|"MetadataExtraction"|"AppendDelimiterToRecord",
#'                 Parameters = list(
#'                   list(
#'                     ParameterName = "LambdaArn"|"NumberOfRetries"|"MetadataExtractionQuery"|"JsonParsingEngine"|"RoleArn"|"BufferSizeInMBs"|"BufferIntervalInSeconds"|"SubRecordType"|"Delimiter"|"CompressionFormat"|"DataMessageExtraction",
#'                     ParameterValue = "string"
#'                   )
#'                 )
#'               )
#'             )
#'           ),
#'           CloudWatchLoggingOptions = list(
#'             Enabled = TRUE|FALSE,
#'             LogGroupName = "string",
#'             LogStreamName = "string"
#'           ),
#'           BufferingHints = list(
#'             IntervalInSeconds = 123,
#'             SizeInMBs = 123
#'           ),
#'           SecretsManagerConfiguration = list(
#'             SecretARN = "string",
#'             RoleARN = "string",
#'             Enabled = TRUE|FALSE
#'           )
#'         ),
#'         HttpEndpointDestinationDescription = list(
#'           EndpointConfiguration = list(
#'             Url = "string",
#'             Name = "string"
#'           ),
#'           BufferingHints = list(
#'             SizeInMBs = 123,
#'             IntervalInSeconds = 123
#'           ),
#'           CloudWatchLoggingOptions = list(
#'             Enabled = TRUE|FALSE,
#'             LogGroupName = "string",
#'             LogStreamName = "string"
#'           ),
#'           RequestConfiguration = list(
#'             ContentEncoding = "NONE"|"GZIP",
#'             CommonAttributes = list(
#'               list(
#'                 AttributeName = "string",
#'                 AttributeValue = "string"
#'               )
#'             )
#'           ),
#'           ProcessingConfiguration = list(
#'             Enabled = TRUE|FALSE,
#'             Processors = list(
#'               list(
#'                 Type = "RecordDeAggregation"|"Decompression"|"CloudWatchLogProcessing"|"Lambda"|"MetadataExtraction"|"AppendDelimiterToRecord",
#'                 Parameters = list(
#'                   list(
#'                     ParameterName = "LambdaArn"|"NumberOfRetries"|"MetadataExtractionQuery"|"JsonParsingEngine"|"RoleArn"|"BufferSizeInMBs"|"BufferIntervalInSeconds"|"SubRecordType"|"Delimiter"|"CompressionFormat"|"DataMessageExtraction",
#'                     ParameterValue = "string"
#'                   )
#'                 )
#'               )
#'             )
#'           ),
#'           RoleARN = "string",
#'           RetryOptions = list(
#'             DurationInSeconds = 123
#'           ),
#'           S3BackupMode = "FailedDataOnly"|"AllData",
#'           S3DestinationDescription = list(
#'             RoleARN = "string",
#'             BucketARN = "string",
#'             Prefix = "string",
#'             ErrorOutputPrefix = "string",
#'             BufferingHints = list(
#'               SizeInMBs = 123,
#'               IntervalInSeconds = 123
#'             ),
#'             CompressionFormat = "UNCOMPRESSED"|"GZIP"|"ZIP"|"Snappy"|"HADOOP_SNAPPY",
#'             EncryptionConfiguration = list(
#'               NoEncryptionConfig = "NoEncryption",
#'               KMSEncryptionConfig = list(
#'                 AWSKMSKeyARN = "string"
#'               )
#'             ),
#'             CloudWatchLoggingOptions = list(
#'               Enabled = TRUE|FALSE,
#'               LogGroupName = "string",
#'               LogStreamName = "string"
#'             )
#'           ),
#'           SecretsManagerConfiguration = list(
#'             SecretARN = "string",
#'             RoleARN = "string",
#'             Enabled = TRUE|FALSE
#'           )
#'         ),
#'         SnowflakeDestinationDescription = list(
#'           AccountUrl = "string",
#'           User = "string",
#'           Database = "string",
#'           Schema = "string",
#'           Table = "string",
#'           SnowflakeRoleConfiguration = list(
#'             Enabled = TRUE|FALSE,
#'             SnowflakeRole = "string"
#'           ),
#'           DataLoadingOption = "JSON_MAPPING"|"VARIANT_CONTENT_MAPPING"|"VARIANT_CONTENT_AND_METADATA_MAPPING",
#'           MetaDataColumnName = "string",
#'           ContentColumnName = "string",
#'           SnowflakeVpcConfiguration = list(
#'             PrivateLinkVpceId = "string"
#'           ),
#'           CloudWatchLoggingOptions = list(
#'             Enabled = TRUE|FALSE,
#'             LogGroupName = "string",
#'             LogStreamName = "string"
#'           ),
#'           ProcessingConfiguration = list(
#'             Enabled = TRUE|FALSE,
#'             Processors = list(
#'               list(
#'                 Type = "RecordDeAggregation"|"Decompression"|"CloudWatchLogProcessing"|"Lambda"|"MetadataExtraction"|"AppendDelimiterToRecord",
#'                 Parameters = list(
#'                   list(
#'                     ParameterName = "LambdaArn"|"NumberOfRetries"|"MetadataExtractionQuery"|"JsonParsingEngine"|"RoleArn"|"BufferSizeInMBs"|"BufferIntervalInSeconds"|"SubRecordType"|"Delimiter"|"CompressionFormat"|"DataMessageExtraction",
#'                     ParameterValue = "string"
#'                   )
#'                 )
#'               )
#'             )
#'           ),
#'           RoleARN = "string",
#'           RetryOptions = list(
#'             DurationInSeconds = 123
#'           ),
#'           S3BackupMode = "FailedDataOnly"|"AllData",
#'           S3DestinationDescription = list(
#'             RoleARN = "string",
#'             BucketARN = "string",
#'             Prefix = "string",
#'             ErrorOutputPrefix = "string",
#'             BufferingHints = list(
#'               SizeInMBs = 123,
#'               IntervalInSeconds = 123
#'             ),
#'             CompressionFormat = "UNCOMPRESSED"|"GZIP"|"ZIP"|"Snappy"|"HADOOP_SNAPPY",
#'             EncryptionConfiguration = list(
#'               NoEncryptionConfig = "NoEncryption",
#'               KMSEncryptionConfig = list(
#'                 AWSKMSKeyARN = "string"
#'               )
#'             ),
#'             CloudWatchLoggingOptions = list(
#'               Enabled = TRUE|FALSE,
#'               LogGroupName = "string",
#'               LogStreamName = "string"
#'             )
#'           ),
#'           SecretsManagerConfiguration = list(
#'             SecretARN = "string",
#'             RoleARN = "string",
#'             Enabled = TRUE|FALSE
#'           ),
#'           BufferingHints = list(
#'             SizeInMBs = 123,
#'             IntervalInSeconds = 123
#'           )
#'         ),
#'         AmazonOpenSearchServerlessDestinationDescription = list(
#'           RoleARN = "string",
#'           CollectionEndpoint = "string",
#'           IndexName = "string",
#'           BufferingHints = list(
#'             IntervalInSeconds = 123,
#'             SizeInMBs = 123
#'           ),
#'           RetryOptions = list(
#'             DurationInSeconds = 123
#'           ),
#'           S3BackupMode = "FailedDocumentsOnly"|"AllDocuments",
#'           S3DestinationDescription = list(
#'             RoleARN = "string",
#'             BucketARN = "string",
#'             Prefix = "string",
#'             ErrorOutputPrefix = "string",
#'             BufferingHints = list(
#'               SizeInMBs = 123,
#'               IntervalInSeconds = 123
#'             ),
#'             CompressionFormat = "UNCOMPRESSED"|"GZIP"|"ZIP"|"Snappy"|"HADOOP_SNAPPY",
#'             EncryptionConfiguration = list(
#'               NoEncryptionConfig = "NoEncryption",
#'               KMSEncryptionConfig = list(
#'                 AWSKMSKeyARN = "string"
#'               )
#'             ),
#'             CloudWatchLoggingOptions = list(
#'               Enabled = TRUE|FALSE,
#'               LogGroupName = "string",
#'               LogStreamName = "string"
#'             )
#'           ),
#'           ProcessingConfiguration = list(
#'             Enabled = TRUE|FALSE,
#'             Processors = list(
#'               list(
#'                 Type = "RecordDeAggregation"|"Decompression"|"CloudWatchLogProcessing"|"Lambda"|"MetadataExtraction"|"AppendDelimiterToRecord",
#'                 Parameters = list(
#'                   list(
#'                     ParameterName = "LambdaArn"|"NumberOfRetries"|"MetadataExtractionQuery"|"JsonParsingEngine"|"RoleArn"|"BufferSizeInMBs"|"BufferIntervalInSeconds"|"SubRecordType"|"Delimiter"|"CompressionFormat"|"DataMessageExtraction",
#'                     ParameterValue = "string"
#'                   )
#'                 )
#'               )
#'             )
#'           ),
#'           CloudWatchLoggingOptions = list(
#'             Enabled = TRUE|FALSE,
#'             LogGroupName = "string",
#'             LogStreamName = "string"
#'           ),
#'           VpcConfigurationDescription = list(
#'             SubnetIds = list(
#'               "string"
#'             ),
#'             RoleARN = "string",
#'             SecurityGroupIds = list(
#'               "string"
#'             ),
#'             VpcId = "string"
#'           )
#'         ),
#'         IcebergDestinationDescription = list(
#'           DestinationTableConfigurationList = list(
#'             list(
#'               DestinationTableName = "string",
#'               DestinationDatabaseName = "string",
#'               UniqueKeys = list(
#'                 "string"
#'               ),
#'               S3ErrorOutputPrefix = "string"
#'             )
#'           ),
#'           BufferingHints = list(
#'             SizeInMBs = 123,
#'             IntervalInSeconds = 123
#'           ),
#'           CloudWatchLoggingOptions = list(
#'             Enabled = TRUE|FALSE,
#'             LogGroupName = "string",
#'             LogStreamName = "string"
#'           ),
#'           ProcessingConfiguration = list(
#'             Enabled = TRUE|FALSE,
#'             Processors = list(
#'               list(
#'                 Type = "RecordDeAggregation"|"Decompression"|"CloudWatchLogProcessing"|"Lambda"|"MetadataExtraction"|"AppendDelimiterToRecord",
#'                 Parameters = list(
#'                   list(
#'                     ParameterName = "LambdaArn"|"NumberOfRetries"|"MetadataExtractionQuery"|"JsonParsingEngine"|"RoleArn"|"BufferSizeInMBs"|"BufferIntervalInSeconds"|"SubRecordType"|"Delimiter"|"CompressionFormat"|"DataMessageExtraction",
#'                     ParameterValue = "string"
#'                   )
#'                 )
#'               )
#'             )
#'           ),
#'           S3BackupMode = "FailedDataOnly"|"AllData",
#'           RetryOptions = list(
#'             DurationInSeconds = 123
#'           ),
#'           RoleARN = "string",
#'           CatalogConfiguration = list(
#'             CatalogARN = "string"
#'           ),
#'           S3DestinationDescription = list(
#'             RoleARN = "string",
#'             BucketARN = "string",
#'             Prefix = "string",
#'             ErrorOutputPrefix = "string",
#'             BufferingHints = list(
#'               SizeInMBs = 123,
#'               IntervalInSeconds = 123
#'             ),
#'             CompressionFormat = "UNCOMPRESSED"|"GZIP"|"ZIP"|"Snappy"|"HADOOP_SNAPPY",
#'             EncryptionConfiguration = list(
#'               NoEncryptionConfig = "NoEncryption",
#'               KMSEncryptionConfig = list(
#'                 AWSKMSKeyARN = "string"
#'               )
#'             ),
#'             CloudWatchLoggingOptions = list(
#'               Enabled = TRUE|FALSE,
#'               LogGroupName = "string",
#'               LogStreamName = "string"
#'             )
#'           )
#'         )
#'       )
#'     ),
#'     HasMoreDestinations = TRUE|FALSE
#'   )
#' )
#' ```
#'
#' @section Request syntax:
#' ```
#' svc$describe_delivery_stream(
#'   DeliveryStreamName = "string",
#'   Limit = 123,
#'   ExclusiveStartDestinationId = "string"
#' )
#' ```
#'
#' @keywords internal
#'
#' @rdname firehose_describe_delivery_stream
#'
#' @aliases firehose_describe_delivery_stream
firehose_describe_delivery_stream <- function(DeliveryStreamName, Limit = NULL, ExclusiveStartDestinationId = NULL) {
  op <- new_operation(
    name = "DescribeDeliveryStream",
    http_method = "POST",
    http_path = "/",
    host_prefix = "",
    paginator = list(),
    stream_api = FALSE
  )
  input <- .firehose$describe_delivery_stream_input(DeliveryStreamName = DeliveryStreamName, Limit = Limit, ExclusiveStartDestinationId = ExclusiveStartDestinationId)
  output <- .firehose$describe_delivery_stream_output()
  config <- get_config()
  svc <- .firehose$service(config, op)
  request <- new_request(svc, op, input, output)
  response <- send_request(request)
  return(response)
}
.firehose$operations$describe_delivery_stream <- firehose_describe_delivery_stream

#' Lists your delivery streams in alphabetical order of their names
#'
#' @description
#' Lists your delivery streams in alphabetical order of their names.
#' 
#' The number of delivery streams might be too large to return using a
#' single call to
#' [`list_delivery_streams`][firehose_list_delivery_streams]. You can limit
#' the number of delivery streams returned, using the `Limit` parameter. To
#' determine whether there are more delivery streams to list, check the
#' value of `HasMoreDeliveryStreams` in the output. If there are more
#' delivery streams to list, you can request them by calling this operation
#' again and setting the `ExclusiveStartDeliveryStreamName` parameter to
#' the name of the last delivery stream returned in the last call.
#'
#' @usage
#' firehose_list_delivery_streams(Limit, DeliveryStreamType,
#'   ExclusiveStartDeliveryStreamName)
#'
#' @param Limit The maximum number of delivery streams to list. The default value is 10.
#' @param DeliveryStreamType The delivery stream type. This can be one of the following values:
#' 
#' - `DirectPut`: Provider applications access the delivery stream
#'   directly.
#' 
#' - `KinesisStreamAsSource`: The delivery stream uses a Kinesis data
#'   stream as a source.
#' 
#' This parameter is optional. If this parameter is omitted, delivery
#' streams of all types are returned.
#' @param ExclusiveStartDeliveryStreamName The list of delivery streams returned by this call to
#' [`list_delivery_streams`][firehose_list_delivery_streams] will start
#' with the delivery stream whose name comes alphabetically immediately
#' after the name you specify in `ExclusiveStartDeliveryStreamName`.
#'
#' @return
#' A list with the following syntax:
#' ```
#' list(
#'   DeliveryStreamNames = list(
#'     "string"
#'   ),
#'   HasMoreDeliveryStreams = TRUE|FALSE
#' )
#' ```
#'
#' @section Request syntax:
#' ```
#' svc$list_delivery_streams(
#'   Limit = 123,
#'   DeliveryStreamType = "DirectPut"|"KinesisStreamAsSource"|"MSKAsSource",
#'   ExclusiveStartDeliveryStreamName = "string"
#' )
#' ```
#'
#' @keywords internal
#'
#' @rdname firehose_list_delivery_streams
#'
#' @aliases firehose_list_delivery_streams
firehose_list_delivery_streams <- function(Limit = NULL, DeliveryStreamType = NULL, ExclusiveStartDeliveryStreamName = NULL) {
  op <- new_operation(
    name = "ListDeliveryStreams",
    http_method = "POST",
    http_path = "/",
    host_prefix = "",
    paginator = list(),
    stream_api = FALSE
  )
  input <- .firehose$list_delivery_streams_input(Limit = Limit, DeliveryStreamType = DeliveryStreamType, ExclusiveStartDeliveryStreamName = ExclusiveStartDeliveryStreamName)
  output <- .firehose$list_delivery_streams_output()
  config <- get_config()
  svc <- .firehose$service(config, op)
  request <- new_request(svc, op, input, output)
  response <- send_request(request)
  return(response)
}
.firehose$operations$list_delivery_streams <- firehose_list_delivery_streams

#' Lists the tags for the specified delivery stream
#'
#' @description
#' Lists the tags for the specified delivery stream. This operation has a
#' limit of five transactions per second per account.
#'
#' @usage
#' firehose_list_tags_for_delivery_stream(DeliveryStreamName,
#'   ExclusiveStartTagKey, Limit)
#'
#' @param DeliveryStreamName &#91;required&#93; The name of the delivery stream whose tags you want to list.
#' @param ExclusiveStartTagKey The key to use as the starting point for the list of tags. If you set
#' this parameter,
#' [`list_tags_for_delivery_stream`][firehose_list_tags_for_delivery_stream]
#' gets all tags that occur after `ExclusiveStartTagKey`.
#' @param Limit The number of tags to return. If this number is less than the total
#' number of tags associated with the delivery stream, `HasMoreTags` is set
#' to `true` in the response. To list additional tags, set
#' `ExclusiveStartTagKey` to the last key in the response.
#'
#' @return
#' A list with the following syntax:
#' ```
#' list(
#'   Tags = list(
#'     list(
#'       Key = "string",
#'       Value = "string"
#'     )
#'   ),
#'   HasMoreTags = TRUE|FALSE
#' )
#' ```
#'
#' @section Request syntax:
#' ```
#' svc$list_tags_for_delivery_stream(
#'   DeliveryStreamName = "string",
#'   ExclusiveStartTagKey = "string",
#'   Limit = 123
#' )
#' ```
#'
#' @keywords internal
#'
#' @rdname firehose_list_tags_for_delivery_stream
#'
#' @aliases firehose_list_tags_for_delivery_stream
firehose_list_tags_for_delivery_stream <- function(DeliveryStreamName, ExclusiveStartTagKey = NULL, Limit = NULL) {
  op <- new_operation(
    name = "ListTagsForDeliveryStream",
    http_method = "POST",
    http_path = "/",
    host_prefix = "",
    paginator = list(),
    stream_api = FALSE
  )
  input <- .firehose$list_tags_for_delivery_stream_input(DeliveryStreamName = DeliveryStreamName, ExclusiveStartTagKey = ExclusiveStartTagKey, Limit = Limit)
  output <- .firehose$list_tags_for_delivery_stream_output()
  config <- get_config()
  svc <- .firehose$service(config, op)
  request <- new_request(svc, op, input, output)
  response <- send_request(request)
  return(response)
}
.firehose$operations$list_tags_for_delivery_stream <- firehose_list_tags_for_delivery_stream

#' Writes a single data record into an Amazon Firehose delivery stream
#'
#' @description
#' Writes a single data record into an Amazon Firehose delivery stream. To
#' write multiple data records into a delivery stream, use
#' [`put_record_batch`][firehose_put_record_batch]. Applications using
#' these operations are referred to as producers.
#' 
#' By default, each delivery stream can take in up to 2,000 transactions
#' per second, 5,000 records per second, or 5 MB per second. If you use
#' [`put_record`][firehose_put_record] and
#' [`put_record_batch`][firehose_put_record_batch], the limits are an
#' aggregate across these two operations for each delivery stream. For more
#' information about limits and how to request an increase, see [Amazon
#' Firehose
#' Limits](https://docs.aws.amazon.com/firehose/latest/dev/limits.html).
#' 
#' Firehose accumulates and publishes a particular metric for a customer
#' account in one minute intervals. It is possible that the bursts of
#' incoming bytes/records ingested to a delivery stream last only for a few
#' seconds. Due to this, the actual spikes in the traffic might not be
#' fully visible in the customer's 1 minute CloudWatch metrics.
#' 
#' You must specify the name of the delivery stream and the data record
#' when using [`put_record`][firehose_put_record]. The data record consists
#' of a data blob that can be up to 1,000 KiB in size, and any kind of
#' data. For example, it can be a segment from a log file, geographic
#' location data, website clickstream data, and so on.
#' 
#' Firehose buffers records before delivering them to the destination. To
#' disambiguate the data blobs at the destination, a common solution is to
#' use delimiters in the data, such as a newline (`\\n`) or some other
#' character unique within the data. This allows the consumer application
#' to parse individual data items when reading the data from the
#' destination.
#' 
#' The [`put_record`][firehose_put_record] operation returns a `RecordId`,
#' which is a unique string assigned to each record. Producer applications
#' can use this ID for purposes such as auditability and investigation.
#' 
#' If the [`put_record`][firehose_put_record] operation throws a
#' `ServiceUnavailableException`, the API is automatically reinvoked
#' (retried) 3 times. If the exception persists, it is possible that the
#' throughput limits have been exceeded for the delivery stream.
#' 
#' Re-invoking the Put API operations (for example, PutRecord and
#' PutRecordBatch) can result in data duplicates. For larger data assets,
#' allow for a longer time out before retrying Put API operations.
#' 
#' Data records sent to Firehose are stored for 24 hours from the time they
#' are added to a delivery stream as it tries to send the records to the
#' destination. If the destination is unreachable for more than 24 hours,
#' the data is no longer available.
#' 
#' Don't concatenate two or more base64 strings to form the data fields of
#' your records. Instead, concatenate the raw data, then perform base64
#' encoding.
#'
#' @usage
#' firehose_put_record(DeliveryStreamName, Record)
#'
#' @param DeliveryStreamName &#91;required&#93; The name of the delivery stream.
#' @param Record &#91;required&#93; The record.
#'
#' @return
#' A list with the following syntax:
#' ```
#' list(
#'   RecordId = "string",
#'   Encrypted = TRUE|FALSE
#' )
#' ```
#'
#' @section Request syntax:
#' ```
#' svc$put_record(
#'   DeliveryStreamName = "string",
#'   Record = list(
#'     Data = raw
#'   )
#' )
#' ```
#'
#' @keywords internal
#'
#' @rdname firehose_put_record
#'
#' @aliases firehose_put_record
firehose_put_record <- function(DeliveryStreamName, Record) {
  op <- new_operation(
    name = "PutRecord",
    http_method = "POST",
    http_path = "/",
    host_prefix = "",
    paginator = list(),
    stream_api = FALSE
  )
  input <- .firehose$put_record_input(DeliveryStreamName = DeliveryStreamName, Record = Record)
  output <- .firehose$put_record_output()
  config <- get_config()
  svc <- .firehose$service(config, op)
  request <- new_request(svc, op, input, output)
  response <- send_request(request)
  return(response)
}
.firehose$operations$put_record <- firehose_put_record

#' Writes multiple data records into a delivery stream in a single call,
#' which can achieve higher throughput per producer than when writing
#' single records
#'
#' @description
#' Writes multiple data records into a delivery stream in a single call,
#' which can achieve higher throughput per producer than when writing
#' single records. To write single data records into a delivery stream, use
#' [`put_record`][firehose_put_record]. Applications using these operations
#' are referred to as producers.
#' 
#' Firehose accumulates and publishes a particular metric for a customer
#' account in one minute intervals. It is possible that the bursts of
#' incoming bytes/records ingested to a delivery stream last only for a few
#' seconds. Due to this, the actual spikes in the traffic might not be
#' fully visible in the customer's 1 minute CloudWatch metrics.
#' 
#' For information about service quota, see [Amazon Firehose
#' Quota](https://docs.aws.amazon.com/firehose/latest/dev/limits.html).
#' 
#' Each [`put_record_batch`][firehose_put_record_batch] request supports up
#' to 500 records. Each record in the request can be as large as 1,000 KB
#' (before base64 encoding), up to a limit of 4 MB for the entire request.
#' These limits cannot be changed.
#' 
#' You must specify the name of the delivery stream and the data record
#' when using [`put_record`][firehose_put_record]. The data record consists
#' of a data blob that can be up to 1,000 KB in size, and any kind of data.
#' For example, it could be a segment from a log file, geographic location
#' data, website clickstream data, and so on.
#' 
#' Firehose buffers records before delivering them to the destination. To
#' disambiguate the data blobs at the destination, a common solution is to
#' use delimiters in the data, such as a newline (`\\n`) or some other
#' character unique within the data. This allows the consumer application
#' to parse individual data items when reading the data from the
#' destination.
#' 
#' The [`put_record_batch`][firehose_put_record_batch] response includes a
#' count of failed records, `FailedPutCount`, and an array of responses,
#' `RequestResponses`. Even if the
#' [`put_record_batch`][firehose_put_record_batch] call succeeds, the value
#' of `FailedPutCount` may be greater than 0, indicating that there are
#' records for which the operation didn't succeed. Each entry in the
#' `RequestResponses` array provides additional information about the
#' processed record. It directly correlates with a record in the request
#' array using the same ordering, from the top to the bottom. The response
#' array always includes the same number of records as the request array.
#' `RequestResponses` includes both successfully and unsuccessfully
#' processed records. Firehose tries to process all records in each
#' [`put_record_batch`][firehose_put_record_batch] request. A single record
#' failure does not stop the processing of subsequent records.
#' 
#' A successfully processed record includes a `RecordId` value, which is
#' unique for the record. An unsuccessfully processed record includes
#' `ErrorCode` and `ErrorMessage` values. `ErrorCode` reflects the type of
#' error, and is one of the following values: `ServiceUnavailableException`
#' or `InternalFailure`. `ErrorMessage` provides more detailed information
#' about the error.
#' 
#' If there is an internal server error or a timeout, the write might have
#' completed or it might have failed. If `FailedPutCount` is greater than
#' 0, retry the request, resending only those records that might have
#' failed processing. This minimizes the possible duplicate records and
#' also reduces the total bytes sent (and corresponding charges). We
#' recommend that you handle any duplicates at the destination.
#' 
#' If [`put_record_batch`][firehose_put_record_batch] throws
#' `ServiceUnavailableException`, the API is automatically reinvoked
#' (retried) 3 times. If the exception persists, it is possible that the
#' throughput limits have been exceeded for the delivery stream.
#' 
#' Re-invoking the Put API operations (for example, PutRecord and
#' PutRecordBatch) can result in data duplicates. For larger data assets,
#' allow for a longer time out before retrying Put API operations.
#' 
#' Data records sent to Firehose are stored for 24 hours from the time they
#' are added to a delivery stream as it attempts to send the records to the
#' destination. If the destination is unreachable for more than 24 hours,
#' the data is no longer available.
#' 
#' Don't concatenate two or more base64 strings to form the data fields of
#' your records. Instead, concatenate the raw data, then perform base64
#' encoding.
#'
#' @usage
#' firehose_put_record_batch(DeliveryStreamName, Records)
#'
#' @param DeliveryStreamName &#91;required&#93; The name of the delivery stream.
#' @param Records &#91;required&#93; One or more records.
#'
#' @return
#' A list with the following syntax:
#' ```
#' list(
#'   FailedPutCount = 123,
#'   Encrypted = TRUE|FALSE,
#'   RequestResponses = list(
#'     list(
#'       RecordId = "string",
#'       ErrorCode = "string",
#'       ErrorMessage = "string"
#'     )
#'   )
#' )
#' ```
#'
#' @section Request syntax:
#' ```
#' svc$put_record_batch(
#'   DeliveryStreamName = "string",
#'   Records = list(
#'     list(
#'       Data = raw
#'     )
#'   )
#' )
#' ```
#'
#' @keywords internal
#'
#' @rdname firehose_put_record_batch
#'
#' @aliases firehose_put_record_batch
firehose_put_record_batch <- function(DeliveryStreamName, Records) {
  op <- new_operation(
    name = "PutRecordBatch",
    http_method = "POST",
    http_path = "/",
    host_prefix = "",
    paginator = list(),
    stream_api = FALSE
  )
  input <- .firehose$put_record_batch_input(DeliveryStreamName = DeliveryStreamName, Records = Records)
  output <- .firehose$put_record_batch_output()
  config <- get_config()
  svc <- .firehose$service(config, op)
  request <- new_request(svc, op, input, output)
  response <- send_request(request)
  return(response)
}
.firehose$operations$put_record_batch <- firehose_put_record_batch

#' Enables server-side encryption (SSE) for the delivery stream
#'
#' @description
#' Enables server-side encryption (SSE) for the delivery stream.
#' 
#' This operation is asynchronous. It returns immediately. When you invoke
#' it, Firehose first sets the encryption status of the stream to
#' `ENABLING`, and then to `ENABLED`. The encryption status of a delivery
#' stream is the `Status` property in
#' DeliveryStreamEncryptionConfiguration. If the operation fails, the
#' encryption status changes to `ENABLING_FAILED`. You can continue to read
#' and write data to your delivery stream while the encryption status is
#' `ENABLING`, but the data is not encrypted. It can take up to 5 seconds
#' after the encryption status changes to `ENABLED` before all records
#' written to the delivery stream are encrypted. To find out whether a
#' record or a batch of records was encrypted, check the response elements
#' PutRecordOutput$Encrypted and PutRecordBatchOutput$Encrypted,
#' respectively.
#' 
#' To check the encryption status of a delivery stream, use
#' [`describe_delivery_stream`][firehose_describe_delivery_stream].
#' 
#' Even if encryption is currently enabled for a delivery stream, you can
#' still invoke this operation on it to change the ARN of the CMK or both
#' its type and ARN. If you invoke this method to change the CMK, and the
#' old CMK is of type `CUSTOMER_MANAGED_CMK`, Firehose schedules the grant
#' it had on the old CMK for retirement. If the new CMK is of type
#' `CUSTOMER_MANAGED_CMK`, Firehose creates a grant that enables it to use
#' the new CMK to encrypt and decrypt data and to manage the grant.
#' 
#' For the KMS grant creation to be successful, the Firehose API operations
#' [`start_delivery_stream_encryption`][firehose_start_delivery_stream_encryption]
#' and [`create_delivery_stream`][firehose_create_delivery_stream] should
#' not be called with session credentials that are more than 6 hours old.
#' 
#' If a delivery stream already has encryption enabled and then you invoke
#' this operation to change the ARN of the CMK or both its type and ARN and
#' you get `ENABLING_FAILED`, this only means that the attempt to change
#' the CMK failed. In this case, encryption remains enabled with the old
#' CMK.
#' 
#' If the encryption status of your delivery stream is `ENABLING_FAILED`,
#' you can invoke this operation again with a valid CMK. The CMK must be
#' enabled and the key policy mustn't explicitly deny the permission for
#' Firehose to invoke KMS encrypt and decrypt operations.
#' 
#' You can enable SSE for a delivery stream only if it's a delivery stream
#' that uses `DirectPut` as its source.
#' 
#' The
#' [`start_delivery_stream_encryption`][firehose_start_delivery_stream_encryption]
#' and
#' [`stop_delivery_stream_encryption`][firehose_stop_delivery_stream_encryption]
#' operations have a combined limit of 25 calls per delivery stream per 24
#' hours. For example, you reach the limit if you call
#' [`start_delivery_stream_encryption`][firehose_start_delivery_stream_encryption]
#' 13 times and
#' [`stop_delivery_stream_encryption`][firehose_stop_delivery_stream_encryption]
#' 12 times for the same delivery stream in a 24-hour period.
#'
#' @usage
#' firehose_start_delivery_stream_encryption(DeliveryStreamName,
#'   DeliveryStreamEncryptionConfigurationInput)
#'
#' @param DeliveryStreamName &#91;required&#93; The name of the delivery stream for which you want to enable server-side
#' encryption (SSE).
#' @param DeliveryStreamEncryptionConfigurationInput Used to specify the type and Amazon Resource Name (ARN) of the KMS key
#' needed for Server-Side Encryption (SSE).
#'
#' @return
#' An empty list.
#'
#' @section Request syntax:
#' ```
#' svc$start_delivery_stream_encryption(
#'   DeliveryStreamName = "string",
#'   DeliveryStreamEncryptionConfigurationInput = list(
#'     KeyARN = "string",
#'     KeyType = "AWS_OWNED_CMK"|"CUSTOMER_MANAGED_CMK"
#'   )
#' )
#' ```
#'
#' @keywords internal
#'
#' @rdname firehose_start_delivery_stream_encryption
#'
#' @aliases firehose_start_delivery_stream_encryption
firehose_start_delivery_stream_encryption <- function(DeliveryStreamName, DeliveryStreamEncryptionConfigurationInput = NULL) {
  op <- new_operation(
    name = "StartDeliveryStreamEncryption",
    http_method = "POST",
    http_path = "/",
    host_prefix = "",
    paginator = list(),
    stream_api = FALSE
  )
  input <- .firehose$start_delivery_stream_encryption_input(DeliveryStreamName = DeliveryStreamName, DeliveryStreamEncryptionConfigurationInput = DeliveryStreamEncryptionConfigurationInput)
  output <- .firehose$start_delivery_stream_encryption_output()
  config <- get_config()
  svc <- .firehose$service(config, op)
  request <- new_request(svc, op, input, output)
  response <- send_request(request)
  return(response)
}
.firehose$operations$start_delivery_stream_encryption <- firehose_start_delivery_stream_encryption

#' Disables server-side encryption (SSE) for the delivery stream
#'
#' @description
#' Disables server-side encryption (SSE) for the delivery stream.
#' 
#' This operation is asynchronous. It returns immediately. When you invoke
#' it, Firehose first sets the encryption status of the stream to
#' `DISABLING`, and then to `DISABLED`. You can continue to read and write
#' data to your stream while its status is `DISABLING`. It can take up to 5
#' seconds after the encryption status changes to `DISABLED` before all
#' records written to the delivery stream are no longer subject to
#' encryption. To find out whether a record or a batch of records was
#' encrypted, check the response elements PutRecordOutput$Encrypted and
#' PutRecordBatchOutput$Encrypted, respectively.
#' 
#' To check the encryption state of a delivery stream, use
#' [`describe_delivery_stream`][firehose_describe_delivery_stream].
#' 
#' If SSE is enabled using a customer managed CMK and then you invoke
#' [`stop_delivery_stream_encryption`][firehose_stop_delivery_stream_encryption],
#' Firehose schedules the related KMS grant for retirement and then retires
#' it after it ensures that it is finished delivering records to the
#' destination.
#' 
#' The
#' [`start_delivery_stream_encryption`][firehose_start_delivery_stream_encryption]
#' and
#' [`stop_delivery_stream_encryption`][firehose_stop_delivery_stream_encryption]
#' operations have a combined limit of 25 calls per delivery stream per 24
#' hours. For example, you reach the limit if you call
#' [`start_delivery_stream_encryption`][firehose_start_delivery_stream_encryption]
#' 13 times and
#' [`stop_delivery_stream_encryption`][firehose_stop_delivery_stream_encryption]
#' 12 times for the same delivery stream in a 24-hour period.
#'
#' @usage
#' firehose_stop_delivery_stream_encryption(DeliveryStreamName)
#'
#' @param DeliveryStreamName &#91;required&#93; The name of the delivery stream for which you want to disable
#' server-side encryption (SSE).
#'
#' @return
#' An empty list.
#'
#' @section Request syntax:
#' ```
#' svc$stop_delivery_stream_encryption(
#'   DeliveryStreamName = "string"
#' )
#' ```
#'
#' @keywords internal
#'
#' @rdname firehose_stop_delivery_stream_encryption
#'
#' @aliases firehose_stop_delivery_stream_encryption
firehose_stop_delivery_stream_encryption <- function(DeliveryStreamName) {
  op <- new_operation(
    name = "StopDeliveryStreamEncryption",
    http_method = "POST",
    http_path = "/",
    host_prefix = "",
    paginator = list(),
    stream_api = FALSE
  )
  input <- .firehose$stop_delivery_stream_encryption_input(DeliveryStreamName = DeliveryStreamName)
  output <- .firehose$stop_delivery_stream_encryption_output()
  config <- get_config()
  svc <- .firehose$service(config, op)
  request <- new_request(svc, op, input, output)
  response <- send_request(request)
  return(response)
}
.firehose$operations$stop_delivery_stream_encryption <- firehose_stop_delivery_stream_encryption

#' Adds or updates tags for the specified delivery stream
#'
#' @description
#' Adds or updates tags for the specified delivery stream. A tag is a
#' key-value pair that you can define and assign to Amazon Web Services
#' resources. If you specify a tag that already exists, the tag value is
#' replaced with the value that you specify in the request. Tags are
#' metadata. For example, you can add friendly names and descriptions or
#' other types of information that can help you distinguish the delivery
#' stream. For more information about tags, see [Using Cost Allocation
#' Tags](https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/cost-alloc-tags.html)
#' in the *Amazon Web Services Billing and Cost Management User Guide*.
#' 
#' Each delivery stream can have up to 50 tags.
#' 
#' This operation has a limit of five transactions per second per account.
#'
#' @usage
#' firehose_tag_delivery_stream(DeliveryStreamName, Tags)
#'
#' @param DeliveryStreamName &#91;required&#93; The name of the delivery stream to which you want to add the tags.
#' @param Tags &#91;required&#93; A set of key-value pairs to use to create the tags.
#'
#' @return
#' An empty list.
#'
#' @section Request syntax:
#' ```
#' svc$tag_delivery_stream(
#'   DeliveryStreamName = "string",
#'   Tags = list(
#'     list(
#'       Key = "string",
#'       Value = "string"
#'     )
#'   )
#' )
#' ```
#'
#' @keywords internal
#'
#' @rdname firehose_tag_delivery_stream
#'
#' @aliases firehose_tag_delivery_stream
firehose_tag_delivery_stream <- function(DeliveryStreamName, Tags) {
  op <- new_operation(
    name = "TagDeliveryStream",
    http_method = "POST",
    http_path = "/",
    host_prefix = "",
    paginator = list(),
    stream_api = FALSE
  )
  input <- .firehose$tag_delivery_stream_input(DeliveryStreamName = DeliveryStreamName, Tags = Tags)
  output <- .firehose$tag_delivery_stream_output()
  config <- get_config()
  svc <- .firehose$service(config, op)
  request <- new_request(svc, op, input, output)
  response <- send_request(request)
  return(response)
}
.firehose$operations$tag_delivery_stream <- firehose_tag_delivery_stream

#' Removes tags from the specified delivery stream
#'
#' @description
#' Removes tags from the specified delivery stream. Removed tags are
#' deleted, and you can't recover them after this operation successfully
#' completes.
#' 
#' If you specify a tag that doesn't exist, the operation ignores it.
#' 
#' This operation has a limit of five transactions per second per account.
#'
#' @usage
#' firehose_untag_delivery_stream(DeliveryStreamName, TagKeys)
#'
#' @param DeliveryStreamName &#91;required&#93; The name of the delivery stream.
#' @param TagKeys &#91;required&#93; A list of tag keys. Each corresponding tag is removed from the delivery
#' stream.
#'
#' @return
#' An empty list.
#'
#' @section Request syntax:
#' ```
#' svc$untag_delivery_stream(
#'   DeliveryStreamName = "string",
#'   TagKeys = list(
#'     "string"
#'   )
#' )
#' ```
#'
#' @keywords internal
#'
#' @rdname firehose_untag_delivery_stream
#'
#' @aliases firehose_untag_delivery_stream
firehose_untag_delivery_stream <- function(DeliveryStreamName, TagKeys) {
  op <- new_operation(
    name = "UntagDeliveryStream",
    http_method = "POST",
    http_path = "/",
    host_prefix = "",
    paginator = list(),
    stream_api = FALSE
  )
  input <- .firehose$untag_delivery_stream_input(DeliveryStreamName = DeliveryStreamName, TagKeys = TagKeys)
  output <- .firehose$untag_delivery_stream_output()
  config <- get_config()
  svc <- .firehose$service(config, op)
  request <- new_request(svc, op, input, output)
  response <- send_request(request)
  return(response)
}
.firehose$operations$untag_delivery_stream <- firehose_untag_delivery_stream

#' Updates the specified destination of the specified delivery stream
#'
#' @description
#' Updates the specified destination of the specified delivery stream.
#' 
#' Use this operation to change the destination type (for example, to
#' replace the Amazon S3 destination with Amazon Redshift) or change the
#' parameters associated with a destination (for example, to change the
#' bucket name of the Amazon S3 destination). The update might not occur
#' immediately. The target delivery stream remains active while the
#' configurations are updated, so data writes to the delivery stream can
#' continue during this process. The updated configurations are usually
#' effective within a few minutes.
#' 
#' Switching between Amazon OpenSearch Service and other services is not
#' supported. For an Amazon OpenSearch Service destination, you can only
#' update to another Amazon OpenSearch Service destination.
#' 
#' If the destination type is the same, Firehose merges the configuration
#' parameters specified with the destination configuration that already
#' exists on the delivery stream. If any of the parameters are not
#' specified in the call, the existing values are retained. For example, in
#' the Amazon S3 destination, if EncryptionConfiguration is not specified,
#' then the existing `EncryptionConfiguration` is maintained on the
#' destination.
#' 
#' If the destination type is not the same, for example, changing the
#' destination from Amazon S3 to Amazon Redshift, Firehose does not merge
#' any parameters. In this case, all parameters must be specified.
#' 
#' Firehose uses `CurrentDeliveryStreamVersionId` to avoid race conditions
#' and conflicting merges. This is a required field, and the service
#' updates the configuration only if the existing configuration has a
#' version ID that matches. After the update is applied successfully, the
#' version ID is updated, and can be retrieved using
#' [`describe_delivery_stream`][firehose_describe_delivery_stream]. Use the
#' new version ID to set `CurrentDeliveryStreamVersionId` in the next call.
#'
#' @usage
#' firehose_update_destination(DeliveryStreamName,
#'   CurrentDeliveryStreamVersionId, DestinationId, S3DestinationUpdate,
#'   ExtendedS3DestinationUpdate, RedshiftDestinationUpdate,
#'   ElasticsearchDestinationUpdate,
#'   AmazonopensearchserviceDestinationUpdate, SplunkDestinationUpdate,
#'   HttpEndpointDestinationUpdate,
#'   AmazonOpenSearchServerlessDestinationUpdate, SnowflakeDestinationUpdate,
#'   IcebergDestinationUpdate)
#'
#' @param DeliveryStreamName &#91;required&#93; The name of the delivery stream.
#' @param CurrentDeliveryStreamVersionId &#91;required&#93; Obtain this value from the `VersionId` result of
#' DeliveryStreamDescription. This value is required, and helps the service
#' perform conditional operations. For example, if there is an interleaving
#' update and this value is null, then the update destination fails. After
#' the update is successful, the `VersionId` value is updated. The service
#' then performs a merge of the old configuration with the new
#' configuration.
#' @param DestinationId &#91;required&#93; The ID of the destination.
#' @param S3DestinationUpdate \[Deprecated\] Describes an update for a destination in Amazon S3.
#' @param ExtendedS3DestinationUpdate Describes an update for a destination in Amazon S3.
#' @param RedshiftDestinationUpdate Describes an update for a destination in Amazon Redshift.
#' @param ElasticsearchDestinationUpdate Describes an update for a destination in Amazon ES.
#' @param AmazonopensearchserviceDestinationUpdate Describes an update for a destination in Amazon OpenSearch Service.
#' @param SplunkDestinationUpdate Describes an update for a destination in Splunk.
#' @param HttpEndpointDestinationUpdate Describes an update to the specified HTTP endpoint destination.
#' @param AmazonOpenSearchServerlessDestinationUpdate Describes an update for a destination in the Serverless offering for
#' Amazon OpenSearch Service.
#' @param SnowflakeDestinationUpdate Update to the Snowflake destination configuration settings.
#' @param IcebergDestinationUpdate Describes an update for a destination in Apache Iceberg Tables.
#' 
#' Amazon Data Firehose is in preview release and is subject to change.
#'
#' @return
#' An empty list.
#'
#' @section Request syntax:
#' ```
#' svc$update_destination(
#'   DeliveryStreamName = "string",
#'   CurrentDeliveryStreamVersionId = "string",
#'   DestinationId = "string",
#'   S3DestinationUpdate = list(
#'     RoleARN = "string",
#'     BucketARN = "string",
#'     Prefix = "string",
#'     ErrorOutputPrefix = "string",
#'     BufferingHints = list(
#'       SizeInMBs = 123,
#'       IntervalInSeconds = 123
#'     ),
#'     CompressionFormat = "UNCOMPRESSED"|"GZIP"|"ZIP"|"Snappy"|"HADOOP_SNAPPY",
#'     EncryptionConfiguration = list(
#'       NoEncryptionConfig = "NoEncryption",
#'       KMSEncryptionConfig = list(
#'         AWSKMSKeyARN = "string"
#'       )
#'     ),
#'     CloudWatchLoggingOptions = list(
#'       Enabled = TRUE|FALSE,
#'       LogGroupName = "string",
#'       LogStreamName = "string"
#'     )
#'   ),
#'   ExtendedS3DestinationUpdate = list(
#'     RoleARN = "string",
#'     BucketARN = "string",
#'     Prefix = "string",
#'     ErrorOutputPrefix = "string",
#'     BufferingHints = list(
#'       SizeInMBs = 123,
#'       IntervalInSeconds = 123
#'     ),
#'     CompressionFormat = "UNCOMPRESSED"|"GZIP"|"ZIP"|"Snappy"|"HADOOP_SNAPPY",
#'     EncryptionConfiguration = list(
#'       NoEncryptionConfig = "NoEncryption",
#'       KMSEncryptionConfig = list(
#'         AWSKMSKeyARN = "string"
#'       )
#'     ),
#'     CloudWatchLoggingOptions = list(
#'       Enabled = TRUE|FALSE,
#'       LogGroupName = "string",
#'       LogStreamName = "string"
#'     ),
#'     ProcessingConfiguration = list(
#'       Enabled = TRUE|FALSE,
#'       Processors = list(
#'         list(
#'           Type = "RecordDeAggregation"|"Decompression"|"CloudWatchLogProcessing"|"Lambda"|"MetadataExtraction"|"AppendDelimiterToRecord",
#'           Parameters = list(
#'             list(
#'               ParameterName = "LambdaArn"|"NumberOfRetries"|"MetadataExtractionQuery"|"JsonParsingEngine"|"RoleArn"|"BufferSizeInMBs"|"BufferIntervalInSeconds"|"SubRecordType"|"Delimiter"|"CompressionFormat"|"DataMessageExtraction",
#'               ParameterValue = "string"
#'             )
#'           )
#'         )
#'       )
#'     ),
#'     S3BackupMode = "Disabled"|"Enabled",
#'     S3BackupUpdate = list(
#'       RoleARN = "string",
#'       BucketARN = "string",
#'       Prefix = "string",
#'       ErrorOutputPrefix = "string",
#'       BufferingHints = list(
#'         SizeInMBs = 123,
#'         IntervalInSeconds = 123
#'       ),
#'       CompressionFormat = "UNCOMPRESSED"|"GZIP"|"ZIP"|"Snappy"|"HADOOP_SNAPPY",
#'       EncryptionConfiguration = list(
#'         NoEncryptionConfig = "NoEncryption",
#'         KMSEncryptionConfig = list(
#'           AWSKMSKeyARN = "string"
#'         )
#'       ),
#'       CloudWatchLoggingOptions = list(
#'         Enabled = TRUE|FALSE,
#'         LogGroupName = "string",
#'         LogStreamName = "string"
#'       )
#'     ),
#'     DataFormatConversionConfiguration = list(
#'       SchemaConfiguration = list(
#'         RoleARN = "string",
#'         CatalogId = "string",
#'         DatabaseName = "string",
#'         TableName = "string",
#'         Region = "string",
#'         VersionId = "string"
#'       ),
#'       InputFormatConfiguration = list(
#'         Deserializer = list(
#'           OpenXJsonSerDe = list(
#'             ConvertDotsInJsonKeysToUnderscores = TRUE|FALSE,
#'             CaseInsensitive = TRUE|FALSE,
#'             ColumnToJsonKeyMappings = list(
#'               "string"
#'             )
#'           ),
#'           HiveJsonSerDe = list(
#'             TimestampFormats = list(
#'               "string"
#'             )
#'           )
#'         )
#'       ),
#'       OutputFormatConfiguration = list(
#'         Serializer = list(
#'           ParquetSerDe = list(
#'             BlockSizeBytes = 123,
#'             PageSizeBytes = 123,
#'             Compression = "UNCOMPRESSED"|"GZIP"|"SNAPPY",
#'             EnableDictionaryCompression = TRUE|FALSE,
#'             MaxPaddingBytes = 123,
#'             WriterVersion = "V1"|"V2"
#'           ),
#'           OrcSerDe = list(
#'             StripeSizeBytes = 123,
#'             BlockSizeBytes = 123,
#'             RowIndexStride = 123,
#'             EnablePadding = TRUE|FALSE,
#'             PaddingTolerance = 123.0,
#'             Compression = "NONE"|"ZLIB"|"SNAPPY",
#'             BloomFilterColumns = list(
#'               "string"
#'             ),
#'             BloomFilterFalsePositiveProbability = 123.0,
#'             DictionaryKeyThreshold = 123.0,
#'             FormatVersion = "V0_11"|"V0_12"
#'           )
#'         )
#'       ),
#'       Enabled = TRUE|FALSE
#'     ),
#'     DynamicPartitioningConfiguration = list(
#'       RetryOptions = list(
#'         DurationInSeconds = 123
#'       ),
#'       Enabled = TRUE|FALSE
#'     ),
#'     FileExtension = "string",
#'     CustomTimeZone = "string"
#'   ),
#'   RedshiftDestinationUpdate = list(
#'     RoleARN = "string",
#'     ClusterJDBCURL = "string",
#'     CopyCommand = list(
#'       DataTableName = "string",
#'       DataTableColumns = "string",
#'       CopyOptions = "string"
#'     ),
#'     Username = "string",
#'     Password = "string",
#'     RetryOptions = list(
#'       DurationInSeconds = 123
#'     ),
#'     S3Update = list(
#'       RoleARN = "string",
#'       BucketARN = "string",
#'       Prefix = "string",
#'       ErrorOutputPrefix = "string",
#'       BufferingHints = list(
#'         SizeInMBs = 123,
#'         IntervalInSeconds = 123
#'       ),
#'       CompressionFormat = "UNCOMPRESSED"|"GZIP"|"ZIP"|"Snappy"|"HADOOP_SNAPPY",
#'       EncryptionConfiguration = list(
#'         NoEncryptionConfig = "NoEncryption",
#'         KMSEncryptionConfig = list(
#'           AWSKMSKeyARN = "string"
#'         )
#'       ),
#'       CloudWatchLoggingOptions = list(
#'         Enabled = TRUE|FALSE,
#'         LogGroupName = "string",
#'         LogStreamName = "string"
#'       )
#'     ),
#'     ProcessingConfiguration = list(
#'       Enabled = TRUE|FALSE,
#'       Processors = list(
#'         list(
#'           Type = "RecordDeAggregation"|"Decompression"|"CloudWatchLogProcessing"|"Lambda"|"MetadataExtraction"|"AppendDelimiterToRecord",
#'           Parameters = list(
#'             list(
#'               ParameterName = "LambdaArn"|"NumberOfRetries"|"MetadataExtractionQuery"|"JsonParsingEngine"|"RoleArn"|"BufferSizeInMBs"|"BufferIntervalInSeconds"|"SubRecordType"|"Delimiter"|"CompressionFormat"|"DataMessageExtraction",
#'               ParameterValue = "string"
#'             )
#'           )
#'         )
#'       )
#'     ),
#'     S3BackupMode = "Disabled"|"Enabled",
#'     S3BackupUpdate = list(
#'       RoleARN = "string",
#'       BucketARN = "string",
#'       Prefix = "string",
#'       ErrorOutputPrefix = "string",
#'       BufferingHints = list(
#'         SizeInMBs = 123,
#'         IntervalInSeconds = 123
#'       ),
#'       CompressionFormat = "UNCOMPRESSED"|"GZIP"|"ZIP"|"Snappy"|"HADOOP_SNAPPY",
#'       EncryptionConfiguration = list(
#'         NoEncryptionConfig = "NoEncryption",
#'         KMSEncryptionConfig = list(
#'           AWSKMSKeyARN = "string"
#'         )
#'       ),
#'       CloudWatchLoggingOptions = list(
#'         Enabled = TRUE|FALSE,
#'         LogGroupName = "string",
#'         LogStreamName = "string"
#'       )
#'     ),
#'     CloudWatchLoggingOptions = list(
#'       Enabled = TRUE|FALSE,
#'       LogGroupName = "string",
#'       LogStreamName = "string"
#'     ),
#'     SecretsManagerConfiguration = list(
#'       SecretARN = "string",
#'       RoleARN = "string",
#'       Enabled = TRUE|FALSE
#'     )
#'   ),
#'   ElasticsearchDestinationUpdate = list(
#'     RoleARN = "string",
#'     DomainARN = "string",
#'     ClusterEndpoint = "string",
#'     IndexName = "string",
#'     TypeName = "string",
#'     IndexRotationPeriod = "NoRotation"|"OneHour"|"OneDay"|"OneWeek"|"OneMonth",
#'     BufferingHints = list(
#'       IntervalInSeconds = 123,
#'       SizeInMBs = 123
#'     ),
#'     RetryOptions = list(
#'       DurationInSeconds = 123
#'     ),
#'     S3Update = list(
#'       RoleARN = "string",
#'       BucketARN = "string",
#'       Prefix = "string",
#'       ErrorOutputPrefix = "string",
#'       BufferingHints = list(
#'         SizeInMBs = 123,
#'         IntervalInSeconds = 123
#'       ),
#'       CompressionFormat = "UNCOMPRESSED"|"GZIP"|"ZIP"|"Snappy"|"HADOOP_SNAPPY",
#'       EncryptionConfiguration = list(
#'         NoEncryptionConfig = "NoEncryption",
#'         KMSEncryptionConfig = list(
#'           AWSKMSKeyARN = "string"
#'         )
#'       ),
#'       CloudWatchLoggingOptions = list(
#'         Enabled = TRUE|FALSE,
#'         LogGroupName = "string",
#'         LogStreamName = "string"
#'       )
#'     ),
#'     ProcessingConfiguration = list(
#'       Enabled = TRUE|FALSE,
#'       Processors = list(
#'         list(
#'           Type = "RecordDeAggregation"|"Decompression"|"CloudWatchLogProcessing"|"Lambda"|"MetadataExtraction"|"AppendDelimiterToRecord",
#'           Parameters = list(
#'             list(
#'               ParameterName = "LambdaArn"|"NumberOfRetries"|"MetadataExtractionQuery"|"JsonParsingEngine"|"RoleArn"|"BufferSizeInMBs"|"BufferIntervalInSeconds"|"SubRecordType"|"Delimiter"|"CompressionFormat"|"DataMessageExtraction",
#'               ParameterValue = "string"
#'             )
#'           )
#'         )
#'       )
#'     ),
#'     CloudWatchLoggingOptions = list(
#'       Enabled = TRUE|FALSE,
#'       LogGroupName = "string",
#'       LogStreamName = "string"
#'     ),
#'     DocumentIdOptions = list(
#'       DefaultDocumentIdFormat = "FIREHOSE_DEFAULT"|"NO_DOCUMENT_ID"
#'     )
#'   ),
#'   AmazonopensearchserviceDestinationUpdate = list(
#'     RoleARN = "string",
#'     DomainARN = "string",
#'     ClusterEndpoint = "string",
#'     IndexName = "string",
#'     TypeName = "string",
#'     IndexRotationPeriod = "NoRotation"|"OneHour"|"OneDay"|"OneWeek"|"OneMonth",
#'     BufferingHints = list(
#'       IntervalInSeconds = 123,
#'       SizeInMBs = 123
#'     ),
#'     RetryOptions = list(
#'       DurationInSeconds = 123
#'     ),
#'     S3Update = list(
#'       RoleARN = "string",
#'       BucketARN = "string",
#'       Prefix = "string",
#'       ErrorOutputPrefix = "string",
#'       BufferingHints = list(
#'         SizeInMBs = 123,
#'         IntervalInSeconds = 123
#'       ),
#'       CompressionFormat = "UNCOMPRESSED"|"GZIP"|"ZIP"|"Snappy"|"HADOOP_SNAPPY",
#'       EncryptionConfiguration = list(
#'         NoEncryptionConfig = "NoEncryption",
#'         KMSEncryptionConfig = list(
#'           AWSKMSKeyARN = "string"
#'         )
#'       ),
#'       CloudWatchLoggingOptions = list(
#'         Enabled = TRUE|FALSE,
#'         LogGroupName = "string",
#'         LogStreamName = "string"
#'       )
#'     ),
#'     ProcessingConfiguration = list(
#'       Enabled = TRUE|FALSE,
#'       Processors = list(
#'         list(
#'           Type = "RecordDeAggregation"|"Decompression"|"CloudWatchLogProcessing"|"Lambda"|"MetadataExtraction"|"AppendDelimiterToRecord",
#'           Parameters = list(
#'             list(
#'               ParameterName = "LambdaArn"|"NumberOfRetries"|"MetadataExtractionQuery"|"JsonParsingEngine"|"RoleArn"|"BufferSizeInMBs"|"BufferIntervalInSeconds"|"SubRecordType"|"Delimiter"|"CompressionFormat"|"DataMessageExtraction",
#'               ParameterValue = "string"
#'             )
#'           )
#'         )
#'       )
#'     ),
#'     CloudWatchLoggingOptions = list(
#'       Enabled = TRUE|FALSE,
#'       LogGroupName = "string",
#'       LogStreamName = "string"
#'     ),
#'     DocumentIdOptions = list(
#'       DefaultDocumentIdFormat = "FIREHOSE_DEFAULT"|"NO_DOCUMENT_ID"
#'     )
#'   ),
#'   SplunkDestinationUpdate = list(
#'     HECEndpoint = "string",
#'     HECEndpointType = "Raw"|"Event",
#'     HECToken = "string",
#'     HECAcknowledgmentTimeoutInSeconds = 123,
#'     RetryOptions = list(
#'       DurationInSeconds = 123
#'     ),
#'     S3BackupMode = "FailedEventsOnly"|"AllEvents",
#'     S3Update = list(
#'       RoleARN = "string",
#'       BucketARN = "string",
#'       Prefix = "string",
#'       ErrorOutputPrefix = "string",
#'       BufferingHints = list(
#'         SizeInMBs = 123,
#'         IntervalInSeconds = 123
#'       ),
#'       CompressionFormat = "UNCOMPRESSED"|"GZIP"|"ZIP"|"Snappy"|"HADOOP_SNAPPY",
#'       EncryptionConfiguration = list(
#'         NoEncryptionConfig = "NoEncryption",
#'         KMSEncryptionConfig = list(
#'           AWSKMSKeyARN = "string"
#'         )
#'       ),
#'       CloudWatchLoggingOptions = list(
#'         Enabled = TRUE|FALSE,
#'         LogGroupName = "string",
#'         LogStreamName = "string"
#'       )
#'     ),
#'     ProcessingConfiguration = list(
#'       Enabled = TRUE|FALSE,
#'       Processors = list(
#'         list(
#'           Type = "RecordDeAggregation"|"Decompression"|"CloudWatchLogProcessing"|"Lambda"|"MetadataExtraction"|"AppendDelimiterToRecord",
#'           Parameters = list(
#'             list(
#'               ParameterName = "LambdaArn"|"NumberOfRetries"|"MetadataExtractionQuery"|"JsonParsingEngine"|"RoleArn"|"BufferSizeInMBs"|"BufferIntervalInSeconds"|"SubRecordType"|"Delimiter"|"CompressionFormat"|"DataMessageExtraction",
#'               ParameterValue = "string"
#'             )
#'           )
#'         )
#'       )
#'     ),
#'     CloudWatchLoggingOptions = list(
#'       Enabled = TRUE|FALSE,
#'       LogGroupName = "string",
#'       LogStreamName = "string"
#'     ),
#'     BufferingHints = list(
#'       IntervalInSeconds = 123,
#'       SizeInMBs = 123
#'     ),
#'     SecretsManagerConfiguration = list(
#'       SecretARN = "string",
#'       RoleARN = "string",
#'       Enabled = TRUE|FALSE
#'     )
#'   ),
#'   HttpEndpointDestinationUpdate = list(
#'     EndpointConfiguration = list(
#'       Url = "string",
#'       Name = "string",
#'       AccessKey = "string"
#'     ),
#'     BufferingHints = list(
#'       SizeInMBs = 123,
#'       IntervalInSeconds = 123
#'     ),
#'     CloudWatchLoggingOptions = list(
#'       Enabled = TRUE|FALSE,
#'       LogGroupName = "string",
#'       LogStreamName = "string"
#'     ),
#'     RequestConfiguration = list(
#'       ContentEncoding = "NONE"|"GZIP",
#'       CommonAttributes = list(
#'         list(
#'           AttributeName = "string",
#'           AttributeValue = "string"
#'         )
#'       )
#'     ),
#'     ProcessingConfiguration = list(
#'       Enabled = TRUE|FALSE,
#'       Processors = list(
#'         list(
#'           Type = "RecordDeAggregation"|"Decompression"|"CloudWatchLogProcessing"|"Lambda"|"MetadataExtraction"|"AppendDelimiterToRecord",
#'           Parameters = list(
#'             list(
#'               ParameterName = "LambdaArn"|"NumberOfRetries"|"MetadataExtractionQuery"|"JsonParsingEngine"|"RoleArn"|"BufferSizeInMBs"|"BufferIntervalInSeconds"|"SubRecordType"|"Delimiter"|"CompressionFormat"|"DataMessageExtraction",
#'               ParameterValue = "string"
#'             )
#'           )
#'         )
#'       )
#'     ),
#'     RoleARN = "string",
#'     RetryOptions = list(
#'       DurationInSeconds = 123
#'     ),
#'     S3BackupMode = "FailedDataOnly"|"AllData",
#'     S3Update = list(
#'       RoleARN = "string",
#'       BucketARN = "string",
#'       Prefix = "string",
#'       ErrorOutputPrefix = "string",
#'       BufferingHints = list(
#'         SizeInMBs = 123,
#'         IntervalInSeconds = 123
#'       ),
#'       CompressionFormat = "UNCOMPRESSED"|"GZIP"|"ZIP"|"Snappy"|"HADOOP_SNAPPY",
#'       EncryptionConfiguration = list(
#'         NoEncryptionConfig = "NoEncryption",
#'         KMSEncryptionConfig = list(
#'           AWSKMSKeyARN = "string"
#'         )
#'       ),
#'       CloudWatchLoggingOptions = list(
#'         Enabled = TRUE|FALSE,
#'         LogGroupName = "string",
#'         LogStreamName = "string"
#'       )
#'     ),
#'     SecretsManagerConfiguration = list(
#'       SecretARN = "string",
#'       RoleARN = "string",
#'       Enabled = TRUE|FALSE
#'     )
#'   ),
#'   AmazonOpenSearchServerlessDestinationUpdate = list(
#'     RoleARN = "string",
#'     CollectionEndpoint = "string",
#'     IndexName = "string",
#'     BufferingHints = list(
#'       IntervalInSeconds = 123,
#'       SizeInMBs = 123
#'     ),
#'     RetryOptions = list(
#'       DurationInSeconds = 123
#'     ),
#'     S3Update = list(
#'       RoleARN = "string",
#'       BucketARN = "string",
#'       Prefix = "string",
#'       ErrorOutputPrefix = "string",
#'       BufferingHints = list(
#'         SizeInMBs = 123,
#'         IntervalInSeconds = 123
#'       ),
#'       CompressionFormat = "UNCOMPRESSED"|"GZIP"|"ZIP"|"Snappy"|"HADOOP_SNAPPY",
#'       EncryptionConfiguration = list(
#'         NoEncryptionConfig = "NoEncryption",
#'         KMSEncryptionConfig = list(
#'           AWSKMSKeyARN = "string"
#'         )
#'       ),
#'       CloudWatchLoggingOptions = list(
#'         Enabled = TRUE|FALSE,
#'         LogGroupName = "string",
#'         LogStreamName = "string"
#'       )
#'     ),
#'     ProcessingConfiguration = list(
#'       Enabled = TRUE|FALSE,
#'       Processors = list(
#'         list(
#'           Type = "RecordDeAggregation"|"Decompression"|"CloudWatchLogProcessing"|"Lambda"|"MetadataExtraction"|"AppendDelimiterToRecord",
#'           Parameters = list(
#'             list(
#'               ParameterName = "LambdaArn"|"NumberOfRetries"|"MetadataExtractionQuery"|"JsonParsingEngine"|"RoleArn"|"BufferSizeInMBs"|"BufferIntervalInSeconds"|"SubRecordType"|"Delimiter"|"CompressionFormat"|"DataMessageExtraction",
#'               ParameterValue = "string"
#'             )
#'           )
#'         )
#'       )
#'     ),
#'     CloudWatchLoggingOptions = list(
#'       Enabled = TRUE|FALSE,
#'       LogGroupName = "string",
#'       LogStreamName = "string"
#'     )
#'   ),
#'   SnowflakeDestinationUpdate = list(
#'     AccountUrl = "string",
#'     PrivateKey = "string",
#'     KeyPassphrase = "string",
#'     User = "string",
#'     Database = "string",
#'     Schema = "string",
#'     Table = "string",
#'     SnowflakeRoleConfiguration = list(
#'       Enabled = TRUE|FALSE,
#'       SnowflakeRole = "string"
#'     ),
#'     DataLoadingOption = "JSON_MAPPING"|"VARIANT_CONTENT_MAPPING"|"VARIANT_CONTENT_AND_METADATA_MAPPING",
#'     MetaDataColumnName = "string",
#'     ContentColumnName = "string",
#'     CloudWatchLoggingOptions = list(
#'       Enabled = TRUE|FALSE,
#'       LogGroupName = "string",
#'       LogStreamName = "string"
#'     ),
#'     ProcessingConfiguration = list(
#'       Enabled = TRUE|FALSE,
#'       Processors = list(
#'         list(
#'           Type = "RecordDeAggregation"|"Decompression"|"CloudWatchLogProcessing"|"Lambda"|"MetadataExtraction"|"AppendDelimiterToRecord",
#'           Parameters = list(
#'             list(
#'               ParameterName = "LambdaArn"|"NumberOfRetries"|"MetadataExtractionQuery"|"JsonParsingEngine"|"RoleArn"|"BufferSizeInMBs"|"BufferIntervalInSeconds"|"SubRecordType"|"Delimiter"|"CompressionFormat"|"DataMessageExtraction",
#'               ParameterValue = "string"
#'             )
#'           )
#'         )
#'       )
#'     ),
#'     RoleARN = "string",
#'     RetryOptions = list(
#'       DurationInSeconds = 123
#'     ),
#'     S3BackupMode = "FailedDataOnly"|"AllData",
#'     S3Update = list(
#'       RoleARN = "string",
#'       BucketARN = "string",
#'       Prefix = "string",
#'       ErrorOutputPrefix = "string",
#'       BufferingHints = list(
#'         SizeInMBs = 123,
#'         IntervalInSeconds = 123
#'       ),
#'       CompressionFormat = "UNCOMPRESSED"|"GZIP"|"ZIP"|"Snappy"|"HADOOP_SNAPPY",
#'       EncryptionConfiguration = list(
#'         NoEncryptionConfig = "NoEncryption",
#'         KMSEncryptionConfig = list(
#'           AWSKMSKeyARN = "string"
#'         )
#'       ),
#'       CloudWatchLoggingOptions = list(
#'         Enabled = TRUE|FALSE,
#'         LogGroupName = "string",
#'         LogStreamName = "string"
#'       )
#'     ),
#'     SecretsManagerConfiguration = list(
#'       SecretARN = "string",
#'       RoleARN = "string",
#'       Enabled = TRUE|FALSE
#'     ),
#'     BufferingHints = list(
#'       SizeInMBs = 123,
#'       IntervalInSeconds = 123
#'     )
#'   ),
#'   IcebergDestinationUpdate = list(
#'     DestinationTableConfigurationList = list(
#'       list(
#'         DestinationTableName = "string",
#'         DestinationDatabaseName = "string",
#'         UniqueKeys = list(
#'           "string"
#'         ),
#'         S3ErrorOutputPrefix = "string"
#'       )
#'     ),
#'     BufferingHints = list(
#'       SizeInMBs = 123,
#'       IntervalInSeconds = 123
#'     ),
#'     CloudWatchLoggingOptions = list(
#'       Enabled = TRUE|FALSE,
#'       LogGroupName = "string",
#'       LogStreamName = "string"
#'     ),
#'     ProcessingConfiguration = list(
#'       Enabled = TRUE|FALSE,
#'       Processors = list(
#'         list(
#'           Type = "RecordDeAggregation"|"Decompression"|"CloudWatchLogProcessing"|"Lambda"|"MetadataExtraction"|"AppendDelimiterToRecord",
#'           Parameters = list(
#'             list(
#'               ParameterName = "LambdaArn"|"NumberOfRetries"|"MetadataExtractionQuery"|"JsonParsingEngine"|"RoleArn"|"BufferSizeInMBs"|"BufferIntervalInSeconds"|"SubRecordType"|"Delimiter"|"CompressionFormat"|"DataMessageExtraction",
#'               ParameterValue = "string"
#'             )
#'           )
#'         )
#'       )
#'     ),
#'     S3BackupMode = "FailedDataOnly"|"AllData",
#'     RetryOptions = list(
#'       DurationInSeconds = 123
#'     ),
#'     RoleARN = "string",
#'     CatalogConfiguration = list(
#'       CatalogARN = "string"
#'     ),
#'     S3Configuration = list(
#'       RoleARN = "string",
#'       BucketARN = "string",
#'       Prefix = "string",
#'       ErrorOutputPrefix = "string",
#'       BufferingHints = list(
#'         SizeInMBs = 123,
#'         IntervalInSeconds = 123
#'       ),
#'       CompressionFormat = "UNCOMPRESSED"|"GZIP"|"ZIP"|"Snappy"|"HADOOP_SNAPPY",
#'       EncryptionConfiguration = list(
#'         NoEncryptionConfig = "NoEncryption",
#'         KMSEncryptionConfig = list(
#'           AWSKMSKeyARN = "string"
#'         )
#'       ),
#'       CloudWatchLoggingOptions = list(
#'         Enabled = TRUE|FALSE,
#'         LogGroupName = "string",
#'         LogStreamName = "string"
#'       )
#'     )
#'   )
#' )
#' ```
#'
#' @keywords internal
#'
#' @rdname firehose_update_destination
#'
#' @aliases firehose_update_destination
firehose_update_destination <- function(DeliveryStreamName, CurrentDeliveryStreamVersionId, DestinationId, S3DestinationUpdate = NULL, ExtendedS3DestinationUpdate = NULL, RedshiftDestinationUpdate = NULL, ElasticsearchDestinationUpdate = NULL, AmazonopensearchserviceDestinationUpdate = NULL, SplunkDestinationUpdate = NULL, HttpEndpointDestinationUpdate = NULL, AmazonOpenSearchServerlessDestinationUpdate = NULL, SnowflakeDestinationUpdate = NULL, IcebergDestinationUpdate = NULL) {
  op <- new_operation(
    name = "UpdateDestination",
    http_method = "POST",
    http_path = "/",
    host_prefix = "",
    paginator = list(),
    stream_api = FALSE
  )
  input <- .firehose$update_destination_input(DeliveryStreamName = DeliveryStreamName, CurrentDeliveryStreamVersionId = CurrentDeliveryStreamVersionId, DestinationId = DestinationId, S3DestinationUpdate = S3DestinationUpdate, ExtendedS3DestinationUpdate = ExtendedS3DestinationUpdate, RedshiftDestinationUpdate = RedshiftDestinationUpdate, ElasticsearchDestinationUpdate = ElasticsearchDestinationUpdate, AmazonopensearchserviceDestinationUpdate = AmazonopensearchserviceDestinationUpdate, SplunkDestinationUpdate = SplunkDestinationUpdate, HttpEndpointDestinationUpdate = HttpEndpointDestinationUpdate, AmazonOpenSearchServerlessDestinationUpdate = AmazonOpenSearchServerlessDestinationUpdate, SnowflakeDestinationUpdate = SnowflakeDestinationUpdate, IcebergDestinationUpdate = IcebergDestinationUpdate)
  output <- .firehose$update_destination_output()
  config <- get_config()
  svc <- .firehose$service(config, op)
  request <- new_request(svc, op, input, output)
  response <- send_request(request)
  return(response)
}
.firehose$operations$update_destination <- firehose_update_destination
