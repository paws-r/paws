# This file is generated by make.paws. Please do not edit here.
#' @importFrom paws.common get_config new_operation new_request send_request
#' @include elasticinference_service.R
NULL

#' Describes the locations in which a given accelerator type or set of
#' types is present in a given region
#'
#' @description
#' Describes the locations in which a given accelerator type or set of
#' types is present in a given region.
#' 
#' February 15, 2023: Starting April 15, 2023, AWS will not onboard new
#' customers to Amazon Elastic Inference (EI), and will help current
#' customers migrate their workloads to options that offer better price and
#' performance. After April 15, 2023, new customers will not be able to
#' launch instances with Amazon EI accelerators in Amazon SageMaker, Amazon
#' ECS, or Amazon EC2. However, customers who have used Amazon EI at least
#' once during the past 30-day period are considered current customers and
#' will be able to continue using the service.
#'
#' @usage
#' elasticinference_describe_accelerator_offerings(locationType,
#'   acceleratorTypes)
#'
#' @param locationType &#91;required&#93; The location type that you want to describe accelerator type offerings
#' for. It can assume the following values: region: will return the
#' accelerator type offering at the regional level. availability-zone: will
#' return the accelerator type offering at the availability zone level.
#' availability-zone-id: will return the accelerator type offering at the
#' availability zone level returning the availability zone id.
#' @param acceleratorTypes The list of accelerator types to describe.
#'
#' @return
#' A list with the following syntax:
#' ```
#' list(
#'   acceleratorTypeOfferings = list(
#'     list(
#'       acceleratorType = "string",
#'       locationType = "region"|"availability-zone"|"availability-zone-id",
#'       location = "string"
#'     )
#'   )
#' )
#' ```
#'
#' @section Request syntax:
#' ```
#' svc$describe_accelerator_offerings(
#'   locationType = "region"|"availability-zone"|"availability-zone-id",
#'   acceleratorTypes = list(
#'     "string"
#'   )
#' )
#' ```
#'
#' @keywords internal
#'
#' @rdname elasticinference_describe_accelerator_offerings
#'
#' @aliases elasticinference_describe_accelerator_offerings
elasticinference_describe_accelerator_offerings <- function(locationType, acceleratorTypes = NULL) {
  op <- new_operation(
    name = "DescribeAcceleratorOfferings",
    http_method = "POST",
    http_path = "/describe-accelerator-offerings",
    host_prefix = "",
    paginator = list(),
    stream_api = FALSE
  )
  input <- .elasticinference$describe_accelerator_offerings_input(locationType = locationType, acceleratorTypes = acceleratorTypes)
  output <- .elasticinference$describe_accelerator_offerings_output()
  config <- get_config()
  svc <- .elasticinference$service(config, op)
  request <- new_request(svc, op, input, output)
  response <- send_request(request)
  return(response)
}
.elasticinference$operations$describe_accelerator_offerings <- elasticinference_describe_accelerator_offerings

#' Describes the accelerator types available in a given region, as well as
#' their characteristics, such as memory and throughput
#'
#' @description
#' Describes the accelerator types available in a given region, as well as
#' their characteristics, such as memory and throughput.
#' 
#' February 15, 2023: Starting April 15, 2023, AWS will not onboard new
#' customers to Amazon Elastic Inference (EI), and will help current
#' customers migrate their workloads to options that offer better price and
#' performance. After April 15, 2023, new customers will not be able to
#' launch instances with Amazon EI accelerators in Amazon SageMaker, Amazon
#' ECS, or Amazon EC2. However, customers who have used Amazon EI at least
#' once during the past 30-day period are considered current customers and
#' will be able to continue using the service.
#'
#' @usage
#' elasticinference_describe_accelerator_types()
#'

#'
#' @return
#' A list with the following syntax:
#' ```
#' list(
#'   acceleratorTypes = list(
#'     list(
#'       acceleratorTypeName = "string",
#'       memoryInfo = list(
#'         sizeInMiB = 123
#'       ),
#'       throughputInfo = list(
#'         list(
#'           key = "string",
#'           value = 123
#'         )
#'       )
#'     )
#'   )
#' )
#' ```
#'
#' @section Request syntax:
#' ```
#' svc$describe_accelerator_types()
#' ```
#'
#' @keywords internal
#'
#' @rdname elasticinference_describe_accelerator_types
#'
#' @aliases elasticinference_describe_accelerator_types
elasticinference_describe_accelerator_types <- function() {
  op <- new_operation(
    name = "DescribeAcceleratorTypes",
    http_method = "GET",
    http_path = "/describe-accelerator-types",
    host_prefix = "",
    paginator = list(),
    stream_api = FALSE
  )
  input <- .elasticinference$describe_accelerator_types_input()
  output <- .elasticinference$describe_accelerator_types_output()
  config <- get_config()
  svc <- .elasticinference$service(config, op)
  request <- new_request(svc, op, input, output)
  response <- send_request(request)
  return(response)
}
.elasticinference$operations$describe_accelerator_types <- elasticinference_describe_accelerator_types

#' Describes information over a provided set of accelerators belonging to
#' an account
#'
#' @description
#' Describes information over a provided set of accelerators belonging to
#' an account.
#' 
#' February 15, 2023: Starting April 15, 2023, AWS will not onboard new
#' customers to Amazon Elastic Inference (EI), and will help current
#' customers migrate their workloads to options that offer better price and
#' performance. After April 15, 2023, new customers will not be able to
#' launch instances with Amazon EI accelerators in Amazon SageMaker, Amazon
#' ECS, or Amazon EC2. However, customers who have used Amazon EI at least
#' once during the past 30-day period are considered current customers and
#' will be able to continue using the service.
#'
#' @usage
#' elasticinference_describe_accelerators(acceleratorIds, filters,
#'   maxResults, nextToken)
#'
#' @param acceleratorIds The IDs of the accelerators to describe.
#' @param filters One or more filters. Filter names and values are case-sensitive. Valid
#' filter names are: accelerator-types: can provide a list of accelerator
#' type names to filter for. instance-id: can provide a list of EC2
#' instance ids to filter for.
#' @param maxResults The total number of items to return in the command's output. If the
#' total number of items available is more than the value specified, a
#' NextToken is provided in the command's output. To resume pagination,
#' provide the NextToken value in the starting-token argument of a
#' subsequent command. Do not use the NextToken response element directly
#' outside of the AWS CLI.
#' @param nextToken A token to specify where to start paginating. This is the NextToken from
#' a previously truncated response.
#'
#' @return
#' A list with the following syntax:
#' ```
#' list(
#'   acceleratorSet = list(
#'     list(
#'       acceleratorHealth = list(
#'         status = "string"
#'       ),
#'       acceleratorType = "string",
#'       acceleratorId = "string",
#'       availabilityZone = "string",
#'       attachedResource = "string"
#'     )
#'   ),
#'   nextToken = "string"
#' )
#' ```
#'
#' @section Request syntax:
#' ```
#' svc$describe_accelerators(
#'   acceleratorIds = list(
#'     "string"
#'   ),
#'   filters = list(
#'     list(
#'       name = "string",
#'       values = list(
#'         "string"
#'       )
#'     )
#'   ),
#'   maxResults = 123,
#'   nextToken = "string"
#' )
#' ```
#'
#' @keywords internal
#'
#' @rdname elasticinference_describe_accelerators
#'
#' @aliases elasticinference_describe_accelerators
elasticinference_describe_accelerators <- function(acceleratorIds = NULL, filters = NULL, maxResults = NULL, nextToken = NULL) {
  op <- new_operation(
    name = "DescribeAccelerators",
    http_method = "POST",
    http_path = "/describe-accelerators",
    host_prefix = "",
    paginator = list(input_token = "nextToken", output_token = "nextToken", limit_key = "maxResults", result_key = "acceleratorSet"),
    stream_api = FALSE
  )
  input <- .elasticinference$describe_accelerators_input(acceleratorIds = acceleratorIds, filters = filters, maxResults = maxResults, nextToken = nextToken)
  output <- .elasticinference$describe_accelerators_output()
  config <- get_config()
  svc <- .elasticinference$service(config, op)
  request <- new_request(svc, op, input, output)
  response <- send_request(request)
  return(response)
}
.elasticinference$operations$describe_accelerators <- elasticinference_describe_accelerators

#' Returns all tags of an Elastic Inference Accelerator
#'
#' @description
#' Returns all tags of an Elastic Inference Accelerator.
#' 
#' February 15, 2023: Starting April 15, 2023, AWS will not onboard new
#' customers to Amazon Elastic Inference (EI), and will help current
#' customers migrate their workloads to options that offer better price and
#' performance. After April 15, 2023, new customers will not be able to
#' launch instances with Amazon EI accelerators in Amazon SageMaker, Amazon
#' ECS, or Amazon EC2. However, customers who have used Amazon EI at least
#' once during the past 30-day period are considered current customers and
#' will be able to continue using the service.
#'
#' @usage
#' elasticinference_list_tags_for_resource(resourceArn)
#'
#' @param resourceArn &#91;required&#93; The ARN of the Elastic Inference Accelerator to list the tags for.
#'
#' @return
#' A list with the following syntax:
#' ```
#' list(
#'   tags = list(
#'     "string"
#'   )
#' )
#' ```
#'
#' @section Request syntax:
#' ```
#' svc$list_tags_for_resource(
#'   resourceArn = "string"
#' )
#' ```
#'
#' @keywords internal
#'
#' @rdname elasticinference_list_tags_for_resource
#'
#' @aliases elasticinference_list_tags_for_resource
elasticinference_list_tags_for_resource <- function(resourceArn) {
  op <- new_operation(
    name = "ListTagsForResource",
    http_method = "GET",
    http_path = "/tags/{resourceArn}",
    host_prefix = "",
    paginator = list(),
    stream_api = FALSE
  )
  input <- .elasticinference$list_tags_for_resource_input(resourceArn = resourceArn)
  output <- .elasticinference$list_tags_for_resource_output()
  config <- get_config()
  svc <- .elasticinference$service(config, op)
  request <- new_request(svc, op, input, output)
  response <- send_request(request)
  return(response)
}
.elasticinference$operations$list_tags_for_resource <- elasticinference_list_tags_for_resource

#' Adds the specified tags to an Elastic Inference Accelerator
#'
#' @description
#' Adds the specified tags to an Elastic Inference Accelerator.
#' 
#' February 15, 2023: Starting April 15, 2023, AWS will not onboard new
#' customers to Amazon Elastic Inference (EI), and will help current
#' customers migrate their workloads to options that offer better price and
#' performance. After April 15, 2023, new customers will not be able to
#' launch instances with Amazon EI accelerators in Amazon SageMaker, Amazon
#' ECS, or Amazon EC2. However, customers who have used Amazon EI at least
#' once during the past 30-day period are considered current customers and
#' will be able to continue using the service.
#'
#' @usage
#' elasticinference_tag_resource(resourceArn, tags)
#'
#' @param resourceArn &#91;required&#93; The ARN of the Elastic Inference Accelerator to tag.
#' @param tags &#91;required&#93; The tags to add to the Elastic Inference Accelerator.
#'
#' @return
#' An empty list.
#'
#' @section Request syntax:
#' ```
#' svc$tag_resource(
#'   resourceArn = "string",
#'   tags = list(
#'     "string"
#'   )
#' )
#' ```
#'
#' @keywords internal
#'
#' @rdname elasticinference_tag_resource
#'
#' @aliases elasticinference_tag_resource
elasticinference_tag_resource <- function(resourceArn, tags) {
  op <- new_operation(
    name = "TagResource",
    http_method = "POST",
    http_path = "/tags/{resourceArn}",
    host_prefix = "",
    paginator = list(),
    stream_api = FALSE
  )
  input <- .elasticinference$tag_resource_input(resourceArn = resourceArn, tags = tags)
  output <- .elasticinference$tag_resource_output()
  config <- get_config()
  svc <- .elasticinference$service(config, op)
  request <- new_request(svc, op, input, output)
  response <- send_request(request)
  return(response)
}
.elasticinference$operations$tag_resource <- elasticinference_tag_resource

#' Removes the specified tags from an Elastic Inference Accelerator
#'
#' @description
#' Removes the specified tags from an Elastic Inference Accelerator.
#' 
#' February 15, 2023: Starting April 15, 2023, AWS will not onboard new
#' customers to Amazon Elastic Inference (EI), and will help current
#' customers migrate their workloads to options that offer better price and
#' performance. After April 15, 2023, new customers will not be able to
#' launch instances with Amazon EI accelerators in Amazon SageMaker, Amazon
#' ECS, or Amazon EC2. However, customers who have used Amazon EI at least
#' once during the past 30-day period are considered current customers and
#' will be able to continue using the service.
#'
#' @usage
#' elasticinference_untag_resource(resourceArn, tagKeys)
#'
#' @param resourceArn &#91;required&#93; The ARN of the Elastic Inference Accelerator to untag.
#' @param tagKeys &#91;required&#93; The list of tags to remove from the Elastic Inference Accelerator.
#'
#' @return
#' An empty list.
#'
#' @section Request syntax:
#' ```
#' svc$untag_resource(
#'   resourceArn = "string",
#'   tagKeys = list(
#'     "string"
#'   )
#' )
#' ```
#'
#' @keywords internal
#'
#' @rdname elasticinference_untag_resource
#'
#' @aliases elasticinference_untag_resource
elasticinference_untag_resource <- function(resourceArn, tagKeys) {
  op <- new_operation(
    name = "UntagResource",
    http_method = "DELETE",
    http_path = "/tags/{resourceArn}",
    host_prefix = "",
    paginator = list(),
    stream_api = FALSE
  )
  input <- .elasticinference$untag_resource_input(resourceArn = resourceArn, tagKeys = tagKeys)
  output <- .elasticinference$untag_resource_output()
  config <- get_config()
  svc <- .elasticinference$service(config, op)
  request <- new_request(svc, op, input, output)
  response <- send_request(request)
  return(response)
}
.elasticinference$operations$untag_resource <- elasticinference_untag_resource
