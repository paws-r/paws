# This file is generated by make.paws. Please do not edit here.
#' @importFrom paws.common get_config new_operation new_request send_request
#' @include bedrockruntime_service.R
NULL

#' The action to apply a guardrail
#'
#' @description
#' The action to apply a guardrail.
#' 
#' For troubleshooting some of the common errors you might encounter when
#' using the [`apply_guardrail`][bedrockruntime_apply_guardrail] API, see
#' [Troubleshooting Amazon Bedrock API Error
#' Codes](https://docs.aws.amazon.com/bedrock/latest/userguide/troubleshooting-api-error-codes.html)
#' in the Amazon Bedrock User Guide
#'
#' @usage
#' bedrockruntime_apply_guardrail(guardrailIdentifier, guardrailVersion,
#'   source, content)
#'
#' @param guardrailIdentifier &#91;required&#93; The guardrail identifier used in the request to apply the guardrail.
#' @param guardrailVersion &#91;required&#93; The guardrail version used in the request to apply the guardrail.
#' @param source &#91;required&#93; The source of data used in the request to apply the guardrail.
#' @param content &#91;required&#93; The content details used in the request to apply the guardrail.
#'
#' @return
#' A list with the following syntax:
#' ```
#' list(
#'   usage = list(
#'     topicPolicyUnits = 123,
#'     contentPolicyUnits = 123,
#'     wordPolicyUnits = 123,
#'     sensitiveInformationPolicyUnits = 123,
#'     sensitiveInformationPolicyFreeUnits = 123,
#'     contextualGroundingPolicyUnits = 123
#'   ),
#'   action = "NONE"|"GUARDRAIL_INTERVENED",
#'   outputs = list(
#'     list(
#'       text = "string"
#'     )
#'   ),
#'   assessments = list(
#'     list(
#'       topicPolicy = list(
#'         topics = list(
#'           list(
#'             name = "string",
#'             type = "DENY",
#'             action = "BLOCKED"
#'           )
#'         )
#'       ),
#'       contentPolicy = list(
#'         filters = list(
#'           list(
#'             type = "INSULTS"|"HATE"|"SEXUAL"|"VIOLENCE"|"MISCONDUCT"|"PROMPT_ATTACK",
#'             confidence = "NONE"|"LOW"|"MEDIUM"|"HIGH",
#'             filterStrength = "NONE"|"LOW"|"MEDIUM"|"HIGH",
#'             action = "BLOCKED"
#'           )
#'         )
#'       ),
#'       wordPolicy = list(
#'         customWords = list(
#'           list(
#'             match = "string",
#'             action = "BLOCKED"
#'           )
#'         ),
#'         managedWordLists = list(
#'           list(
#'             match = "string",
#'             type = "PROFANITY",
#'             action = "BLOCKED"
#'           )
#'         )
#'       ),
#'       sensitiveInformationPolicy = list(
#'         piiEntities = list(
#'           list(
#'             match = "string",
#'             type = "ADDRESS"|"AGE"|"AWS_ACCESS_KEY"|"AWS_SECRET_KEY"|"CA_HEALTH_NUMBER"|"CA_SOCIAL_INSURANCE_NUMBER"|"CREDIT_DEBIT_CARD_CVV"|"CREDIT_DEBIT_CARD_EXPIRY"|"CREDIT_DEBIT_CARD_NUMBER"|"DRIVER_ID"|"EMAIL"|"INTERNATIONAL_BANK_ACCOUNT_NUMBER"|"IP_ADDRESS"|"LICENSE_PLATE"|"MAC_ADDRESS"|"NAME"|"PASSWORD"|"PHONE"|"PIN"|"SWIFT_CODE"|"UK_NATIONAL_HEALTH_SERVICE_NUMBER"|"UK_NATIONAL_INSURANCE_NUMBER"|"UK_UNIQUE_TAXPAYER_REFERENCE_NUMBER"|"URL"|"USERNAME"|"US_BANK_ACCOUNT_NUMBER"|"US_BANK_ROUTING_NUMBER"|"US_INDIVIDUAL_TAX_IDENTIFICATION_NUMBER"|"US_PASSPORT_NUMBER"|"US_SOCIAL_SECURITY_NUMBER"|"VEHICLE_IDENTIFICATION_NUMBER",
#'             action = "ANONYMIZED"|"BLOCKED"
#'           )
#'         ),
#'         regexes = list(
#'           list(
#'             name = "string",
#'             match = "string",
#'             regex = "string",
#'             action = "ANONYMIZED"|"BLOCKED"
#'           )
#'         )
#'       ),
#'       contextualGroundingPolicy = list(
#'         filters = list(
#'           list(
#'             type = "GROUNDING"|"RELEVANCE",
#'             threshold = 123.0,
#'             score = 123.0,
#'             action = "BLOCKED"|"NONE"
#'           )
#'         )
#'       ),
#'       invocationMetrics = list(
#'         guardrailProcessingLatency = 123,
#'         usage = list(
#'           topicPolicyUnits = 123,
#'           contentPolicyUnits = 123,
#'           wordPolicyUnits = 123,
#'           sensitiveInformationPolicyUnits = 123,
#'           sensitiveInformationPolicyFreeUnits = 123,
#'           contextualGroundingPolicyUnits = 123
#'         ),
#'         guardrailCoverage = list(
#'           textCharacters = list(
#'             guarded = 123,
#'             total = 123
#'           ),
#'           images = list(
#'             guarded = 123,
#'             total = 123
#'           )
#'         )
#'       )
#'     )
#'   ),
#'   guardrailCoverage = list(
#'     textCharacters = list(
#'       guarded = 123,
#'       total = 123
#'     ),
#'     images = list(
#'       guarded = 123,
#'       total = 123
#'     )
#'   )
#' )
#' ```
#'
#' @section Request syntax:
#' ```
#' svc$apply_guardrail(
#'   guardrailIdentifier = "string",
#'   guardrailVersion = "string",
#'   source = "INPUT"|"OUTPUT",
#'   content = list(
#'     list(
#'       text = list(
#'         text = "string",
#'         qualifiers = list(
#'           "grounding_source"|"query"|"guard_content"
#'         )
#'       ),
#'       image = list(
#'         format = "png"|"jpeg",
#'         source = list(
#'           bytes = raw
#'         )
#'       )
#'     )
#'   )
#' )
#' ```
#'
#' @keywords internal
#'
#' @rdname bedrockruntime_apply_guardrail
#'
#' @aliases bedrockruntime_apply_guardrail
bedrockruntime_apply_guardrail <- function(guardrailIdentifier, guardrailVersion, source, content) {
  op <- new_operation(
    name = "ApplyGuardrail",
    http_method = "POST",
    http_path = "/guardrail/{guardrailIdentifier}/version/{guardrailVersion}/apply",
    host_prefix = "",
    paginator = list(),
    stream_api = FALSE
  )
  input <- .bedrockruntime$apply_guardrail_input(guardrailIdentifier = guardrailIdentifier, guardrailVersion = guardrailVersion, source = source, content = content)
  output <- .bedrockruntime$apply_guardrail_output()
  config <- get_config()
  svc <- .bedrockruntime$service(config, op)
  request <- new_request(svc, op, input, output)
  response <- send_request(request)
  return(response)
}
.bedrockruntime$operations$apply_guardrail <- bedrockruntime_apply_guardrail

#' Sends messages to the specified Amazon Bedrock model
#'
#' @description
#' Sends messages to the specified Amazon Bedrock model.
#' [`converse`][bedrockruntime_converse] provides a consistent interface
#' that works with all models that support messages. This allows you to
#' write code once and use it with different models. If a model has unique
#' inference parameters, you can also pass those unique parameters to the
#' model.
#' 
#' Amazon Bedrock doesn't store any text, images, or documents that you
#' provide as content. The data is only used to generate the response.
#' 
#' You can submit a prompt by including it in the `messages` field,
#' specifying the `modelId` of a foundation model or inference profile to
#' run inference on it, and including any other fields that are relevant to
#' your use case.
#' 
#' You can also submit a prompt from Prompt management by specifying the
#' ARN of the prompt version and including a map of variables to values in
#' the `promptVariables` field. You can append more messages to the prompt
#' by using the `messages` field. If you use a prompt from Prompt
#' management, you can't include the following fields in the request:
#' `additionalModelRequestFields`, `inferenceConfig`, `system`, or
#' `toolConfig`. Instead, these fields must be defined through Prompt
#' management. For more information, see [Use a prompt from Prompt
#' management](https://docs.aws.amazon.com/bedrock/latest/userguide/).
#' 
#' For information about the Converse API, see *Use the Converse API* in
#' the *Amazon Bedrock User Guide*. To use a guardrail, see *Use a
#' guardrail with the Converse API* in the *Amazon Bedrock User Guide*. To
#' use a tool with a model, see *Tool use (Function calling)* in the
#' *Amazon Bedrock User Guide*
#' 
#' For example code, see *Converse API examples* in the *Amazon Bedrock
#' User Guide*.
#' 
#' This operation requires permission for the `bedrock:InvokeModel` action.
#' 
#' To deny all inference access to resources that you specify in the
#' modelId field, you need to deny access to the `bedrock:InvokeModel` and
#' `bedrock:InvokeModelWithResponseStream` actions. Doing this also denies
#' access to the resource through the base inference actions
#' ([`invoke_model`][bedrockruntime_invoke_model] and
#' [`invoke_model_with_response_stream`][bedrockruntime_invoke_model_with_response_stream]).
#' For more information see [Deny access for inference on specific
#' models](https://docs.aws.amazon.com/bedrock/latest/userguide/security_iam_id-based-policy-examples.html#security_iam_id-based-policy-examples-deny-inference).
#' 
#' For troubleshooting some of the common errors you might encounter when
#' using the [`converse`][bedrockruntime_converse] API, see
#' [Troubleshooting Amazon Bedrock API Error
#' Codes](https://docs.aws.amazon.com/bedrock/latest/userguide/troubleshooting-api-error-codes.html)
#' in the Amazon Bedrock User Guide
#'
#' @usage
#' bedrockruntime_converse(modelId, messages, system, inferenceConfig,
#'   toolConfig, guardrailConfig, additionalModelRequestFields,
#'   promptVariables, additionalModelResponseFieldPaths, requestMetadata,
#'   performanceConfig)
#'
#' @param modelId &#91;required&#93; Specifies the model or throughput with which to run inference, or the
#' prompt resource to use in inference. The value depends on the resource
#' that you use:
#' 
#' -   If you use a base model, specify the model ID or its ARN. For a list
#'     of model IDs for base models, see [Amazon Bedrock base model IDs
#'     (on-demand
#'     throughput)](https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html#model-ids-arns)
#'     in the Amazon Bedrock User Guide.
#' 
#' -   If you use an inference profile, specify the inference profile ID or
#'     its ARN. For a list of inference profile IDs, see [Supported Regions
#'     and models for cross-region
#'     inference](https://docs.aws.amazon.com/bedrock/latest/userguide/inference-profiles-support.html)
#'     in the Amazon Bedrock User Guide.
#' 
#' -   If you use a provisioned model, specify the ARN of the Provisioned
#'     Throughput. For more information, see [Run inference using a
#'     Provisioned
#'     Throughput](https://docs.aws.amazon.com/bedrock/latest/userguide/prov-thru-use.html)
#'     in the Amazon Bedrock User Guide.
#' 
#' -   If you use a custom model, first purchase Provisioned Throughput for
#'     it. Then specify the ARN of the resulting provisioned model. For
#'     more information, see [Use a custom model in Amazon
#'     Bedrock](https://docs.aws.amazon.com/bedrock/latest/userguide/model-customization-use.html)
#'     in the Amazon Bedrock User Guide.
#' 
#' -   To include a prompt that was defined in [Prompt
#'     management](https://docs.aws.amazon.com/bedrock/latest/userguide/prompt-management.html),
#'     specify the ARN of the prompt version to use.
#' 
#' The Converse API doesn't support [imported
#' models](https://docs.aws.amazon.com/bedrock/latest/userguide/model-customization-import-model.html).
#' @param messages The messages that you want to send to the model.
#' @param system A prompt that provides instructions or context to the model about the
#' task it should perform, or the persona it should adopt during the
#' conversation.
#' @param inferenceConfig Inference parameters to pass to the model.
#' [`converse`][bedrockruntime_converse] and
#' [`converse_stream`][bedrockruntime_converse_stream] support a base set
#' of inference parameters. If you need to pass additional parameters that
#' the model supports, use the `additionalModelRequestFields` request
#' field.
#' @param toolConfig Configuration information for the tools that the model can use when
#' generating a response.
#' 
#' For information about models that support tool use, see [Supported
#' models and model
#' features](https://docs.aws.amazon.com/bedrock/latest/userguide/conversation-inference.html#conversation-inference-supported-models-features).
#' @param guardrailConfig Configuration information for a guardrail that you want to use in the
#' request. If you include `guardContent` blocks in the `content` field in
#' the `messages` field, the guardrail operates only on those messages. If
#' you include no `guardContent` blocks, the guardrail operates on all
#' messages in the request body and in any included prompt resource.
#' @param additionalModelRequestFields Additional inference parameters that the model supports, beyond the base
#' set of inference parameters that [`converse`][bedrockruntime_converse]
#' and [`converse_stream`][bedrockruntime_converse_stream] support in the
#' `inferenceConfig` field. For more information, see [Model
#' parameters](https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters.html).
#' @param promptVariables Contains a map of variables in a prompt from Prompt management to
#' objects containing the values to fill in for them when running model
#' invocation. This field is ignored if you don't specify a prompt resource
#' in the `modelId` field.
#' @param additionalModelResponseFieldPaths Additional model parameters field paths to return in the response.
#' [`converse`][bedrockruntime_converse] and
#' [`converse_stream`][bedrockruntime_converse_stream] return the requested
#' fields as a JSON Pointer object in the `additionalModelResponseFields`
#' field. The following is example JSON for
#' `additionalModelResponseFieldPaths`.
#' 
#' `[ "/stop_sequence" ]`
#' 
#' For information about the JSON Pointer syntax, see the [Internet
#' Engineering Task Force
#' (IETF)](https://datatracker.ietf.org/doc/html/rfc6901) documentation.
#' 
#' [`converse`][bedrockruntime_converse] and
#' [`converse_stream`][bedrockruntime_converse_stream] reject an empty JSON
#' Pointer or incorrectly structured JSON Pointer with a `400` error code.
#' if the JSON Pointer is valid, but the requested field is not in the
#' model response, it is ignored by [`converse`][bedrockruntime_converse].
#' @param requestMetadata Key-value pairs that you can use to filter invocation logs.
#' @param performanceConfig Model performance settings for the request.
#'
#' @return
#' A list with the following syntax:
#' ```
#' list(
#'   output = list(
#'     message = list(
#'       role = "user"|"assistant",
#'       content = list(
#'         list(
#'           text = "string",
#'           image = list(
#'             format = "png"|"jpeg"|"gif"|"webp",
#'             source = list(
#'               bytes = raw
#'             )
#'           ),
#'           document = list(
#'             format = "pdf"|"csv"|"doc"|"docx"|"xls"|"xlsx"|"html"|"txt"|"md",
#'             name = "string",
#'             source = list(
#'               bytes = raw
#'             )
#'           ),
#'           video = list(
#'             format = "mkv"|"mov"|"mp4"|"webm"|"flv"|"mpeg"|"mpg"|"wmv"|"three_gp",
#'             source = list(
#'               bytes = raw,
#'               s3Location = list(
#'                 uri = "string",
#'                 bucketOwner = "string"
#'               )
#'             )
#'           ),
#'           toolUse = list(
#'             toolUseId = "string",
#'             name = "string",
#'             input = list()
#'           ),
#'           toolResult = list(
#'             toolUseId = "string",
#'             content = list(
#'               list(
#'                 json = list(),
#'                 text = "string",
#'                 image = list(
#'                   format = "png"|"jpeg"|"gif"|"webp",
#'                   source = list(
#'                     bytes = raw
#'                   )
#'                 ),
#'                 document = list(
#'                   format = "pdf"|"csv"|"doc"|"docx"|"xls"|"xlsx"|"html"|"txt"|"md",
#'                   name = "string",
#'                   source = list(
#'                     bytes = raw
#'                   )
#'                 ),
#'                 video = list(
#'                   format = "mkv"|"mov"|"mp4"|"webm"|"flv"|"mpeg"|"mpg"|"wmv"|"three_gp",
#'                   source = list(
#'                     bytes = raw,
#'                     s3Location = list(
#'                       uri = "string",
#'                       bucketOwner = "string"
#'                     )
#'                   )
#'                 )
#'               )
#'             ),
#'             status = "success"|"error"
#'           ),
#'           guardContent = list(
#'             text = list(
#'               text = "string",
#'               qualifiers = list(
#'                 "grounding_source"|"query"|"guard_content"
#'               )
#'             ),
#'             image = list(
#'               format = "png"|"jpeg",
#'               source = list(
#'                 bytes = raw
#'               )
#'             )
#'           )
#'         )
#'       )
#'     )
#'   ),
#'   stopReason = "end_turn"|"tool_use"|"max_tokens"|"stop_sequence"|"guardrail_intervened"|"content_filtered",
#'   usage = list(
#'     inputTokens = 123,
#'     outputTokens = 123,
#'     totalTokens = 123
#'   ),
#'   metrics = list(
#'     latencyMs = 123
#'   ),
#'   additionalModelResponseFields = list(),
#'   trace = list(
#'     guardrail = list(
#'       modelOutput = list(
#'         "string"
#'       ),
#'       inputAssessment = list(
#'         list(
#'           topicPolicy = list(
#'             topics = list(
#'               list(
#'                 name = "string",
#'                 type = "DENY",
#'                 action = "BLOCKED"
#'               )
#'             )
#'           ),
#'           contentPolicy = list(
#'             filters = list(
#'               list(
#'                 type = "INSULTS"|"HATE"|"SEXUAL"|"VIOLENCE"|"MISCONDUCT"|"PROMPT_ATTACK",
#'                 confidence = "NONE"|"LOW"|"MEDIUM"|"HIGH",
#'                 filterStrength = "NONE"|"LOW"|"MEDIUM"|"HIGH",
#'                 action = "BLOCKED"
#'               )
#'             )
#'           ),
#'           wordPolicy = list(
#'             customWords = list(
#'               list(
#'                 match = "string",
#'                 action = "BLOCKED"
#'               )
#'             ),
#'             managedWordLists = list(
#'               list(
#'                 match = "string",
#'                 type = "PROFANITY",
#'                 action = "BLOCKED"
#'               )
#'             )
#'           ),
#'           sensitiveInformationPolicy = list(
#'             piiEntities = list(
#'               list(
#'                 match = "string",
#'                 type = "ADDRESS"|"AGE"|"AWS_ACCESS_KEY"|"AWS_SECRET_KEY"|"CA_HEALTH_NUMBER"|"CA_SOCIAL_INSURANCE_NUMBER"|"CREDIT_DEBIT_CARD_CVV"|"CREDIT_DEBIT_CARD_EXPIRY"|"CREDIT_DEBIT_CARD_NUMBER"|"DRIVER_ID"|"EMAIL"|"INTERNATIONAL_BANK_ACCOUNT_NUMBER"|"IP_ADDRESS"|"LICENSE_PLATE"|"MAC_ADDRESS"|"NAME"|"PASSWORD"|"PHONE"|"PIN"|"SWIFT_CODE"|"UK_NATIONAL_HEALTH_SERVICE_NUMBER"|"UK_NATIONAL_INSURANCE_NUMBER"|"UK_UNIQUE_TAXPAYER_REFERENCE_NUMBER"|"URL"|"USERNAME"|"US_BANK_ACCOUNT_NUMBER"|"US_BANK_ROUTING_NUMBER"|"US_INDIVIDUAL_TAX_IDENTIFICATION_NUMBER"|"US_PASSPORT_NUMBER"|"US_SOCIAL_SECURITY_NUMBER"|"VEHICLE_IDENTIFICATION_NUMBER",
#'                 action = "ANONYMIZED"|"BLOCKED"
#'               )
#'             ),
#'             regexes = list(
#'               list(
#'                 name = "string",
#'                 match = "string",
#'                 regex = "string",
#'                 action = "ANONYMIZED"|"BLOCKED"
#'               )
#'             )
#'           ),
#'           contextualGroundingPolicy = list(
#'             filters = list(
#'               list(
#'                 type = "GROUNDING"|"RELEVANCE",
#'                 threshold = 123.0,
#'                 score = 123.0,
#'                 action = "BLOCKED"|"NONE"
#'               )
#'             )
#'           ),
#'           invocationMetrics = list(
#'             guardrailProcessingLatency = 123,
#'             usage = list(
#'               topicPolicyUnits = 123,
#'               contentPolicyUnits = 123,
#'               wordPolicyUnits = 123,
#'               sensitiveInformationPolicyUnits = 123,
#'               sensitiveInformationPolicyFreeUnits = 123,
#'               contextualGroundingPolicyUnits = 123
#'             ),
#'             guardrailCoverage = list(
#'               textCharacters = list(
#'                 guarded = 123,
#'                 total = 123
#'               ),
#'               images = list(
#'                 guarded = 123,
#'                 total = 123
#'               )
#'             )
#'           )
#'         )
#'       ),
#'       outputAssessments = list(
#'         list(
#'           list(
#'             topicPolicy = list(
#'               topics = list(
#'                 list(
#'                   name = "string",
#'                   type = "DENY",
#'                   action = "BLOCKED"
#'                 )
#'               )
#'             ),
#'             contentPolicy = list(
#'               filters = list(
#'                 list(
#'                   type = "INSULTS"|"HATE"|"SEXUAL"|"VIOLENCE"|"MISCONDUCT"|"PROMPT_ATTACK",
#'                   confidence = "NONE"|"LOW"|"MEDIUM"|"HIGH",
#'                   filterStrength = "NONE"|"LOW"|"MEDIUM"|"HIGH",
#'                   action = "BLOCKED"
#'                 )
#'               )
#'             ),
#'             wordPolicy = list(
#'               customWords = list(
#'                 list(
#'                   match = "string",
#'                   action = "BLOCKED"
#'                 )
#'               ),
#'               managedWordLists = list(
#'                 list(
#'                   match = "string",
#'                   type = "PROFANITY",
#'                   action = "BLOCKED"
#'                 )
#'               )
#'             ),
#'             sensitiveInformationPolicy = list(
#'               piiEntities = list(
#'                 list(
#'                   match = "string",
#'                   type = "ADDRESS"|"AGE"|"AWS_ACCESS_KEY"|"AWS_SECRET_KEY"|"CA_HEALTH_NUMBER"|"CA_SOCIAL_INSURANCE_NUMBER"|"CREDIT_DEBIT_CARD_CVV"|"CREDIT_DEBIT_CARD_EXPIRY"|"CREDIT_DEBIT_CARD_NUMBER"|"DRIVER_ID"|"EMAIL"|"INTERNATIONAL_BANK_ACCOUNT_NUMBER"|"IP_ADDRESS"|"LICENSE_PLATE"|"MAC_ADDRESS"|"NAME"|"PASSWORD"|"PHONE"|"PIN"|"SWIFT_CODE"|"UK_NATIONAL_HEALTH_SERVICE_NUMBER"|"UK_NATIONAL_INSURANCE_NUMBER"|"UK_UNIQUE_TAXPAYER_REFERENCE_NUMBER"|"URL"|"USERNAME"|"US_BANK_ACCOUNT_NUMBER"|"US_BANK_ROUTING_NUMBER"|"US_INDIVIDUAL_TAX_IDENTIFICATION_NUMBER"|"US_PASSPORT_NUMBER"|"US_SOCIAL_SECURITY_NUMBER"|"VEHICLE_IDENTIFICATION_NUMBER",
#'                   action = "ANONYMIZED"|"BLOCKED"
#'                 )
#'               ),
#'               regexes = list(
#'                 list(
#'                   name = "string",
#'                   match = "string",
#'                   regex = "string",
#'                   action = "ANONYMIZED"|"BLOCKED"
#'                 )
#'               )
#'             ),
#'             contextualGroundingPolicy = list(
#'               filters = list(
#'                 list(
#'                   type = "GROUNDING"|"RELEVANCE",
#'                   threshold = 123.0,
#'                   score = 123.0,
#'                   action = "BLOCKED"|"NONE"
#'                 )
#'               )
#'             ),
#'             invocationMetrics = list(
#'               guardrailProcessingLatency = 123,
#'               usage = list(
#'                 topicPolicyUnits = 123,
#'                 contentPolicyUnits = 123,
#'                 wordPolicyUnits = 123,
#'                 sensitiveInformationPolicyUnits = 123,
#'                 sensitiveInformationPolicyFreeUnits = 123,
#'                 contextualGroundingPolicyUnits = 123
#'               ),
#'               guardrailCoverage = list(
#'                 textCharacters = list(
#'                   guarded = 123,
#'                   total = 123
#'                 ),
#'                 images = list(
#'                   guarded = 123,
#'                   total = 123
#'                 )
#'               )
#'             )
#'           )
#'         )
#'       )
#'     ),
#'     promptRouter = list(
#'       invokedModelId = "string"
#'     )
#'   ),
#'   performanceConfig = list(
#'     latency = "standard"|"optimized"
#'   )
#' )
#' ```
#'
#' @section Request syntax:
#' ```
#' svc$converse(
#'   modelId = "string",
#'   messages = list(
#'     list(
#'       role = "user"|"assistant",
#'       content = list(
#'         list(
#'           text = "string",
#'           image = list(
#'             format = "png"|"jpeg"|"gif"|"webp",
#'             source = list(
#'               bytes = raw
#'             )
#'           ),
#'           document = list(
#'             format = "pdf"|"csv"|"doc"|"docx"|"xls"|"xlsx"|"html"|"txt"|"md",
#'             name = "string",
#'             source = list(
#'               bytes = raw
#'             )
#'           ),
#'           video = list(
#'             format = "mkv"|"mov"|"mp4"|"webm"|"flv"|"mpeg"|"mpg"|"wmv"|"three_gp",
#'             source = list(
#'               bytes = raw,
#'               s3Location = list(
#'                 uri = "string",
#'                 bucketOwner = "string"
#'               )
#'             )
#'           ),
#'           toolUse = list(
#'             toolUseId = "string",
#'             name = "string",
#'             input = list()
#'           ),
#'           toolResult = list(
#'             toolUseId = "string",
#'             content = list(
#'               list(
#'                 json = list(),
#'                 text = "string",
#'                 image = list(
#'                   format = "png"|"jpeg"|"gif"|"webp",
#'                   source = list(
#'                     bytes = raw
#'                   )
#'                 ),
#'                 document = list(
#'                   format = "pdf"|"csv"|"doc"|"docx"|"xls"|"xlsx"|"html"|"txt"|"md",
#'                   name = "string",
#'                   source = list(
#'                     bytes = raw
#'                   )
#'                 ),
#'                 video = list(
#'                   format = "mkv"|"mov"|"mp4"|"webm"|"flv"|"mpeg"|"mpg"|"wmv"|"three_gp",
#'                   source = list(
#'                     bytes = raw,
#'                     s3Location = list(
#'                       uri = "string",
#'                       bucketOwner = "string"
#'                     )
#'                   )
#'                 )
#'               )
#'             ),
#'             status = "success"|"error"
#'           ),
#'           guardContent = list(
#'             text = list(
#'               text = "string",
#'               qualifiers = list(
#'                 "grounding_source"|"query"|"guard_content"
#'               )
#'             ),
#'             image = list(
#'               format = "png"|"jpeg",
#'               source = list(
#'                 bytes = raw
#'               )
#'             )
#'           )
#'         )
#'       )
#'     )
#'   ),
#'   system = list(
#'     list(
#'       text = "string",
#'       guardContent = list(
#'         text = list(
#'           text = "string",
#'           qualifiers = list(
#'             "grounding_source"|"query"|"guard_content"
#'           )
#'         ),
#'         image = list(
#'           format = "png"|"jpeg",
#'           source = list(
#'             bytes = raw
#'           )
#'         )
#'       )
#'     )
#'   ),
#'   inferenceConfig = list(
#'     maxTokens = 123,
#'     temperature = 123.0,
#'     topP = 123.0,
#'     stopSequences = list(
#'       "string"
#'     )
#'   ),
#'   toolConfig = list(
#'     tools = list(
#'       list(
#'         toolSpec = list(
#'           name = "string",
#'           description = "string",
#'           inputSchema = list(
#'             json = list()
#'           )
#'         )
#'       )
#'     ),
#'     toolChoice = list(
#'       auto = list(),
#'       any = list(),
#'       tool = list(
#'         name = "string"
#'       )
#'     )
#'   ),
#'   guardrailConfig = list(
#'     guardrailIdentifier = "string",
#'     guardrailVersion = "string",
#'     trace = "enabled"|"disabled"
#'   ),
#'   additionalModelRequestFields = list(),
#'   promptVariables = list(
#'     list(
#'       text = "string"
#'     )
#'   ),
#'   additionalModelResponseFieldPaths = list(
#'     "string"
#'   ),
#'   requestMetadata = list(
#'     "string"
#'   ),
#'   performanceConfig = list(
#'     latency = "standard"|"optimized"
#'   )
#' )
#' ```
#'
#' @keywords internal
#'
#' @rdname bedrockruntime_converse
#'
#' @aliases bedrockruntime_converse
bedrockruntime_converse <- function(modelId, messages = NULL, system = NULL, inferenceConfig = NULL, toolConfig = NULL, guardrailConfig = NULL, additionalModelRequestFields = NULL, promptVariables = NULL, additionalModelResponseFieldPaths = NULL, requestMetadata = NULL, performanceConfig = NULL) {
  op <- new_operation(
    name = "Converse",
    http_method = "POST",
    http_path = "/model/{modelId}/converse",
    host_prefix = "",
    paginator = list(),
    stream_api = FALSE
  )
  input <- .bedrockruntime$converse_input(modelId = modelId, messages = messages, system = system, inferenceConfig = inferenceConfig, toolConfig = toolConfig, guardrailConfig = guardrailConfig, additionalModelRequestFields = additionalModelRequestFields, promptVariables = promptVariables, additionalModelResponseFieldPaths = additionalModelResponseFieldPaths, requestMetadata = requestMetadata, performanceConfig = performanceConfig)
  output <- .bedrockruntime$converse_output()
  config <- get_config()
  svc <- .bedrockruntime$service(config, op)
  request <- new_request(svc, op, input, output)
  response <- send_request(request)
  return(response)
}
.bedrockruntime$operations$converse <- bedrockruntime_converse

#' Sends messages to the specified Amazon Bedrock model and returns the
#' response in a stream
#'
#' @description
#' Sends messages to the specified Amazon Bedrock model and returns the
#' response in a stream.
#' [`converse_stream`][bedrockruntime_converse_stream] provides a
#' consistent API that works with all Amazon Bedrock models that support
#' messages. This allows you to write code once and use it with different
#' models. Should a model have unique inference parameters, you can also
#' pass those unique parameters to the model.
#' 
#' To find out if a model supports streaming, call
#' [GetFoundationModel](https://docs.aws.amazon.com/bedrock/latest/APIReference/API_GetFoundationModel.html)
#' and check the `responseStreamingSupported` field in the response.
#' 
#' The CLI doesn't support streaming operations in Amazon Bedrock,
#' including [`converse_stream`][bedrockruntime_converse_stream].
#' 
#' Amazon Bedrock doesn't store any text, images, or documents that you
#' provide as content. The data is only used to generate the response.
#' 
#' You can submit a prompt by including it in the `messages` field,
#' specifying the `modelId` of a foundation model or inference profile to
#' run inference on it, and including any other fields that are relevant to
#' your use case.
#' 
#' You can also submit a prompt from Prompt management by specifying the
#' ARN of the prompt version and including a map of variables to values in
#' the `promptVariables` field. You can append more messages to the prompt
#' by using the `messages` field. If you use a prompt from Prompt
#' management, you can't include the following fields in the request:
#' `additionalModelRequestFields`, `inferenceConfig`, `system`, or
#' `toolConfig`. Instead, these fields must be defined through Prompt
#' management. For more information, see [Use a prompt from Prompt
#' management](https://docs.aws.amazon.com/bedrock/latest/userguide/).
#' 
#' For information about the Converse API, see *Use the Converse API* in
#' the *Amazon Bedrock User Guide*. To use a guardrail, see *Use a
#' guardrail with the Converse API* in the *Amazon Bedrock User Guide*. To
#' use a tool with a model, see *Tool use (Function calling)* in the
#' *Amazon Bedrock User Guide*
#' 
#' For example code, see *Conversation streaming example* in the *Amazon
#' Bedrock User Guide*.
#' 
#' This operation requires permission for the
#' `bedrock:InvokeModelWithResponseStream` action.
#' 
#' To deny all inference access to resources that you specify in the
#' modelId field, you need to deny access to the `bedrock:InvokeModel` and
#' `bedrock:InvokeModelWithResponseStream` actions. Doing this also denies
#' access to the resource through the base inference actions
#' ([`invoke_model`][bedrockruntime_invoke_model] and
#' [`invoke_model_with_response_stream`][bedrockruntime_invoke_model_with_response_stream]).
#' For more information see [Deny access for inference on specific
#' models](https://docs.aws.amazon.com/bedrock/latest/userguide/security_iam_id-based-policy-examples.html#security_iam_id-based-policy-examples-deny-inference).
#' 
#' For troubleshooting some of the common errors you might encounter when
#' using the [`converse_stream`][bedrockruntime_converse_stream] API, see
#' [Troubleshooting Amazon Bedrock API Error
#' Codes](https://docs.aws.amazon.com/bedrock/latest/userguide/troubleshooting-api-error-codes.html)
#' in the Amazon Bedrock User Guide
#'
#' @usage
#' bedrockruntime_converse_stream(modelId, messages, system,
#'   inferenceConfig, toolConfig, guardrailConfig,
#'   additionalModelRequestFields, promptVariables,
#'   additionalModelResponseFieldPaths, requestMetadata, performanceConfig)
#'
#' @param modelId &#91;required&#93; Specifies the model or throughput with which to run inference, or the
#' prompt resource to use in inference. The value depends on the resource
#' that you use:
#' 
#' -   If you use a base model, specify the model ID or its ARN. For a list
#'     of model IDs for base models, see [Amazon Bedrock base model IDs
#'     (on-demand
#'     throughput)](https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html#model-ids-arns)
#'     in the Amazon Bedrock User Guide.
#' 
#' -   If you use an inference profile, specify the inference profile ID or
#'     its ARN. For a list of inference profile IDs, see [Supported Regions
#'     and models for cross-region
#'     inference](https://docs.aws.amazon.com/bedrock/latest/userguide/inference-profiles-support.html)
#'     in the Amazon Bedrock User Guide.
#' 
#' -   If you use a provisioned model, specify the ARN of the Provisioned
#'     Throughput. For more information, see [Run inference using a
#'     Provisioned
#'     Throughput](https://docs.aws.amazon.com/bedrock/latest/userguide/prov-thru-use.html)
#'     in the Amazon Bedrock User Guide.
#' 
#' -   If you use a custom model, first purchase Provisioned Throughput for
#'     it. Then specify the ARN of the resulting provisioned model. For
#'     more information, see [Use a custom model in Amazon
#'     Bedrock](https://docs.aws.amazon.com/bedrock/latest/userguide/model-customization-use.html)
#'     in the Amazon Bedrock User Guide.
#' 
#' -   To include a prompt that was defined in [Prompt
#'     management](https://docs.aws.amazon.com/bedrock/latest/userguide/prompt-management.html),
#'     specify the ARN of the prompt version to use.
#' 
#' The Converse API doesn't support [imported
#' models](https://docs.aws.amazon.com/bedrock/latest/userguide/model-customization-import-model.html).
#' @param messages The messages that you want to send to the model.
#' @param system A prompt that provides instructions or context to the model about the
#' task it should perform, or the persona it should adopt during the
#' conversation.
#' @param inferenceConfig Inference parameters to pass to the model.
#' [`converse`][bedrockruntime_converse] and
#' [`converse_stream`][bedrockruntime_converse_stream] support a base set
#' of inference parameters. If you need to pass additional parameters that
#' the model supports, use the `additionalModelRequestFields` request
#' field.
#' @param toolConfig Configuration information for the tools that the model can use when
#' generating a response.
#' 
#' For information about models that support streaming tool use, see
#' [Supported models and model
#' features](https://docs.aws.amazon.com/bedrock/latest/userguide/conversation-inference.html#conversation-inference-supported-models-features).
#' @param guardrailConfig Configuration information for a guardrail that you want to use in the
#' request. If you include `guardContent` blocks in the `content` field in
#' the `messages` field, the guardrail operates only on those messages. If
#' you include no `guardContent` blocks, the guardrail operates on all
#' messages in the request body and in any included prompt resource.
#' @param additionalModelRequestFields Additional inference parameters that the model supports, beyond the base
#' set of inference parameters that [`converse`][bedrockruntime_converse]
#' and [`converse_stream`][bedrockruntime_converse_stream] support in the
#' `inferenceConfig` field. For more information, see [Model
#' parameters](https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters.html).
#' @param promptVariables Contains a map of variables in a prompt from Prompt management to
#' objects containing the values to fill in for them when running model
#' invocation. This field is ignored if you don't specify a prompt resource
#' in the `modelId` field.
#' @param additionalModelResponseFieldPaths Additional model parameters field paths to return in the response.
#' [`converse`][bedrockruntime_converse] and
#' [`converse_stream`][bedrockruntime_converse_stream] return the requested
#' fields as a JSON Pointer object in the `additionalModelResponseFields`
#' field. The following is example JSON for
#' `additionalModelResponseFieldPaths`.
#' 
#' `[ "/stop_sequence" ]`
#' 
#' For information about the JSON Pointer syntax, see the [Internet
#' Engineering Task Force
#' (IETF)](https://datatracker.ietf.org/doc/html/rfc6901) documentation.
#' 
#' [`converse`][bedrockruntime_converse] and
#' [`converse_stream`][bedrockruntime_converse_stream] reject an empty JSON
#' Pointer or incorrectly structured JSON Pointer with a `400` error code.
#' if the JSON Pointer is valid, but the requested field is not in the
#' model response, it is ignored by [`converse`][bedrockruntime_converse].
#' @param requestMetadata Key-value pairs that you can use to filter invocation logs.
#' @param performanceConfig Model performance settings for the request.
#'
#' @return
#' A list with the following syntax:
#' ```
#' list(
#'   stream = list(
#'     messageStart = list(
#'       role = "user"|"assistant"
#'     ),
#'     contentBlockStart = list(
#'       start = list(
#'         toolUse = list(
#'           toolUseId = "string",
#'           name = "string"
#'         )
#'       ),
#'       contentBlockIndex = 123
#'     ),
#'     contentBlockDelta = list(
#'       delta = list(
#'         text = "string",
#'         toolUse = list(
#'           input = "string"
#'         )
#'       ),
#'       contentBlockIndex = 123
#'     ),
#'     contentBlockStop = list(
#'       contentBlockIndex = 123
#'     ),
#'     messageStop = list(
#'       stopReason = "end_turn"|"tool_use"|"max_tokens"|"stop_sequence"|"guardrail_intervened"|"content_filtered",
#'       additionalModelResponseFields = list()
#'     ),
#'     metadata = list(
#'       usage = list(
#'         inputTokens = 123,
#'         outputTokens = 123,
#'         totalTokens = 123
#'       ),
#'       metrics = list(
#'         latencyMs = 123
#'       ),
#'       trace = list(
#'         guardrail = list(
#'           modelOutput = list(
#'             "string"
#'           ),
#'           inputAssessment = list(
#'             list(
#'               topicPolicy = list(
#'                 topics = list(
#'                   list(
#'                     name = "string",
#'                     type = "DENY",
#'                     action = "BLOCKED"
#'                   )
#'                 )
#'               ),
#'               contentPolicy = list(
#'                 filters = list(
#'                   list(
#'                     type = "INSULTS"|"HATE"|"SEXUAL"|"VIOLENCE"|"MISCONDUCT"|"PROMPT_ATTACK",
#'                     confidence = "NONE"|"LOW"|"MEDIUM"|"HIGH",
#'                     filterStrength = "NONE"|"LOW"|"MEDIUM"|"HIGH",
#'                     action = "BLOCKED"
#'                   )
#'                 )
#'               ),
#'               wordPolicy = list(
#'                 customWords = list(
#'                   list(
#'                     match = "string",
#'                     action = "BLOCKED"
#'                   )
#'                 ),
#'                 managedWordLists = list(
#'                   list(
#'                     match = "string",
#'                     type = "PROFANITY",
#'                     action = "BLOCKED"
#'                   )
#'                 )
#'               ),
#'               sensitiveInformationPolicy = list(
#'                 piiEntities = list(
#'                   list(
#'                     match = "string",
#'                     type = "ADDRESS"|"AGE"|"AWS_ACCESS_KEY"|"AWS_SECRET_KEY"|"CA_HEALTH_NUMBER"|"CA_SOCIAL_INSURANCE_NUMBER"|"CREDIT_DEBIT_CARD_CVV"|"CREDIT_DEBIT_CARD_EXPIRY"|"CREDIT_DEBIT_CARD_NUMBER"|"DRIVER_ID"|"EMAIL"|"INTERNATIONAL_BANK_ACCOUNT_NUMBER"|"IP_ADDRESS"|"LICENSE_PLATE"|"MAC_ADDRESS"|"NAME"|"PASSWORD"|"PHONE"|"PIN"|"SWIFT_CODE"|"UK_NATIONAL_HEALTH_SERVICE_NUMBER"|"UK_NATIONAL_INSURANCE_NUMBER"|"UK_UNIQUE_TAXPAYER_REFERENCE_NUMBER"|"URL"|"USERNAME"|"US_BANK_ACCOUNT_NUMBER"|"US_BANK_ROUTING_NUMBER"|"US_INDIVIDUAL_TAX_IDENTIFICATION_NUMBER"|"US_PASSPORT_NUMBER"|"US_SOCIAL_SECURITY_NUMBER"|"VEHICLE_IDENTIFICATION_NUMBER",
#'                     action = "ANONYMIZED"|"BLOCKED"
#'                   )
#'                 ),
#'                 regexes = list(
#'                   list(
#'                     name = "string",
#'                     match = "string",
#'                     regex = "string",
#'                     action = "ANONYMIZED"|"BLOCKED"
#'                   )
#'                 )
#'               ),
#'               contextualGroundingPolicy = list(
#'                 filters = list(
#'                   list(
#'                     type = "GROUNDING"|"RELEVANCE",
#'                     threshold = 123.0,
#'                     score = 123.0,
#'                     action = "BLOCKED"|"NONE"
#'                   )
#'                 )
#'               ),
#'               invocationMetrics = list(
#'                 guardrailProcessingLatency = 123,
#'                 usage = list(
#'                   topicPolicyUnits = 123,
#'                   contentPolicyUnits = 123,
#'                   wordPolicyUnits = 123,
#'                   sensitiveInformationPolicyUnits = 123,
#'                   sensitiveInformationPolicyFreeUnits = 123,
#'                   contextualGroundingPolicyUnits = 123
#'                 ),
#'                 guardrailCoverage = list(
#'                   textCharacters = list(
#'                     guarded = 123,
#'                     total = 123
#'                   ),
#'                   images = list(
#'                     guarded = 123,
#'                     total = 123
#'                   )
#'                 )
#'               )
#'             )
#'           ),
#'           outputAssessments = list(
#'             list(
#'               list(
#'                 topicPolicy = list(
#'                   topics = list(
#'                     list(
#'                       name = "string",
#'                       type = "DENY",
#'                       action = "BLOCKED"
#'                     )
#'                   )
#'                 ),
#'                 contentPolicy = list(
#'                   filters = list(
#'                     list(
#'                       type = "INSULTS"|"HATE"|"SEXUAL"|"VIOLENCE"|"MISCONDUCT"|"PROMPT_ATTACK",
#'                       confidence = "NONE"|"LOW"|"MEDIUM"|"HIGH",
#'                       filterStrength = "NONE"|"LOW"|"MEDIUM"|"HIGH",
#'                       action = "BLOCKED"
#'                     )
#'                   )
#'                 ),
#'                 wordPolicy = list(
#'                   customWords = list(
#'                     list(
#'                       match = "string",
#'                       action = "BLOCKED"
#'                     )
#'                   ),
#'                   managedWordLists = list(
#'                     list(
#'                       match = "string",
#'                       type = "PROFANITY",
#'                       action = "BLOCKED"
#'                     )
#'                   )
#'                 ),
#'                 sensitiveInformationPolicy = list(
#'                   piiEntities = list(
#'                     list(
#'                       match = "string",
#'                       type = "ADDRESS"|"AGE"|"AWS_ACCESS_KEY"|"AWS_SECRET_KEY"|"CA_HEALTH_NUMBER"|"CA_SOCIAL_INSURANCE_NUMBER"|"CREDIT_DEBIT_CARD_CVV"|"CREDIT_DEBIT_CARD_EXPIRY"|"CREDIT_DEBIT_CARD_NUMBER"|"DRIVER_ID"|"EMAIL"|"INTERNATIONAL_BANK_ACCOUNT_NUMBER"|"IP_ADDRESS"|"LICENSE_PLATE"|"MAC_ADDRESS"|"NAME"|"PASSWORD"|"PHONE"|"PIN"|"SWIFT_CODE"|"UK_NATIONAL_HEALTH_SERVICE_NUMBER"|"UK_NATIONAL_INSURANCE_NUMBER"|"UK_UNIQUE_TAXPAYER_REFERENCE_NUMBER"|"URL"|"USERNAME"|"US_BANK_ACCOUNT_NUMBER"|"US_BANK_ROUTING_NUMBER"|"US_INDIVIDUAL_TAX_IDENTIFICATION_NUMBER"|"US_PASSPORT_NUMBER"|"US_SOCIAL_SECURITY_NUMBER"|"VEHICLE_IDENTIFICATION_NUMBER",
#'                       action = "ANONYMIZED"|"BLOCKED"
#'                     )
#'                   ),
#'                   regexes = list(
#'                     list(
#'                       name = "string",
#'                       match = "string",
#'                       regex = "string",
#'                       action = "ANONYMIZED"|"BLOCKED"
#'                     )
#'                   )
#'                 ),
#'                 contextualGroundingPolicy = list(
#'                   filters = list(
#'                     list(
#'                       type = "GROUNDING"|"RELEVANCE",
#'                       threshold = 123.0,
#'                       score = 123.0,
#'                       action = "BLOCKED"|"NONE"
#'                     )
#'                   )
#'                 ),
#'                 invocationMetrics = list(
#'                   guardrailProcessingLatency = 123,
#'                   usage = list(
#'                     topicPolicyUnits = 123,
#'                     contentPolicyUnits = 123,
#'                     wordPolicyUnits = 123,
#'                     sensitiveInformationPolicyUnits = 123,
#'                     sensitiveInformationPolicyFreeUnits = 123,
#'                     contextualGroundingPolicyUnits = 123
#'                   ),
#'                   guardrailCoverage = list(
#'                     textCharacters = list(
#'                       guarded = 123,
#'                       total = 123
#'                     ),
#'                     images = list(
#'                       guarded = 123,
#'                       total = 123
#'                     )
#'                   )
#'                 )
#'               )
#'             )
#'           )
#'         ),
#'         promptRouter = list(
#'           invokedModelId = "string"
#'         )
#'       ),
#'       performanceConfig = list(
#'         latency = "standard"|"optimized"
#'       )
#'     ),
#'     internalServerException = list(
#'       message = "string"
#'     ),
#'     modelStreamErrorException = list(
#'       message = "string",
#'       originalStatusCode = 123,
#'       originalMessage = "string"
#'     ),
#'     validationException = list(
#'       message = "string"
#'     ),
#'     throttlingException = list(
#'       message = "string"
#'     ),
#'     serviceUnavailableException = list(
#'       message = "string"
#'     )
#'   )
#' )
#' ```
#'
#' @section Request syntax:
#' ```
#' svc$converse_stream(
#'   modelId = "string",
#'   messages = list(
#'     list(
#'       role = "user"|"assistant",
#'       content = list(
#'         list(
#'           text = "string",
#'           image = list(
#'             format = "png"|"jpeg"|"gif"|"webp",
#'             source = list(
#'               bytes = raw
#'             )
#'           ),
#'           document = list(
#'             format = "pdf"|"csv"|"doc"|"docx"|"xls"|"xlsx"|"html"|"txt"|"md",
#'             name = "string",
#'             source = list(
#'               bytes = raw
#'             )
#'           ),
#'           video = list(
#'             format = "mkv"|"mov"|"mp4"|"webm"|"flv"|"mpeg"|"mpg"|"wmv"|"three_gp",
#'             source = list(
#'               bytes = raw,
#'               s3Location = list(
#'                 uri = "string",
#'                 bucketOwner = "string"
#'               )
#'             )
#'           ),
#'           toolUse = list(
#'             toolUseId = "string",
#'             name = "string",
#'             input = list()
#'           ),
#'           toolResult = list(
#'             toolUseId = "string",
#'             content = list(
#'               list(
#'                 json = list(),
#'                 text = "string",
#'                 image = list(
#'                   format = "png"|"jpeg"|"gif"|"webp",
#'                   source = list(
#'                     bytes = raw
#'                   )
#'                 ),
#'                 document = list(
#'                   format = "pdf"|"csv"|"doc"|"docx"|"xls"|"xlsx"|"html"|"txt"|"md",
#'                   name = "string",
#'                   source = list(
#'                     bytes = raw
#'                   )
#'                 ),
#'                 video = list(
#'                   format = "mkv"|"mov"|"mp4"|"webm"|"flv"|"mpeg"|"mpg"|"wmv"|"three_gp",
#'                   source = list(
#'                     bytes = raw,
#'                     s3Location = list(
#'                       uri = "string",
#'                       bucketOwner = "string"
#'                     )
#'                   )
#'                 )
#'               )
#'             ),
#'             status = "success"|"error"
#'           ),
#'           guardContent = list(
#'             text = list(
#'               text = "string",
#'               qualifiers = list(
#'                 "grounding_source"|"query"|"guard_content"
#'               )
#'             ),
#'             image = list(
#'               format = "png"|"jpeg",
#'               source = list(
#'                 bytes = raw
#'               )
#'             )
#'           )
#'         )
#'       )
#'     )
#'   ),
#'   system = list(
#'     list(
#'       text = "string",
#'       guardContent = list(
#'         text = list(
#'           text = "string",
#'           qualifiers = list(
#'             "grounding_source"|"query"|"guard_content"
#'           )
#'         ),
#'         image = list(
#'           format = "png"|"jpeg",
#'           source = list(
#'             bytes = raw
#'           )
#'         )
#'       )
#'     )
#'   ),
#'   inferenceConfig = list(
#'     maxTokens = 123,
#'     temperature = 123.0,
#'     topP = 123.0,
#'     stopSequences = list(
#'       "string"
#'     )
#'   ),
#'   toolConfig = list(
#'     tools = list(
#'       list(
#'         toolSpec = list(
#'           name = "string",
#'           description = "string",
#'           inputSchema = list(
#'             json = list()
#'           )
#'         )
#'       )
#'     ),
#'     toolChoice = list(
#'       auto = list(),
#'       any = list(),
#'       tool = list(
#'         name = "string"
#'       )
#'     )
#'   ),
#'   guardrailConfig = list(
#'     guardrailIdentifier = "string",
#'     guardrailVersion = "string",
#'     trace = "enabled"|"disabled",
#'     streamProcessingMode = "sync"|"async"
#'   ),
#'   additionalModelRequestFields = list(),
#'   promptVariables = list(
#'     list(
#'       text = "string"
#'     )
#'   ),
#'   additionalModelResponseFieldPaths = list(
#'     "string"
#'   ),
#'   requestMetadata = list(
#'     "string"
#'   ),
#'   performanceConfig = list(
#'     latency = "standard"|"optimized"
#'   )
#' )
#' ```
#'
#' @keywords internal
#'
#' @rdname bedrockruntime_converse_stream
#'
#' @aliases bedrockruntime_converse_stream
bedrockruntime_converse_stream <- function(modelId, messages = NULL, system = NULL, inferenceConfig = NULL, toolConfig = NULL, guardrailConfig = NULL, additionalModelRequestFields = NULL, promptVariables = NULL, additionalModelResponseFieldPaths = NULL, requestMetadata = NULL, performanceConfig = NULL) {
  op <- new_operation(
    name = "ConverseStream",
    http_method = "POST",
    http_path = "/model/{modelId}/converse-stream",
    host_prefix = "",
    paginator = list(),
    stream_api = TRUE
  )
  input <- .bedrockruntime$converse_stream_input(modelId = modelId, messages = messages, system = system, inferenceConfig = inferenceConfig, toolConfig = toolConfig, guardrailConfig = guardrailConfig, additionalModelRequestFields = additionalModelRequestFields, promptVariables = promptVariables, additionalModelResponseFieldPaths = additionalModelResponseFieldPaths, requestMetadata = requestMetadata, performanceConfig = performanceConfig)
  output <- .bedrockruntime$converse_stream_output()
  config <- get_config()
  svc <- .bedrockruntime$service(config, op)
  request <- new_request(svc, op, input, output)
  response <- send_request(request)
  return(response)
}
.bedrockruntime$operations$converse_stream <- bedrockruntime_converse_stream

#' Retrieve information about an asynchronous invocation
#'
#' @description
#' Retrieve information about an asynchronous invocation.
#'
#' @usage
#' bedrockruntime_get_async_invoke(invocationArn)
#'
#' @param invocationArn &#91;required&#93; The invocation's ARN.
#'
#' @return
#' A list with the following syntax:
#' ```
#' list(
#'   invocationArn = "string",
#'   modelArn = "string",
#'   clientRequestToken = "string",
#'   status = "InProgress"|"Completed"|"Failed",
#'   failureMessage = "string",
#'   submitTime = as.POSIXct(
#'     "2015-01-01"
#'   ),
#'   lastModifiedTime = as.POSIXct(
#'     "2015-01-01"
#'   ),
#'   endTime = as.POSIXct(
#'     "2015-01-01"
#'   ),
#'   outputDataConfig = list(
#'     s3OutputDataConfig = list(
#'       s3Uri = "string",
#'       kmsKeyId = "string",
#'       bucketOwner = "string"
#'     )
#'   )
#' )
#' ```
#'
#' @section Request syntax:
#' ```
#' svc$get_async_invoke(
#'   invocationArn = "string"
#' )
#' ```
#'
#' @keywords internal
#'
#' @rdname bedrockruntime_get_async_invoke
#'
#' @aliases bedrockruntime_get_async_invoke
bedrockruntime_get_async_invoke <- function(invocationArn) {
  op <- new_operation(
    name = "GetAsyncInvoke",
    http_method = "GET",
    http_path = "/async-invoke/{invocationArn}",
    host_prefix = "",
    paginator = list(),
    stream_api = FALSE
  )
  input <- .bedrockruntime$get_async_invoke_input(invocationArn = invocationArn)
  output <- .bedrockruntime$get_async_invoke_output()
  config <- get_config()
  svc <- .bedrockruntime$service(config, op)
  request <- new_request(svc, op, input, output)
  response <- send_request(request)
  return(response)
}
.bedrockruntime$operations$get_async_invoke <- bedrockruntime_get_async_invoke

#' Invokes the specified Amazon Bedrock model to run inference using the
#' prompt and inference parameters provided in the request body
#'
#' @description
#' Invokes the specified Amazon Bedrock model to run inference using the
#' prompt and inference parameters provided in the request body. You use
#' model inference to generate text, images, and embeddings.
#' 
#' For example code, see *Invoke model code examples* in the *Amazon
#' Bedrock User Guide*.
#' 
#' This operation requires permission for the `bedrock:InvokeModel` action.
#' 
#' To deny all inference access to resources that you specify in the
#' modelId field, you need to deny access to the `bedrock:InvokeModel` and
#' `bedrock:InvokeModelWithResponseStream` actions. Doing this also denies
#' access to the resource through the Converse API actions
#' ([`converse`][bedrockruntime_converse] and
#' [`converse_stream`][bedrockruntime_converse_stream]). For more
#' information see [Deny access for inference on specific
#' models](https://docs.aws.amazon.com/bedrock/latest/userguide/security_iam_id-based-policy-examples.html#security_iam_id-based-policy-examples-deny-inference).
#' 
#' For troubleshooting some of the common errors you might encounter when
#' using the [`invoke_model`][bedrockruntime_invoke_model] API, see
#' [Troubleshooting Amazon Bedrock API Error
#' Codes](https://docs.aws.amazon.com/bedrock/latest/userguide/troubleshooting-api-error-codes.html)
#' in the Amazon Bedrock User Guide
#'
#' @usage
#' bedrockruntime_invoke_model(body, contentType, accept, modelId, trace,
#'   guardrailIdentifier, guardrailVersion, performanceConfigLatency)
#'
#' @param body The prompt and inference parameters in the format specified in the
#' `contentType` in the header. You must provide the body in JSON format.
#' To see the format and content of the request and response bodies for
#' different models, refer to [Inference
#' parameters](https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters.html).
#' For more information, see [Run
#' inference](https://docs.aws.amazon.com/bedrock/latest/userguide/inference.html)
#' in the Bedrock User Guide.
#' @param contentType The MIME type of the input data in the request. You must specify
#' `application/json`.
#' @param accept The desired MIME type of the inference body in the response. The default
#' value is `application/json`.
#' @param modelId &#91;required&#93; The unique identifier of the model to invoke to run inference.
#' 
#' The `modelId` to provide depends on the type of model or throughput that
#' you use:
#' 
#' -   If you use a base model, specify the model ID or its ARN. For a list
#'     of model IDs for base models, see [Amazon Bedrock base model IDs
#'     (on-demand
#'     throughput)](https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html#model-ids-arns)
#'     in the Amazon Bedrock User Guide.
#' 
#' -   If you use an inference profile, specify the inference profile ID or
#'     its ARN. For a list of inference profile IDs, see [Supported Regions
#'     and models for cross-region
#'     inference](https://docs.aws.amazon.com/bedrock/latest/userguide/inference-profiles-support.html)
#'     in the Amazon Bedrock User Guide.
#' 
#' -   If you use a provisioned model, specify the ARN of the Provisioned
#'     Throughput. For more information, see [Run inference using a
#'     Provisioned
#'     Throughput](https://docs.aws.amazon.com/bedrock/latest/userguide/prov-thru-use.html)
#'     in the Amazon Bedrock User Guide.
#' 
#' -   If you use a custom model, first purchase Provisioned Throughput for
#'     it. Then specify the ARN of the resulting provisioned model. For
#'     more information, see [Use a custom model in Amazon
#'     Bedrock](https://docs.aws.amazon.com/bedrock/latest/userguide/model-customization-use.html)
#'     in the Amazon Bedrock User Guide.
#' 
#' -   If you use an [imported
#'     model](https://docs.aws.amazon.com/bedrock/latest/userguide/model-customization-import-model.html),
#'     specify the ARN of the imported model. You can get the model ARN
#'     from a successful call to
#'     [CreateModelImportJob](https://docs.aws.amazon.com/bedrock/latest/APIReference/API_CreateModelImportJob.html)
#'     or from the Imported models page in the Amazon Bedrock console.
#' @param trace Specifies whether to enable or disable the Bedrock trace. If enabled,
#' you can see the full Bedrock trace.
#' @param guardrailIdentifier The unique identifier of the guardrail that you want to use. If you
#' don't provide a value, no guardrail is applied to the invocation.
#' 
#' An error will be thrown in the following situations.
#' 
#' -   You don't provide a guardrail identifier but you specify the
#'     `amazon-bedrock-guardrailConfig` field in the request body.
#' 
#' -   You enable the guardrail but the `contentType` isn't
#'     `application/json`.
#' 
#' -   You provide a guardrail identifier, but `guardrailVersion` isn't
#'     specified.
#' @param guardrailVersion The version number for the guardrail. The value can also be `DRAFT`.
#' @param performanceConfigLatency Model performance settings for the request.
#'
#' @return
#' A list with the following syntax:
#' ```
#' list(
#'   body = raw,
#'   contentType = "string",
#'   performanceConfigLatency = "standard"|"optimized"
#' )
#' ```
#'
#' @section Request syntax:
#' ```
#' svc$invoke_model(
#'   body = raw,
#'   contentType = "string",
#'   accept = "string",
#'   modelId = "string",
#'   trace = "ENABLED"|"DISABLED",
#'   guardrailIdentifier = "string",
#'   guardrailVersion = "string",
#'   performanceConfigLatency = "standard"|"optimized"
#' )
#' ```
#'
#' @keywords internal
#'
#' @rdname bedrockruntime_invoke_model
#'
#' @aliases bedrockruntime_invoke_model
bedrockruntime_invoke_model <- function(body = NULL, contentType = NULL, accept = NULL, modelId, trace = NULL, guardrailIdentifier = NULL, guardrailVersion = NULL, performanceConfigLatency = NULL) {
  op <- new_operation(
    name = "InvokeModel",
    http_method = "POST",
    http_path = "/model/{modelId}/invoke",
    host_prefix = "",
    paginator = list(),
    stream_api = FALSE
  )
  input <- .bedrockruntime$invoke_model_input(body = body, contentType = contentType, accept = accept, modelId = modelId, trace = trace, guardrailIdentifier = guardrailIdentifier, guardrailVersion = guardrailVersion, performanceConfigLatency = performanceConfigLatency)
  output <- .bedrockruntime$invoke_model_output()
  config <- get_config()
  svc <- .bedrockruntime$service(config, op)
  request <- new_request(svc, op, input, output)
  response <- send_request(request)
  return(response)
}
.bedrockruntime$operations$invoke_model <- bedrockruntime_invoke_model

#' Invoke the specified Amazon Bedrock model to run inference using the
#' prompt and inference parameters provided in the request body
#'
#' @description
#' Invoke the specified Amazon Bedrock model to run inference using the
#' prompt and inference parameters provided in the request body. The
#' response is returned in a stream.
#' 
#' To see if a model supports streaming, call
#' [GetFoundationModel](https://docs.aws.amazon.com/bedrock/latest/APIReference/API_GetFoundationModel.html)
#' and check the `responseStreamingSupported` field in the response.
#' 
#' The CLI doesn't support streaming operations in Amazon Bedrock,
#' including
#' [`invoke_model_with_response_stream`][bedrockruntime_invoke_model_with_response_stream].
#' 
#' For example code, see *Invoke model with streaming code example* in the
#' *Amazon Bedrock User Guide*.
#' 
#' This operation requires permissions to perform the
#' `bedrock:InvokeModelWithResponseStream` action.
#' 
#' To deny all inference access to resources that you specify in the
#' modelId field, you need to deny access to the `bedrock:InvokeModel` and
#' `bedrock:InvokeModelWithResponseStream` actions. Doing this also denies
#' access to the resource through the Converse API actions
#' ([`converse`][bedrockruntime_converse] and
#' [`converse_stream`][bedrockruntime_converse_stream]). For more
#' information see [Deny access for inference on specific
#' models](https://docs.aws.amazon.com/bedrock/latest/userguide/security_iam_id-based-policy-examples.html#security_iam_id-based-policy-examples-deny-inference).
#' 
#' For troubleshooting some of the common errors you might encounter when
#' using the
#' [`invoke_model_with_response_stream`][bedrockruntime_invoke_model_with_response_stream]
#' API, see [Troubleshooting Amazon Bedrock API Error
#' Codes](https://docs.aws.amazon.com/bedrock/latest/userguide/troubleshooting-api-error-codes.html)
#' in the Amazon Bedrock User Guide
#'
#' @usage
#' bedrockruntime_invoke_model_with_response_stream(body, contentType,
#'   accept, modelId, trace, guardrailIdentifier, guardrailVersion,
#'   performanceConfigLatency)
#'
#' @param body The prompt and inference parameters in the format specified in the
#' `contentType` in the header. You must provide the body in JSON format.
#' To see the format and content of the request and response bodies for
#' different models, refer to [Inference
#' parameters](https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters.html).
#' For more information, see [Run
#' inference](https://docs.aws.amazon.com/bedrock/latest/userguide/inference.html)
#' in the Bedrock User Guide.
#' @param contentType The MIME type of the input data in the request. You must specify
#' `application/json`.
#' @param accept The desired MIME type of the inference body in the response. The default
#' value is `application/json`.
#' @param modelId &#91;required&#93; The unique identifier of the model to invoke to run inference.
#' 
#' The `modelId` to provide depends on the type of model or throughput that
#' you use:
#' 
#' -   If you use a base model, specify the model ID or its ARN. For a list
#'     of model IDs for base models, see [Amazon Bedrock base model IDs
#'     (on-demand
#'     throughput)](https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html#model-ids-arns)
#'     in the Amazon Bedrock User Guide.
#' 
#' -   If you use an inference profile, specify the inference profile ID or
#'     its ARN. For a list of inference profile IDs, see [Supported Regions
#'     and models for cross-region
#'     inference](https://docs.aws.amazon.com/bedrock/latest/userguide/inference-profiles-support.html)
#'     in the Amazon Bedrock User Guide.
#' 
#' -   If you use a provisioned model, specify the ARN of the Provisioned
#'     Throughput. For more information, see [Run inference using a
#'     Provisioned
#'     Throughput](https://docs.aws.amazon.com/bedrock/latest/userguide/prov-thru-use.html)
#'     in the Amazon Bedrock User Guide.
#' 
#' -   If you use a custom model, first purchase Provisioned Throughput for
#'     it. Then specify the ARN of the resulting provisioned model. For
#'     more information, see [Use a custom model in Amazon
#'     Bedrock](https://docs.aws.amazon.com/bedrock/latest/userguide/model-customization-use.html)
#'     in the Amazon Bedrock User Guide.
#' 
#' -   If you use an [imported
#'     model](https://docs.aws.amazon.com/bedrock/latest/userguide/model-customization-import-model.html),
#'     specify the ARN of the imported model. You can get the model ARN
#'     from a successful call to
#'     [CreateModelImportJob](https://docs.aws.amazon.com/bedrock/latest/APIReference/API_CreateModelImportJob.html)
#'     or from the Imported models page in the Amazon Bedrock console.
#' @param trace Specifies whether to enable or disable the Bedrock trace. If enabled,
#' you can see the full Bedrock trace.
#' @param guardrailIdentifier The unique identifier of the guardrail that you want to use. If you
#' don't provide a value, no guardrail is applied to the invocation.
#' 
#' An error is thrown in the following situations.
#' 
#' -   You don't provide a guardrail identifier but you specify the
#'     `amazon-bedrock-guardrailConfig` field in the request body.
#' 
#' -   You enable the guardrail but the `contentType` isn't
#'     `application/json`.
#' 
#' -   You provide a guardrail identifier, but `guardrailVersion` isn't
#'     specified.
#' @param guardrailVersion The version number for the guardrail. The value can also be `DRAFT`.
#' @param performanceConfigLatency Model performance settings for the request.
#'
#' @return
#' A list with the following syntax:
#' ```
#' list(
#'   body = list(
#'     chunk = list(
#'       bytes = raw
#'     ),
#'     internalServerException = list(
#'       message = "string"
#'     ),
#'     modelStreamErrorException = list(
#'       message = "string",
#'       originalStatusCode = 123,
#'       originalMessage = "string"
#'     ),
#'     validationException = list(
#'       message = "string"
#'     ),
#'     throttlingException = list(
#'       message = "string"
#'     ),
#'     modelTimeoutException = list(
#'       message = "string"
#'     ),
#'     serviceUnavailableException = list(
#'       message = "string"
#'     )
#'   ),
#'   contentType = "string",
#'   performanceConfigLatency = "standard"|"optimized"
#' )
#' ```
#'
#' @section Request syntax:
#' ```
#' svc$invoke_model_with_response_stream(
#'   body = raw,
#'   contentType = "string",
#'   accept = "string",
#'   modelId = "string",
#'   trace = "ENABLED"|"DISABLED",
#'   guardrailIdentifier = "string",
#'   guardrailVersion = "string",
#'   performanceConfigLatency = "standard"|"optimized"
#' )
#' ```
#'
#' @keywords internal
#'
#' @rdname bedrockruntime_invoke_model_with_response_stream
#'
#' @aliases bedrockruntime_invoke_model_with_response_stream
bedrockruntime_invoke_model_with_response_stream <- function(body = NULL, contentType = NULL, accept = NULL, modelId, trace = NULL, guardrailIdentifier = NULL, guardrailVersion = NULL, performanceConfigLatency = NULL) {
  op <- new_operation(
    name = "InvokeModelWithResponseStream",
    http_method = "POST",
    http_path = "/model/{modelId}/invoke-with-response-stream",
    host_prefix = "",
    paginator = list(),
    stream_api = TRUE
  )
  input <- .bedrockruntime$invoke_model_with_response_stream_input(body = body, contentType = contentType, accept = accept, modelId = modelId, trace = trace, guardrailIdentifier = guardrailIdentifier, guardrailVersion = guardrailVersion, performanceConfigLatency = performanceConfigLatency)
  output <- .bedrockruntime$invoke_model_with_response_stream_output()
  config <- get_config()
  svc <- .bedrockruntime$service(config, op)
  request <- new_request(svc, op, input, output)
  response <- send_request(request)
  return(response)
}
.bedrockruntime$operations$invoke_model_with_response_stream <- bedrockruntime_invoke_model_with_response_stream

#' Lists asynchronous invocations
#'
#' @description
#' Lists asynchronous invocations.
#'
#' @usage
#' bedrockruntime_list_async_invokes(submitTimeAfter, submitTimeBefore,
#'   statusEquals, maxResults, nextToken, sortBy, sortOrder)
#'
#' @param submitTimeAfter Include invocations submitted after this time.
#' @param submitTimeBefore Include invocations submitted before this time.
#' @param statusEquals Filter invocations by status.
#' @param maxResults The maximum number of invocations to return in one page of results.
#' @param nextToken Specify the pagination token from a previous request to retrieve the
#' next page of results.
#' @param sortBy How to sort the response.
#' @param sortOrder The sorting order for the response.
#'
#' @return
#' A list with the following syntax:
#' ```
#' list(
#'   nextToken = "string",
#'   asyncInvokeSummaries = list(
#'     list(
#'       invocationArn = "string",
#'       modelArn = "string",
#'       clientRequestToken = "string",
#'       status = "InProgress"|"Completed"|"Failed",
#'       failureMessage = "string",
#'       submitTime = as.POSIXct(
#'         "2015-01-01"
#'       ),
#'       lastModifiedTime = as.POSIXct(
#'         "2015-01-01"
#'       ),
#'       endTime = as.POSIXct(
#'         "2015-01-01"
#'       ),
#'       outputDataConfig = list(
#'         s3OutputDataConfig = list(
#'           s3Uri = "string",
#'           kmsKeyId = "string",
#'           bucketOwner = "string"
#'         )
#'       )
#'     )
#'   )
#' )
#' ```
#'
#' @section Request syntax:
#' ```
#' svc$list_async_invokes(
#'   submitTimeAfter = as.POSIXct(
#'     "2015-01-01"
#'   ),
#'   submitTimeBefore = as.POSIXct(
#'     "2015-01-01"
#'   ),
#'   statusEquals = "InProgress"|"Completed"|"Failed",
#'   maxResults = 123,
#'   nextToken = "string",
#'   sortBy = "SubmissionTime",
#'   sortOrder = "Ascending"|"Descending"
#' )
#' ```
#'
#' @keywords internal
#'
#' @rdname bedrockruntime_list_async_invokes
#'
#' @aliases bedrockruntime_list_async_invokes
bedrockruntime_list_async_invokes <- function(submitTimeAfter = NULL, submitTimeBefore = NULL, statusEquals = NULL, maxResults = NULL, nextToken = NULL, sortBy = NULL, sortOrder = NULL) {
  op <- new_operation(
    name = "ListAsyncInvokes",
    http_method = "GET",
    http_path = "/async-invoke",
    host_prefix = "",
    paginator = list(input_token = "nextToken", output_token = "nextToken", limit_key = "maxResults", result_key = "asyncInvokeSummaries"),
    stream_api = FALSE
  )
  input <- .bedrockruntime$list_async_invokes_input(submitTimeAfter = submitTimeAfter, submitTimeBefore = submitTimeBefore, statusEquals = statusEquals, maxResults = maxResults, nextToken = nextToken, sortBy = sortBy, sortOrder = sortOrder)
  output <- .bedrockruntime$list_async_invokes_output()
  config <- get_config()
  svc <- .bedrockruntime$service(config, op)
  request <- new_request(svc, op, input, output)
  response <- send_request(request)
  return(response)
}
.bedrockruntime$operations$list_async_invokes <- bedrockruntime_list_async_invokes

#' Starts an asynchronous invocation
#'
#' @description
#' Starts an asynchronous invocation.
#' 
#' This operation requires permission for the `bedrock:InvokeModel` action.
#' 
#' To deny all inference access to resources that you specify in the
#' modelId field, you need to deny access to the `bedrock:InvokeModel` and
#' `bedrock:InvokeModelWithResponseStream` actions. Doing this also denies
#' access to the resource through the Converse API actions
#' ([`converse`][bedrockruntime_converse] and
#' [`converse_stream`][bedrockruntime_converse_stream]). For more
#' information see [Deny access for inference on specific
#' models](https://docs.aws.amazon.com/bedrock/latest/userguide/security_iam_id-based-policy-examples.html#security_iam_id-based-policy-examples-deny-inference).
#'
#' @usage
#' bedrockruntime_start_async_invoke(clientRequestToken, modelId,
#'   modelInput, outputDataConfig, tags)
#'
#' @param clientRequestToken Specify idempotency token to ensure that requests are not duplicated.
#' @param modelId &#91;required&#93; The model to invoke.
#' @param modelInput &#91;required&#93; Input to send to the model.
#' @param outputDataConfig &#91;required&#93; Where to store the output.
#' @param tags Tags to apply to the invocation.
#'
#' @return
#' A list with the following syntax:
#' ```
#' list(
#'   invocationArn = "string"
#' )
#' ```
#'
#' @section Request syntax:
#' ```
#' svc$start_async_invoke(
#'   clientRequestToken = "string",
#'   modelId = "string",
#'   modelInput = list(),
#'   outputDataConfig = list(
#'     s3OutputDataConfig = list(
#'       s3Uri = "string",
#'       kmsKeyId = "string",
#'       bucketOwner = "string"
#'     )
#'   ),
#'   tags = list(
#'     list(
#'       key = "string",
#'       value = "string"
#'     )
#'   )
#' )
#' ```
#'
#' @keywords internal
#'
#' @rdname bedrockruntime_start_async_invoke
#'
#' @aliases bedrockruntime_start_async_invoke
bedrockruntime_start_async_invoke <- function(clientRequestToken = NULL, modelId, modelInput, outputDataConfig, tags = NULL) {
  op <- new_operation(
    name = "StartAsyncInvoke",
    http_method = "POST",
    http_path = "/async-invoke",
    host_prefix = "",
    paginator = list(),
    stream_api = FALSE
  )
  input <- .bedrockruntime$start_async_invoke_input(clientRequestToken = clientRequestToken, modelId = modelId, modelInput = modelInput, outputDataConfig = outputDataConfig, tags = tags)
  output <- .bedrockruntime$start_async_invoke_output()
  config <- get_config()
  svc <- .bedrockruntime$service(config, op)
  request <- new_request(svc, op, input, output)
  response <- send_request(request)
  return(response)
}
.bedrockruntime$operations$start_async_invoke <- bedrockruntime_start_async_invoke
