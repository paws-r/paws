% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/databasemigrationservice_operations.R
\name{databasemigrationservice_create_endpoint}
\alias{databasemigrationservice_create_endpoint}
\title{Creates an endpoint using the provided settings}
\usage{
databasemigrationservice_create_endpoint(EndpointIdentifier,
  EndpointType, EngineName, Username, Password, ServerName, Port,
  DatabaseName, ExtraConnectionAttributes, KmsKeyId, Tags, CertificateArn,
  SslMode, ServiceAccessRoleArn, ExternalTableDefinition,
  DynamoDbSettings, S3Settings, DmsTransferSettings, MongoDbSettings,
  KinesisSettings, KafkaSettings, ElasticsearchSettings, NeptuneSettings,
  RedshiftSettings)
}
\arguments{
\item{EndpointIdentifier}{[required] The database endpoint identifier. Identifiers must begin with a letter
and must contain only ASCII letters, digits, and hyphens. They can't end
with a hyphen or contain two consecutive hyphens.}

\item{EndpointType}{[required] The type of endpoint. Valid values are \code{source} and \code{target}.}

\item{EngineName}{[required] The type of engine for the endpoint. Valid values, depending on the
\code{EndpointType} value, include \code{"mysql"}, \code{"oracle"}, \code{"postgres"},
\code{"mariadb"}, \code{"aurora"}, \code{"aurora-postgresql"}, \code{"redshift"}, \code{"s3"},
\code{"db2"}, \code{"azuredb"}, \code{"sybase"}, \code{"dynamodb"}, \code{"mongodb"},
\code{"kinesis"}, \code{"kafka"}, \code{"elasticsearch"}, \code{"documentdb"},
\code{"sqlserver"}, and \code{"neptune"}.}

\item{Username}{The user name to be used to log in to the endpoint database.}

\item{Password}{The password to be used to log in to the endpoint database.}

\item{ServerName}{The name of the server where the endpoint database resides.}

\item{Port}{The port used by the endpoint database.}

\item{DatabaseName}{The name of the endpoint database.}

\item{ExtraConnectionAttributes}{Additional attributes associated with the connection. Each attribute is
specified as a name-value pair associated by an equal sign (=). Multiple
attributes are separated by a semicolon (;) with no additional white
space. For information on the attributes available for connecting your
source or target endpoint, see \href{https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Endpoints.html}{Working with AWS DMS Endpoints}
in the \emph{AWS Database Migration Service User Guide.}}

\item{KmsKeyId}{An AWS KMS key identifier that is used to encrypt the connection
parameters for the endpoint.

If you don't specify a value for the \code{KmsKeyId} parameter, then AWS DMS
uses your default encryption key.

AWS KMS creates the default encryption key for your AWS account. Your
AWS account has a different default encryption key for each AWS Region.}

\item{Tags}{One or more tags to be assigned to the endpoint.}

\item{CertificateArn}{The Amazon Resource Name (ARN) for the certificate.}

\item{SslMode}{The Secure Sockets Layer (SSL) mode to use for the SSL connection. The
default is \code{none}}

\item{ServiceAccessRoleArn}{The Amazon Resource Name (ARN) for the service access role that you want
to use to create the endpoint.}

\item{ExternalTableDefinition}{The external table definition.}

\item{DynamoDbSettings}{Settings in JSON format for the target Amazon DynamoDB endpoint. For
information about other available settings, see \href{https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Target.DynamoDB.html}{Using Object Mapping to Migrate Data to DynamoDB}
in the \emph{AWS Database Migration Service User Guide.}}

\item{S3Settings}{Settings in JSON format for the target Amazon S3 endpoint. For more
information about the available settings, see \href{https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Target.S3.html#CHAP_Target.S3.Configuring}{Extra Connection Attributes When Using Amazon S3 as a Target for AWS DMS}
in the \emph{AWS Database Migration Service User Guide.}}

\item{DmsTransferSettings}{The settings in JSON format for the DMS transfer type of source
endpoint.

Possible settings include the following:
\itemize{
\item \code{ServiceAccessRoleArn} - The IAM role that has permission to access
the Amazon S3 bucket.
\item \code{BucketName} - The name of the S3 bucket to use.
\item \code{CompressionType} - An optional parameter to use GZIP to compress
the target files. To use GZIP, set this value to \code{NONE} (the
default). To keep the files uncompressed, don't use this value.
}

Shorthand syntax for these settings is as follows:
\verb{ServiceAccessRoleArn=string,BucketName=string,CompressionType=string}

JSON syntax for these settings is as follows:
\verb{\\\{ "ServiceAccessRoleArn": "string", "BucketName": "string", "CompressionType": "none"|"gzip" \\\} }}

\item{MongoDbSettings}{Settings in JSON format for the source MongoDB endpoint. For more
information about the available settings, see \href{https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Source.MongoDB.html#CHAP_Source.MongoDB.Configuration}{Using MongoDB as a Target for AWS Database Migration Service}
in the \emph{AWS Database Migration Service User Guide.}}

\item{KinesisSettings}{Settings in JSON format for the target endpoint for Amazon Kinesis Data
Streams. For more information about the available settings, see \href{https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Target.Kinesis.html}{Using Amazon Kinesis Data Streams as a Target for AWS Database Migration Service}
in the \emph{AWS Database Migration Service User Guide.}}

\item{KafkaSettings}{Settings in JSON format for the target Apache Kafka endpoint. For more
information about the available settings, see \href{https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Target.Kafka.html}{Using Apache Kafka as a Target for AWS Database Migration Service}
in the \emph{AWS Database Migration Service User Guide.}}

\item{ElasticsearchSettings}{Settings in JSON format for the target Elasticsearch endpoint. For more
information about the available settings, see \href{https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Target.Elasticsearch.html#CHAP_Target.Elasticsearch.Configuration}{Extra Connection Attributes When Using Elasticsearch as a Target for AWS DMS}
in the \emph{AWS Database Migration Service User Guide}.}

\item{NeptuneSettings}{Settings in JSON format for the target Amazon Neptune endpoint. For more
information about the available settings, see \href{https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Target.Neptune.html#CHAP_Target.Neptune.EndpointSettings}{Specifying Endpoint Settings for Amazon Neptune as a Target}
in the \emph{AWS Database Migration Service User Guide.}}

\item{RedshiftSettings}{}
}
\description{
Creates an endpoint using the provided settings.
}
\section{Request syntax}{
\preformatted{svc$create_endpoint(
  EndpointIdentifier = "string",
  EndpointType = "source"|"target",
  EngineName = "string",
  Username = "string",
  Password = "string",
  ServerName = "string",
  Port = 123,
  DatabaseName = "string",
  ExtraConnectionAttributes = "string",
  KmsKeyId = "string",
  Tags = list(
    list(
      Key = "string",
      Value = "string"
    )
  ),
  CertificateArn = "string",
  SslMode = "none"|"require"|"verify-ca"|"verify-full",
  ServiceAccessRoleArn = "string",
  ExternalTableDefinition = "string",
  DynamoDbSettings = list(
    ServiceAccessRoleArn = "string"
  ),
  S3Settings = list(
    ServiceAccessRoleArn = "string",
    ExternalTableDefinition = "string",
    CsvRowDelimiter = "string",
    CsvDelimiter = "string",
    BucketFolder = "string",
    BucketName = "string",
    CompressionType = "none"|"gzip",
    EncryptionMode = "sse-s3"|"sse-kms",
    ServerSideEncryptionKmsKeyId = "string",
    DataFormat = "csv"|"parquet",
    EncodingType = "plain"|"plain-dictionary"|"rle-dictionary",
    DictPageSizeLimit = 123,
    RowGroupLength = 123,
    DataPageSize = 123,
    ParquetVersion = "parquet-1-0"|"parquet-2-0",
    EnableStatistics = TRUE|FALSE,
    IncludeOpForFullLoad = TRUE|FALSE,
    CdcInsertsOnly = TRUE|FALSE,
    TimestampColumnName = "string",
    ParquetTimestampInMillisecond = TRUE|FALSE,
    CdcInsertsAndUpdates = TRUE|FALSE
  ),
  DmsTransferSettings = list(
    ServiceAccessRoleArn = "string",
    BucketName = "string"
  ),
  MongoDbSettings = list(
    Username = "string",
    Password = "string",
    ServerName = "string",
    Port = 123,
    DatabaseName = "string",
    AuthType = "no"|"password",
    AuthMechanism = "default"|"mongodb_cr"|"scram_sha_1",
    NestingLevel = "none"|"one",
    ExtractDocId = "string",
    DocsToInvestigate = "string",
    AuthSource = "string",
    KmsKeyId = "string"
  ),
  KinesisSettings = list(
    StreamArn = "string",
    MessageFormat = "json"|"json-unformatted",
    ServiceAccessRoleArn = "string",
    IncludeTransactionDetails = TRUE|FALSE,
    IncludePartitionValue = TRUE|FALSE,
    PartitionIncludeSchemaTable = TRUE|FALSE,
    IncludeTableAlterOperations = TRUE|FALSE,
    IncludeControlDetails = TRUE|FALSE
  ),
  KafkaSettings = list(
    Broker = "string",
    Topic = "string"
  ),
  ElasticsearchSettings = list(
    ServiceAccessRoleArn = "string",
    EndpointUri = "string",
    FullLoadErrorPercentage = 123,
    ErrorRetryDuration = 123
  ),
  NeptuneSettings = list(
    ServiceAccessRoleArn = "string",
    S3BucketName = "string",
    S3BucketFolder = "string",
    ErrorRetryDuration = 123,
    MaxFileSize = 123,
    MaxRetryCount = 123,
    IamAuthEnabled = TRUE|FALSE
  ),
  RedshiftSettings = list(
    AcceptAnyDate = TRUE|FALSE,
    AfterConnectScript = "string",
    BucketFolder = "string",
    BucketName = "string",
    ConnectionTimeout = 123,
    DatabaseName = "string",
    DateFormat = "string",
    EmptyAsNull = TRUE|FALSE,
    EncryptionMode = "sse-s3"|"sse-kms",
    FileTransferUploadStreams = 123,
    LoadTimeout = 123,
    MaxFileSize = 123,
    Password = "string",
    Port = 123,
    RemoveQuotes = TRUE|FALSE,
    ReplaceInvalidChars = "string",
    ReplaceChars = "string",
    ServerName = "string",
    ServiceAccessRoleArn = "string",
    ServerSideEncryptionKmsKeyId = "string",
    TimeFormat = "string",
    TrimBlanks = TRUE|FALSE,
    TruncateColumns = TRUE|FALSE,
    Username = "string",
    WriteBufferSize = 123
  )
)
}
}

\examples{
\dontrun{
# Creates an endpoint using the provided settings.
svc$create_endpoint(
  CertificateArn = "",
  DatabaseName = "testdb",
  EndpointIdentifier = "test-endpoint-1",
  EndpointType = "source",
  EngineName = "mysql",
  ExtraConnectionAttributes = "",
  KmsKeyId = "arn:aws:kms:us-east-1:123456789012:key/4c1731d6-5435-ed4d-be13-d53411a7cfbd",
  Password = "pasword",
  Port = 3306L,
  ServerName = "mydb.cx1llnox7iyx.us-west-2.rds.amazonaws.com",
  SslMode = "require",
  Tags = list(
    list(
      Key = "Acount",
      Value = "143327655"
    )
  ),
  Username = "username"
)
}

}
\keyword{internal}
