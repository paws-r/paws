% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/bedrock_operations.R
\name{bedrock_create_automated_reasoning_policy_test_case}
\alias{bedrock_create_automated_reasoning_policy_test_case}
\title{Creates a test for an Automated Reasoning policy}
\usage{
bedrock_create_automated_reasoning_policy_test_case(
  policyArn,
  guardContent,
  queryContent = NULL,
  expectedAggregatedFindingsResult,
  clientRequestToken = NULL,
  confidenceThreshold = NULL
)
}
\arguments{
\item{policyArn}{[required] The Amazon Resource Name (ARN) of the Automated Reasoning policy for
which to create the test.}

\item{guardContent}{[required] The output content that's validated by the Automated Reasoning policy.
This represents the foundation model response that will be checked for
accuracy.}

\item{queryContent}{The input query or prompt that generated the content. This provides
context for the validation.}

\item{expectedAggregatedFindingsResult}{[required] The expected result of the Automated Reasoning check. Valid values
include: , TOO_COMPLEX, and NO_TRANSLATIONS.
\itemize{
\item \code{VALID} - The claims are true. The claims are implied by the
premises and the Automated Reasoning policy. Given the Automated
Reasoning policy and premises, it is not possible for these claims
to be false. In other words, there are no alternative answers that
are true that contradict the claims.
\item \code{INVALID} - The claims are false. The claims are not implied by the
premises and Automated Reasoning policy. Furthermore, there exists
different claims that are consistent with the premises and Automated
Reasoning policy.
\item \code{SATISFIABLE} - The claims can be true or false. It depends on what
assumptions are made for the claim to be implied from the premises
and Automated Reasoning policy rules. In this situation, different
assumptions can make input claims false and alternative claims true.
\item \code{IMPOSSIBLE} - Automated Reasoning canâ€™t make a statement about the
claims. This can happen if the premises are logically incorrect, or
if there is a conflict within the Automated Reasoning policy itself.
\item \code{TRANSLATION_AMBIGUOUS} - Detected an ambiguity in the translation
meant it would be unsound to continue with validity checking.
Additional context or follow-up questions might be needed to get
translation to succeed.
\item \code{TOO_COMPLEX} - The input contains too much information for
Automated Reasoning to process within its latency limits.
\item \code{NO_TRANSLATIONS} - Identifies that some or all of the input prompt
wasn't translated into logic. This can happen if the input isn't
relevant to the Automated Reasoning policy, or if the policy doesn't
have variables to model relevant input. If Automated Reasoning can't
translate anything, you get a single \code{NO_TRANSLATIONS} finding. You
might also see a \code{NO_TRANSLATIONS} (along with other findings) if
some part of the validation isn't translated.
}}

\item{clientRequestToken}{A unique, case-sensitive identifier to ensure that the operation
completes no more than one time. If this token matches a previous
request, Amazon Bedrock ignores the request, but does not return an
error.}

\item{confidenceThreshold}{The minimum confidence level for logic validation. Content that meets
the threshold is considered a high-confidence finding that can be
validated.}
}
\description{
Creates a test for an Automated Reasoning policy. Tests validate that your policy works as expected by providing sample inputs and expected outcomes. Use tests to verify policy behavior before deploying to production.

See \url{https://www.paws-r-sdk.com/docs/bedrock_create_automated_reasoning_policy_test_case/} for full documentation.
}
\keyword{internal}
